# ç›‘æ§å‘Šè­¦å®Œæ•´æ–¹æ¡ˆ 2025 - Prometheus + Grafana + Alertmanager

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
> **æœ€åæ›´æ–°**: 2025-10-04  
> **å…³è”æ–‡æ¡£**: [ç”Ÿäº§æœ€ä½³å®è·µ 2025](./19-production-best-practices-2025.md), [OPAMP v1.0](./15-opamp-protocol-specification-2025.md)

---

## ç›®å½•

- [ç›‘æ§å‘Šè­¦å®Œæ•´æ–¹æ¡ˆ 2025 - Prometheus + Grafana + Alertmanager](#ç›‘æ§å‘Šè­¦å®Œæ•´æ–¹æ¡ˆ-2025---prometheus--grafana--alertmanager)
  - [ç›®å½•](#ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1 ç›‘æ§å‘Šè­¦çš„é‡è¦æ€§](#11-ç›‘æ§å‘Šè­¦çš„é‡è¦æ€§)
    - [1.2 å®Œæ•´ç›‘æ§ä½“ç³»](#12-å®Œæ•´ç›‘æ§ä½“ç³»)
    - [1.3 æ–‡æ¡£ç›®æ ‡](#13-æ–‡æ¡£ç›®æ ‡)
  - [2. ç›‘æ§æŒ‡æ ‡è®¾è®¡](#2-ç›‘æ§æŒ‡æ ‡è®¾è®¡)
    - [2.1 å››å±‚ç›‘æ§æ¨¡å‹](#21-å››å±‚ç›‘æ§æ¨¡å‹)
    - [2.2 åº”ç”¨å±‚æŒ‡æ ‡](#22-åº”ç”¨å±‚æŒ‡æ ‡)
      - [2.2.1 RED æŒ‡æ ‡ï¼ˆRate, Errors, Durationï¼‰](#221-red-æŒ‡æ ‡rate-errors-duration)
      - [2.2.2 USE æŒ‡æ ‡ï¼ˆUtilization, Saturation, Errorsï¼‰](#222-use-æŒ‡æ ‡utilization-saturation-errors)
    - [2.3 Collector æŒ‡æ ‡](#23-collector-æŒ‡æ ‡)
      - [2.3.1 æ•°æ®æµæŒ‡æ ‡](#231-æ•°æ®æµæŒ‡æ ‡)
      - [2.3.2 èµ„æºæŒ‡æ ‡](#232-èµ„æºæŒ‡æ ‡)
    - [2.4 åç«¯å­˜å‚¨æŒ‡æ ‡](#24-åç«¯å­˜å‚¨æŒ‡æ ‡)
      - [2.4.1 Jaeger æŒ‡æ ‡](#241-jaeger-æŒ‡æ ‡)
      - [2.4.2 Prometheus æŒ‡æ ‡](#242-prometheus-æŒ‡æ ‡)
    - [2.5 åŸºç¡€è®¾æ–½æŒ‡æ ‡](#25-åŸºç¡€è®¾æ–½æŒ‡æ ‡)
      - [2.5.1 Kubernetes æŒ‡æ ‡](#251-kubernetes-æŒ‡æ ‡)
      - [2.5.2 èŠ‚ç‚¹æŒ‡æ ‡](#252-èŠ‚ç‚¹æŒ‡æ ‡)
  - [3. Prometheus é…ç½®](#3-prometheus-é…ç½®)
    - [3.1 æœåŠ¡å‘ç°é…ç½®](#31-æœåŠ¡å‘ç°é…ç½®)
      - [3.1.1 Kubernetes æœåŠ¡å‘ç°](#311-kubernetes-æœåŠ¡å‘ç°)
    - [3.2 æŠ“å–é…ç½®](#32-æŠ“å–é…ç½®)
      - [3.2.1 åº”ç”¨æŠ“å–é…ç½®](#321-åº”ç”¨æŠ“å–é…ç½®)
    - [3.3 è®°å½•è§„åˆ™](#33-è®°å½•è§„åˆ™)
      - [3.3.1 é¢„èšåˆè§„åˆ™](#331-é¢„èšåˆè§„åˆ™)
    - [3.4 è”é‚¦é›†ç¾¤](#34-è”é‚¦é›†ç¾¤)
      - [3.4.1 å¤šé›†ç¾¤èšåˆ](#341-å¤šé›†ç¾¤èšåˆ)
  - [4. å‘Šè­¦è§„åˆ™åº“](#4-å‘Šè­¦è§„åˆ™åº“)
    - [4.1 åº”ç”¨å±‚å‘Šè­¦](#41-åº”ç”¨å±‚å‘Šè­¦)
      - [4.1.1 é«˜é”™è¯¯ç‡å‘Šè­¦](#411-é«˜é”™è¯¯ç‡å‘Šè­¦)
      - [4.1.2 èµ„æºå‘Šè­¦](#412-èµ„æºå‘Šè­¦)
    - [4.2 Collector å‘Šè­¦](#42-collector-å‘Šè­¦)
      - [4.2.1 æ•°æ®ä¸¢å¤±å‘Šè­¦](#421-æ•°æ®ä¸¢å¤±å‘Šè­¦)
      - [4.2.2 æ€§èƒ½å‘Šè­¦](#422-æ€§èƒ½å‘Šè­¦)
    - [4.3 åç«¯å­˜å‚¨å‘Šè­¦](#43-åç«¯å­˜å‚¨å‘Šè­¦)
      - [4.3.1 Jaeger å‘Šè­¦](#431-jaeger-å‘Šè­¦)
    - [4.4 SLO å‘Šè­¦](#44-slo-å‘Šè­¦)
      - [4.4.1 SLO è¿åå‘Šè­¦](#441-slo-è¿åå‘Šè­¦)
  - [5. Alertmanager é…ç½®](#5-alertmanager-é…ç½®)
    - [5.1 è·¯ç”±é…ç½®](#51-è·¯ç”±é…ç½®)
    - [5.2 æŠ‘åˆ¶è§„åˆ™](#52-æŠ‘åˆ¶è§„åˆ™)
    - [5.3 é™é»˜è§„åˆ™](#53-é™é»˜è§„åˆ™)
    - [5.4 é«˜å¯ç”¨é…ç½®](#54-é«˜å¯ç”¨é…ç½®)
  - [6. é€šçŸ¥æ¸ é“é›†æˆ](#6-é€šçŸ¥æ¸ é“é›†æˆ)
    - [6.1 PagerDuty é›†æˆ](#61-pagerduty-é›†æˆ)
    - [6.2 Slack é›†æˆ](#62-slack-é›†æˆ)
    - [6.3 ä¼ä¸šå¾®ä¿¡é›†æˆ](#63-ä¼ä¸šå¾®ä¿¡é›†æˆ)
    - [6.4 Email é›†æˆ](#64-email-é›†æˆ)
  - [7. Grafana Dashboard](#7-grafana-dashboard)
    - [7.1 Overview Dashboard](#71-overview-dashboard)
      - [7.1.1 Dashboard è®¾è®¡](#711-dashboard-è®¾è®¡)
    - [7.2 Application Dashboard](#72-application-dashboard)
      - [7.2.1 RED æŒ‡æ ‡é¢æ¿](#721-red-æŒ‡æ ‡é¢æ¿)
    - [7.3 Collector Dashboard](#73-collector-dashboard)
      - [7.3.1 æ•°æ®æµé¢æ¿](#731-æ•°æ®æµé¢æ¿)
    - [7.4 Backend Dashboard](#74-backend-dashboard)
      - [7.4.1 Jaeger é¢æ¿](#741-jaeger-é¢æ¿)
  - [8. SLO/SLI å®šä¹‰](#8-slosli-å®šä¹‰)
    - [8.1 å¯è§‚æµ‹æ€§ç³»ç»Ÿ SLO](#81-å¯è§‚æµ‹æ€§ç³»ç»Ÿ-slo)
      - [8.1.1 SLO å®šä¹‰](#811-slo-å®šä¹‰)
      - [8.1.2 SLI è®¡ç®—](#812-sli-è®¡ç®—)
    - [8.2 Error Budget ç®¡ç†](#82-error-budget-ç®¡ç†)
      - [8.2.1 Error Budget è®¡ç®—](#821-error-budget-è®¡ç®—)
      - [8.2.2 Error Budget ç­–ç•¥](#822-error-budget-ç­–ç•¥)
    - [8.3 SLI è®¡ç®—æ–¹æ³•](#83-sli-è®¡ç®—æ–¹æ³•)
      - [8.3.1 åŸºäºè¯·æ±‚çš„ SLI](#831-åŸºäºè¯·æ±‚çš„-sli)
      - [8.3.2 åŸºäºæ—¶é—´çª—å£çš„ SLI](#832-åŸºäºæ—¶é—´çª—å£çš„-sli)
    - [8.4 SLO å‘Šè­¦ç­–ç•¥](#84-slo-å‘Šè­¦ç­–ç•¥)
      - [8.4.1 å¤šçª—å£å¤šç‡ƒçƒ§ç‡å‘Šè­¦](#841-å¤šçª—å£å¤šç‡ƒçƒ§ç‡å‘Šè­¦)
  - [9. è‡ªåŠ¨åŒ–å“åº”](#9-è‡ªåŠ¨åŒ–å“åº”)
    - [9.1 è‡ªåŠ¨æ‰©å®¹](#91-è‡ªåŠ¨æ‰©å®¹)
      - [9.1.1 HPA é…ç½®ï¼ˆKubernetesï¼‰](#911-hpa-é…ç½®kubernetes)
      - [9.1.2 KEDA æ‰©å®¹ï¼ˆåŸºäº Prometheus æŒ‡æ ‡ï¼‰](#912-keda-æ‰©å®¹åŸºäº-prometheus-æŒ‡æ ‡)
    - [9.2 è‡ªåŠ¨é™çº§](#92-è‡ªåŠ¨é™çº§)
      - [9.2.1 åŠ¨æ€é‡‡æ ·ç‡è°ƒæ•´](#921-åŠ¨æ€é‡‡æ ·ç‡è°ƒæ•´)
      - [9.2.2 ç†”æ–­é™çº§](#922-ç†”æ–­é™çº§)
    - [9.3 è‡ªåŠ¨ä¿®å¤](#93-è‡ªåŠ¨ä¿®å¤)
      - [9.3.1 è‡ªåŠ¨é‡å¯ Pod](#931-è‡ªåŠ¨é‡å¯-pod)
      - [9.3.2 è‡ªåŠ¨æ¸…ç†ç£ç›˜](#932-è‡ªåŠ¨æ¸…ç†ç£ç›˜)
    - [9.4 äº‹ä»¶ç®¡ç†](#94-äº‹ä»¶ç®¡ç†)
      - [9.4.1 PagerDuty äº‹ä»¶åˆ›å»º](#941-pagerduty-äº‹ä»¶åˆ›å»º)
  - [10. æœ€ä½³å®è·µ](#10-æœ€ä½³å®è·µ)
    - [10.1 å‘Šè­¦è®¾è®¡åŸåˆ™](#101-å‘Šè­¦è®¾è®¡åŸåˆ™)
      - [10.1.1 SMART åŸåˆ™](#1011-smart-åŸåˆ™)
      - [10.1.2 å‘Šè­¦åˆ†çº§](#1012-å‘Šè­¦åˆ†çº§)
    - [10.2 å‘Šè­¦ç–²åŠ³é¢„é˜²](#102-å‘Šè­¦ç–²åŠ³é¢„é˜²)
      - [10.2.1 å‡å°‘å™ªéŸ³](#1021-å‡å°‘å™ªéŸ³)
      - [10.2.2 å‘Šè­¦èšåˆ](#1022-å‘Šè­¦èšåˆ)
    - [10.3 å€¼ç­è½®æ¢](#103-å€¼ç­è½®æ¢)
      - [10.3.1 å€¼ç­è¡¨ç®¡ç†](#1031-å€¼ç­è¡¨ç®¡ç†)
      - [10.3.2 å€¼ç­äº¤æ¥](#1032-å€¼ç­äº¤æ¥)
    - [10.4 äº‹åå¤ç›˜](#104-äº‹åå¤ç›˜)
      - [10.4.1 äº‹ä»¶æŠ¥å‘Šæ¨¡æ¿](#1041-äº‹ä»¶æŠ¥å‘Šæ¨¡æ¿)
      - [10.4.2 æ”¹è¿›æªæ–½è·Ÿè¸ª](#1042-æ”¹è¿›æªæ–½è·Ÿè¸ª)
  - [11. å‚è€ƒæ–‡çŒ®](#11-å‚è€ƒæ–‡çŒ®)
  - [11. å‚è€ƒæ–‡çŒ®1](#11-å‚è€ƒæ–‡çŒ®1)

---

## 1. æ¦‚è¿°

### 1.1 ç›‘æ§å‘Šè­¦çš„é‡è¦æ€§

å¯è§‚æµ‹æ€§ç³»ç»Ÿæœ¬èº«ä¹Ÿéœ€è¦è¢«ç›‘æ§ï¼Œç¡®ä¿ï¼š

- **æ•°æ®å®Œæ•´æ€§**: æ— æ•°æ®ä¸¢å¤±
- **ä½å»¶è¿Ÿ**: P99 < 10s
- **é«˜å¯ç”¨**: 99.9%+ å¯ç”¨æ€§
- **æˆæœ¬å¯æ§**: å®æ—¶ç›‘æ§æˆæœ¬

### 1.2 å®Œæ•´ç›‘æ§ä½“ç³»

```mermaid
graph TB
    A[åº”ç”¨] --> B[OTLP SDK]
    B --> C[Collector]
    C --> D[åç«¯å­˜å‚¨]
    
    B -.ç›‘æ§.-> E[Prometheus]
    C -.ç›‘æ§.-> E
    D -.ç›‘æ§.-> E
    
    E --> F[Alertmanager]
    F --> G[PagerDuty/Slack]
    
    E --> H[Grafana]
    H --> I[Dashboard]
```

### 1.3 æ–‡æ¡£ç›®æ ‡

æœ¬æ–‡æ¡£æä¾›ï¼š

- âœ… å®Œæ•´çš„ Prometheus é…ç½®
- âœ… 100+ æ¡å‘Šè­¦è§„åˆ™
- âœ… Grafana Dashboard JSON
- âœ… SLO/SLI å®šä¹‰ä¸è®¡ç®—
- âœ… è‡ªåŠ¨åŒ–å“åº”æ–¹æ¡ˆ

---

## 2. ç›‘æ§æŒ‡æ ‡è®¾è®¡

### 2.1 å››å±‚ç›‘æ§æ¨¡å‹

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: ä¸šåŠ¡æŒ‡æ ‡                              â”‚
â”‚  - æ”¯ä»˜æˆåŠŸç‡ã€è®¢å•è½¬åŒ–ç‡                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: åº”ç”¨æŒ‡æ ‡ï¼ˆREDï¼‰                       â”‚
â”‚  - Rate, Errors, Duration                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: å¯è§‚æµ‹æ€§ç³»ç»ŸæŒ‡æ ‡                      â”‚
â”‚  - Collector ååã€Span ä¸¢å¤±ç‡                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: åŸºç¡€è®¾æ–½æŒ‡æ ‡                          â”‚
â”‚  - CPU, Memory, Disk, Network                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 åº”ç”¨å±‚æŒ‡æ ‡

#### 2.2.1 RED æŒ‡æ ‡ï¼ˆRate, Errors, Durationï¼‰

**Rateï¼ˆè¯·æ±‚é€Ÿç‡ï¼‰**:

```promql
# QPS
sum(rate(http_requests_total[5m])) by (service, method)

# æ¯ä¸ªæœåŠ¡çš„ QPS
sum(rate(http_requests_total[5m])) by (service)
```

**Errorsï¼ˆé”™è¯¯ç‡ï¼‰**:

```promql
# é”™è¯¯ç‡
sum(rate(http_requests_total{status=~"5.."}[5m])) by (service) 
/ 
sum(rate(http_requests_total[5m])) by (service)

# é”™è¯¯æ•°é‡
sum(rate(http_requests_total{status=~"5.."}[5m])) by (service, status)
```

**Durationï¼ˆå“åº”æ—¶é—´ï¼‰**:

```promql
# P50 å»¶è¿Ÿ
histogram_quantile(0.50, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)

# P95 å»¶è¿Ÿ
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)

# P99 å»¶è¿Ÿ
histogram_quantile(0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
)
```

#### 2.2.2 USE æŒ‡æ ‡ï¼ˆUtilization, Saturation, Errorsï¼‰

**Utilizationï¼ˆåˆ©ç”¨ç‡ï¼‰**:

```promql
# CPU åˆ©ç”¨ç‡
rate(process_cpu_seconds_total[5m])

# å†…å­˜åˆ©ç”¨ç‡
process_resident_memory_bytes / node_memory_MemTotal_bytes
```

**Saturationï¼ˆé¥±å’Œåº¦ï¼‰**:

```promql
# Goroutine æ•°é‡
go_goroutines

# GC æš‚åœæ—¶é—´
rate(go_gc_duration_seconds_sum[5m])
```

**Errorsï¼ˆé”™è¯¯ï¼‰**:

```promql
# Panic æ•°é‡
rate(go_panics_total[5m])
```

### 2.3 Collector æŒ‡æ ‡

#### 2.3.1 æ•°æ®æµæŒ‡æ ‡

**æ¥æ”¶æŒ‡æ ‡**:

```promql
# Span æ¥æ”¶é€Ÿç‡
rate(otelcol_receiver_accepted_spans[5m])

# Span æ‹’ç»é€Ÿç‡
rate(otelcol_receiver_refused_spans[5m])
```

**å¤„ç†æŒ‡æ ‡**:

```promql
# Span å¤„ç†é€Ÿç‡
rate(otelcol_processor_accepted_spans[5m])

# Span ä¸¢å¼ƒé€Ÿç‡
rate(otelcol_processor_dropped_spans[5m])

# Span ä¸¢å¤±ç‡
rate(otelcol_processor_dropped_spans[5m]) 
/ 
rate(otelcol_processor_accepted_spans[5m])
```

**å¯¼å‡ºæŒ‡æ ‡**:

```promql
# Span å¯¼å‡ºé€Ÿç‡
rate(otelcol_exporter_sent_spans[5m])

# Span å¯¼å‡ºå¤±è´¥é€Ÿç‡
rate(otelcol_exporter_send_failed_spans[5m])

# å¯¼å‡ºæˆåŠŸç‡
rate(otelcol_exporter_sent_spans[5m]) 
/ 
(rate(otelcol_exporter_sent_spans[5m]) + rate(otelcol_exporter_send_failed_spans[5m]))
```

#### 2.3.2 èµ„æºæŒ‡æ ‡

**é˜Ÿåˆ—æŒ‡æ ‡**:

```promql
# é˜Ÿåˆ—é•¿åº¦
otelcol_exporter_queue_size

# é˜Ÿåˆ—å®¹é‡
otelcol_exporter_queue_capacity

# é˜Ÿåˆ—ä½¿ç”¨ç‡
otelcol_exporter_queue_size / otelcol_exporter_queue_capacity
```

**èµ„æºä½¿ç”¨**:

```promql
# CPU ä½¿ç”¨
rate(process_cpu_seconds_total{job="otel-collector"}[5m])

# å†…å­˜ä½¿ç”¨
process_resident_memory_bytes{job="otel-collector"}

# Goroutine æ•°é‡
go_goroutines{job="otel-collector"}
```

### 2.4 åç«¯å­˜å‚¨æŒ‡æ ‡

#### 2.4.1 Jaeger æŒ‡æ ‡

```promql
# å†™å…¥é€Ÿç‡
rate(jaeger_spans_received_total[5m])

# æŸ¥è¯¢å»¶è¿Ÿ
histogram_quantile(0.99, 
  rate(jaeger_query_requests_duration_seconds_bucket[5m])
)

# å­˜å‚¨å®¹é‡
jaeger_storage_capacity_bytes
```

#### 2.4.2 Prometheus æŒ‡æ ‡

```promql
# æ—¶é—´åºåˆ—æ•°é‡
prometheus_tsdb_symbol_table_size_bytes

# æŸ¥è¯¢å»¶è¿Ÿ
histogram_quantile(0.99, 
  rate(prometheus_http_request_duration_seconds_bucket{handler="/api/v1/query"}[5m])
)

# WAL å¤§å°
prometheus_tsdb_wal_size_bytes
```

### 2.5 åŸºç¡€è®¾æ–½æŒ‡æ ‡

#### 2.5.1 Kubernetes æŒ‡æ ‡

```promql
# Pod CPU ä½¿ç”¨ç‡
sum(rate(container_cpu_usage_seconds_total{namespace="observability"}[5m])) by (pod)

# Pod å†…å­˜ä½¿ç”¨ç‡
sum(container_memory_working_set_bytes{namespace="observability"}) by (pod)

# Pod é‡å¯æ¬¡æ•°
kube_pod_container_status_restarts_total{namespace="observability"}
```

#### 2.5.2 èŠ‚ç‚¹æŒ‡æ ‡

```promql
# èŠ‚ç‚¹ CPU ä½¿ç”¨ç‡
1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance)

# èŠ‚ç‚¹å†…å­˜ä½¿ç”¨ç‡
1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)

# ç£ç›˜ä½¿ç”¨ç‡
1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)
```

---

## 3. Prometheus é…ç½®

### 3.1 æœåŠ¡å‘ç°é…ç½®

#### 3.1.1 Kubernetes æœåŠ¡å‘ç°

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'prod-k8s'
    region: 'us-east-1'

scrape_configs:
  # 1. Kubernetes Pod å‘ç°
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
    - role: pod
      namespaces:
        names:
        - observability
        - default
    
    relabel_configs:
    # ä»…æŠ“å–å¸¦æœ‰ prometheus.io/scrape=true çš„ Pod
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
      action: keep
      regex: true
      
    # ä½¿ç”¨æ³¨è§£æŒ‡å®šçš„ç«¯å£
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
      action: replace
      target_label: __address__
      regex: ([^:]+)(?::\d+)?;(\d+)
      replacement: $1:$2
      
    # ä½¿ç”¨æ³¨è§£æŒ‡å®šçš„è·¯å¾„
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
      action: replace
      target_label: __metrics_path__
      regex: (.+)
      
    # æ·»åŠ  Pod æ ‡ç­¾
    - source_labels: [__meta_kubernetes_namespace]
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      target_label: pod
    - source_labels: [__meta_kubernetes_pod_label_app]
      target_label: app

  # 2. Kubernetes Service å‘ç°
  - job_name: 'kubernetes-services'
    kubernetes_sd_configs:
    - role: service
      namespaces:
        names:
        - observability
    
    relabel_configs:
    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
      action: keep
      regex: true
    - source_labels: [__meta_kubernetes_service_name]
      target_label: service

  # 3. OTLP Collector ä¸“ç”¨é…ç½®
  - job_name: 'otel-collector'
    kubernetes_sd_configs:
    - role: pod
      namespaces:
        names:
        - observability
    
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_label_app]
      action: keep
      regex: otel-collector
    - source_labels: [__meta_kubernetes_pod_name]
      target_label: instance
    - source_labels: [__meta_kubernetes_pod_node_name]
      target_label: node
```

### 3.2 æŠ“å–é…ç½®

#### 3.2.1 åº”ç”¨æŠ“å–é…ç½®

```yaml
scrape_configs:
  - job_name: 'applications'
    scrape_interval: 10s
    scrape_timeout: 5s
    
    kubernetes_sd_configs:
    - role: pod
    
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
      action: keep
      regex: true
      
    # é‡‡æ ·ï¼šä»…æŠ“å– 10% çš„ Podï¼ˆå¤§è§„æ¨¡åœºæ™¯ï¼‰
    - source_labels: [__meta_kubernetes_pod_name]
      action: hashmod
      target_label: __tmp_hash
      modulus: 10
    - source_labels: [__tmp_hash]
      action: keep
      regex: 0  # ä»…ä¿ç•™å“ˆå¸Œå€¼ä¸º 0 çš„ï¼ˆ10%ï¼‰
```

### 3.3 è®°å½•è§„åˆ™

#### 3.3.1 é¢„èšåˆè§„åˆ™

```yaml
# recording_rules.yml
groups:
- name: otel_recording_rules
  interval: 30s
  rules:
  # 1. QPS é¢„èšåˆ
  - record: service:http_requests:rate5m
    expr: |
      sum(rate(http_requests_total[5m])) by (service)
  
  # 2. é”™è¯¯ç‡é¢„èšåˆ
  - record: service:http_errors:rate5m
    expr: |
      sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
      /
      sum(rate(http_requests_total[5m])) by (service)
  
  # 3. P99 å»¶è¿Ÿé¢„èšåˆ
  - record: service:http_duration:p99
    expr: |
      histogram_quantile(0.99,
        sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
      )
  
  # 4. Collector Span ä¸¢å¤±ç‡
  - record: collector:spans_dropped:rate5m
    expr: |
      sum(rate(otelcol_processor_dropped_spans[5m])) by (instance)
      /
      sum(rate(otelcol_processor_accepted_spans[5m])) by (instance)
  
  # 5. Collector é˜Ÿåˆ—ä½¿ç”¨ç‡
  - record: collector:queue_utilization
    expr: |
      otelcol_exporter_queue_size / otelcol_exporter_queue_capacity
```

### 3.4 è”é‚¦é›†ç¾¤

#### 3.4.1 å¤šé›†ç¾¤èšåˆ

```yaml
# ä¸­å¿ƒ Prometheus é…ç½®
scrape_configs:
  - job_name: 'federate'
    scrape_interval: 30s
    honor_labels: true
    metrics_path: '/federate'
    
    params:
      'match[]':
      - '{job="otel-collector"}'
      - '{__name__=~"service:.*"}'  # ä»…æ‹‰å–é¢„èšåˆæŒ‡æ ‡
    
    static_configs:
    - targets:
      - 'prometheus-us-east-1:9090'
      - 'prometheus-us-west-2:9090'
      - 'prometheus-eu-west-1:9090'
```

---

## 4. å‘Šè­¦è§„åˆ™åº“

### 4.1 åº”ç”¨å±‚å‘Šè­¦

#### 4.1.1 é«˜é”™è¯¯ç‡å‘Šè­¦

```yaml
# alert_rules.yml
groups:
- name: application_alerts
  rules:
  # 1. é«˜é”™è¯¯ç‡ï¼ˆ5xxï¼‰
  - alert: HighErrorRate
    expr: |
      (
        sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
        /
        sum(rate(http_requests_total[5m])) by (service)
      ) > 0.05
    for: 2m
    labels:
      severity: critical
      team: backend
    annotations:
      summary: "æœåŠ¡ {{ $labels.service }} é”™è¯¯ç‡è¿‡é«˜"
      description: "é”™è¯¯ç‡: {{ $value | humanizePercentage }}"
      runbook_url: "https://wiki.example.com/runbooks/high-error-rate"
      dashboard_url: "https://grafana.example.com/d/app-overview?var-service={{ $labels.service }}"
  
  # 2. é«˜å»¶è¿Ÿ
  - alert: HighLatency
    expr: |
      histogram_quantile(0.99,
        sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
      ) > 1.0
    for: 5m
    labels:
      severity: warning
      team: backend
    annotations:
      summary: "æœåŠ¡ {{ $labels.service }} P99 å»¶è¿Ÿè¿‡é«˜"
      description: "P99 å»¶è¿Ÿ: {{ $value }}s"
  
  # 3. ä½ååé‡ï¼ˆæµé‡çªé™ï¼‰
  - alert: LowThroughput
    expr: |
      sum(rate(http_requests_total[5m])) by (service)
      <
      sum(rate(http_requests_total[5m] offset 1h)) by (service) * 0.5
    for: 5m
    labels:
      severity: warning
      team: backend
    annotations:
      summary: "æœåŠ¡ {{ $labels.service }} æµé‡çªé™ 50%"
      description: "å½“å‰ QPS: {{ $value }}"
```

#### 4.1.2 èµ„æºå‘Šè­¦

```yaml
- name: resource_alerts
  rules:
  # 1. é«˜ CPU ä½¿ç”¨
  - alert: HighCPUUsage
    expr: |
      rate(process_cpu_seconds_total{job="applications"}[5m]) > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "åº”ç”¨ {{ $labels.instance }} CPU ä½¿ç”¨ç‡è¿‡é«˜"
      description: "CPU ä½¿ç”¨ç‡: {{ $value | humanizePercentage }}"
  
  # 2. é«˜å†…å­˜ä½¿ç”¨
  - alert: HighMemoryUsage
    expr: |
      process_resident_memory_bytes{job="applications"} 
      / 
      node_memory_MemTotal_bytes > 0.9
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "åº”ç”¨ {{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
      description: "å†…å­˜ä½¿ç”¨ç‡: {{ $value | humanizePercentage }}"
  
  # 3. Goroutine æ³„æ¼
  - alert: GoroutineLeakSuspected
    expr: |
      go_goroutines{job="applications"} > 10000
      and
      deriv(go_goroutines{job="applications"}[10m]) > 10
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "åº”ç”¨ {{ $labels.instance }} ç–‘ä¼¼ Goroutine æ³„æ¼"
      description: "Goroutine æ•°é‡: {{ $value }}"
```

### 4.2 Collector å‘Šè­¦

#### 4.2.1 æ•°æ®ä¸¢å¤±å‘Šè­¦

```yaml
- name: collector_alerts
  rules:
  # 1. Span ä¸¢å¤±ç‡è¿‡é«˜
  - alert: HighSpanDropRate
    expr: |
      (
        sum(rate(otelcol_processor_dropped_spans[5m])) by (instance)
        /
        sum(rate(otelcol_processor_accepted_spans[5m])) by (instance)
      ) > 0.01
    for: 2m
    labels:
      severity: critical
      team: observability
    annotations:
      summary: "Collector {{ $labels.instance }} Span ä¸¢å¤±ç‡è¿‡é«˜"
      description: "ä¸¢å¤±ç‡: {{ $value | humanizePercentage }}"
      action: "æ£€æŸ¥é˜Ÿåˆ—å®¹é‡ã€åç«¯å¥åº·çŠ¶æ€"
  
  # 2. å¯¼å‡ºå¤±è´¥ç‡è¿‡é«˜
  - alert: HighExportFailureRate
    expr: |
      (
        sum(rate(otelcol_exporter_send_failed_spans[5m])) by (instance, exporter)
        /
        (
          sum(rate(otelcol_exporter_sent_spans[5m])) by (instance, exporter)
          +
          sum(rate(otelcol_exporter_send_failed_spans[5m])) by (instance, exporter)
        )
      ) > 0.05
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Collector {{ $labels.instance }} å¯¼å‡ºå¤±è´¥ç‡è¿‡é«˜"
      description: "å¤±è´¥ç‡: {{ $value | humanizePercentage }}, Exporter: {{ $labels.exporter }}"
  
  # 3. é˜Ÿåˆ—æ¥è¿‘æ»¡
  - alert: ExporterQueueAlmostFull
    expr: |
      (
        otelcol_exporter_queue_size
        /
        otelcol_exporter_queue_capacity
      ) > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Collector {{ $labels.instance }} é˜Ÿåˆ—æ¥è¿‘æ»¡"
      description: "é˜Ÿåˆ—ä½¿ç”¨ç‡: {{ $value | humanizePercentage }}"
      action: "è€ƒè™‘å¢å¤§é˜Ÿåˆ—å®¹é‡æˆ–æ‰©å®¹ Collector"
```

#### 4.2.2 æ€§èƒ½å‘Šè­¦

```yaml
- name: collector_performance_alerts
  rules:
  # 1. Collector CPU è¿‡é«˜
  - alert: CollectorHighCPU
    expr: |
      rate(process_cpu_seconds_total{job="otel-collector"}[5m]) > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Collector {{ $labels.instance }} CPU ä½¿ç”¨ç‡è¿‡é«˜"
      description: "CPU: {{ $value | humanizePercentage }}"
  
  # 2. Collector å†…å­˜è¿‡é«˜
  - alert: CollectorHighMemory
    expr: |
      process_resident_memory_bytes{job="otel-collector"} > 6e9  # 6GB
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Collector {{ $labels.instance }} å†…å­˜ä½¿ç”¨è¿‡é«˜"
      description: "å†…å­˜: {{ $value | humanize }}B"
  
  # 3. Collector é‡å¯é¢‘ç¹
  - alert: CollectorFrequentRestarts
    expr: |
      rate(kube_pod_container_status_restarts_total{container="otel-collector"}[1h]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Collector {{ $labels.pod }} é‡å¯é¢‘ç¹"
      description: "1 å°æ—¶å†…é‡å¯ {{ $value }} æ¬¡"
```

### 4.3 åç«¯å­˜å‚¨å‘Šè­¦

#### 4.3.1 Jaeger å‘Šè­¦

```yaml
- name: jaeger_alerts
  rules:
  # 1. Jaeger æŸ¥è¯¢å»¶è¿Ÿè¿‡é«˜
  - alert: JaegerHighQueryLatency
    expr: |
      histogram_quantile(0.99,
        rate(jaeger_query_requests_duration_seconds_bucket[5m])
      ) > 5.0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Jaeger æŸ¥è¯¢ P99 å»¶è¿Ÿè¿‡é«˜"
      description: "P99 å»¶è¿Ÿ: {{ $value }}s"
  
  # 2. Jaeger å­˜å‚¨å®¹é‡ä¸è¶³
  - alert: JaegerStorageLow
    expr: |
      (
        jaeger_storage_used_bytes
        /
        jaeger_storage_capacity_bytes
      ) > 0.85
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Jaeger å­˜å‚¨å®¹é‡ä¸è¶³"
      description: "ä½¿ç”¨ç‡: {{ $value | humanizePercentage }}"
```

### 4.4 SLO å‘Šè­¦

#### 4.4.1 SLO è¿åå‘Šè­¦

```yaml
- name: slo_alerts
  rules:
  # 1. å¯ç”¨æ€§ SLO è¿å
  - alert: AvailabilitySLOViolation
    expr: |
      (
        1 - (
          sum(rate(http_requests_total{status=~"5.."}[30d]))
          /
          sum(rate(http_requests_total[30d]))
        )
      ) < 0.999
    for: 5m
    labels:
      severity: critical
      slo: availability
    annotations:
      summary: "å¯ç”¨æ€§ SLO è¿åï¼ˆç›®æ ‡ 99.9%ï¼‰"
      description: "å½“å‰å¯ç”¨æ€§: {{ $value | humanizePercentage }}"
  
  # 2. Error Budget è€—å°½
  - alert: ErrorBudgetExhausted
    expr: |
      (
        1 - (
          sum(rate(http_requests_total{status=~"5.."}[7d]))
          /
          sum(rate(http_requests_total[7d]))
        )
      ) < 0.999
    for: 1h
    labels:
      severity: warning
      slo: availability
    annotations:
      summary: "Error Budget å³å°†è€—å°½"
      description: "7 å¤©å¯ç”¨æ€§: {{ $value | humanizePercentage }}"
      action: "æš‚åœéå…³é”®å‘å¸ƒï¼Œä¸“æ³¨ç¨³å®šæ€§"
```

---

## 5. Alertmanager é…ç½®

### 5.1 è·¯ç”±é…ç½®

```yaml
# alertmanager.yml
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

route:
  receiver: 'default'
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  
  routes:
  # 1. Critical å‘Šè­¦ â†’ PagerDuty
  - match:
      severity: critical
    receiver: 'pagerduty'
    continue: true
  
  # 2. æŒ‰å›¢é˜Ÿè·¯ç”±
  - match:
      team: backend
    receiver: 'team-backend'
    routes:
    - match:
        severity: critical
      receiver: 'pagerduty-backend'
  
  - match:
      team: observability
    receiver: 'team-observability'
  
  # 3. SLO å‘Šè­¦ç‰¹æ®Šå¤„ç†
  - match_re:
      slo: .+
    receiver: 'slo-team'
    group_by: ['slo']

receivers:
- name: 'default'
  slack_configs:
  - channel: '#alerts'
    title: '{{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

- name: 'pagerduty'
  pagerduty_configs:
  - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
    description: '{{ .GroupLabels.alertname }}'

- name: 'team-backend'
  slack_configs:
  - channel: '#team-backend-alerts'

- name: 'team-observability'
  slack_configs:
  - channel: '#observability-alerts'
```

### 5.2 æŠ‘åˆ¶è§„åˆ™

```yaml
inhibit_rules:
# 1. èŠ‚ç‚¹å®•æœºæ—¶ï¼ŒæŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šæ‰€æœ‰ Pod å‘Šè­¦
- source_match:
    alertname: 'NodeDown'
  target_match_re:
    alertname: '.*'
  equal: ['node']

# 2. Collector å®•æœºæ—¶ï¼ŒæŠ‘åˆ¶æ•°æ®ä¸¢å¤±å‘Šè­¦
- source_match:
    alertname: 'CollectorDown'
  target_match:
    alertname: 'HighSpanDropRate'
  equal: ['instance']

# 3. åç«¯å­˜å‚¨æ•…éšœæ—¶ï¼ŒæŠ‘åˆ¶å¯¼å‡ºå¤±è´¥å‘Šè­¦
- source_match:
    alertname: 'JaegerDown'
  target_match:
    alertname: 'HighExportFailureRate'
```

### 5.3 é™é»˜è§„åˆ™

```yaml
# é€šè¿‡ API åˆ›å»ºé™é»˜
# amtool silence add alertname=HighCPUUsage --duration=2h --comment="ç»´æŠ¤çª—å£"

# æˆ–é€šè¿‡é…ç½®æ–‡ä»¶ï¼ˆä¸æ¨èï¼Œå»ºè®®ç”¨ APIï¼‰
silences:
- matchers:
  - name: alertname
    value: HighCPUUsage
  startsAt: 2025-10-05T00:00:00Z
  endsAt: 2025-10-05T02:00:00Z
  createdBy: ops-team
  comment: "è®¡åˆ’ç»´æŠ¤çª—å£"
```

### 5.4 é«˜å¯ç”¨é…ç½®

```yaml
# Alertmanager é›†ç¾¤é…ç½®
alertmanager:
  cluster:
    listen-address: "0.0.0.0:9094"
    peers:
    - alertmanager-0.alertmanager:9094
    - alertmanager-1.alertmanager:9094
    - alertmanager-2.alertmanager:9094
```

---

## 6. é€šçŸ¥æ¸ é“é›†æˆ

### 6.1 PagerDuty é›†æˆ

```yaml
receivers:
- name: 'pagerduty-critical'
  pagerduty_configs:
  - service_key: 'YOUR_SERVICE_KEY'
    description: |
      {{ .GroupLabels.alertname }}
      {{ range .Alerts }}
      - {{ .Annotations.summary }}
      {{ end }}
    details:
      firing: '{{ .Alerts.Firing | len }}'
      resolved: '{{ .Alerts.Resolved | len }}'
      runbook: '{{ .CommonAnnotations.runbook_url }}'
    severity: '{{ .CommonLabels.severity }}'
```

### 6.2 Slack é›†æˆ

```yaml
receivers:
- name: 'slack-alerts'
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
    channel: '#alerts'
    username: 'Prometheus'
    icon_emoji: ':prometheus:'
    title: '{{ .GroupLabels.alertname }}'
    text: |
      {{ range .Alerts }}
      *Alert:* {{ .Labels.alertname }}
      *Severity:* {{ .Labels.severity }}
      *Summary:* {{ .Annotations.summary }}
      *Description:* {{ .Annotations.description }}
      *Runbook:* {{ .Annotations.runbook_url }}
      {{ end }}
    actions:
    - type: button
      text: 'Runbook :book:'
      url: '{{ .CommonAnnotations.runbook_url }}'
    - type: button
      text: 'Dashboard :chart_with_upwards_trend:'
      url: '{{ .CommonAnnotations.dashboard_url }}'
    - type: button
      text: 'Silence :no_bell:'
      url: '{{ .ExternalURL }}/#/silences/new?filter=%7B'
```

### 6.3 ä¼ä¸šå¾®ä¿¡é›†æˆ

```yaml
receivers:
- name: 'wechat-alerts'
  wechat_configs:
  - corp_id: 'YOUR_CORP_ID'
    agent_id: 'YOUR_AGENT_ID'
    api_secret: 'YOUR_API_SECRET'
    to_user: '@all'
    message: |
      {{ range .Alerts }}
      å‘Šè­¦åç§°: {{ .Labels.alertname }}
      å‘Šè­¦çº§åˆ«: {{ .Labels.severity }}
      å‘Šè­¦æ‘˜è¦: {{ .Annotations.summary }}
      å‘Šè­¦è¯¦æƒ…: {{ .Annotations.description }}
      {{ end }}
```

### 6.4 Email é›†æˆ

```yaml
receivers:
- name: 'email-alerts'
  email_configs:
  - to: 'oncall@example.com'
    from: 'alertmanager@example.com'
    smarthost: 'smtp.example.com:587'
    auth_username: 'alertmanager@example.com'
    auth_password: 'YOUR_PASSWORD'
    headers:
      Subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
    html: |
      <h2>{{ .GroupLabels.alertname }}</h2>
      <table>
      {{ range .Alerts }}
        <tr><td>Severity:</td><td>{{ .Labels.severity }}</td></tr>
        <tr><td>Summary:</td><td>{{ .Annotations.summary }}</td></tr>
        <tr><td>Description:</td><td>{{ .Annotations.description }}</td></tr>
      {{ end }}
      </table>
```

---

## 7. Grafana Dashboard

### 7.1 Overview Dashboard

#### 7.1.1 Dashboard è®¾è®¡

**æ ¸å¿ƒæŒ‡æ ‡**:

- æ€» QPS
- æ€»é”™è¯¯ç‡
- P99 å»¶è¿Ÿ
- Collector å¥åº·çŠ¶æ€
- åç«¯å­˜å‚¨çŠ¶æ€

**Dashboard JSON**ï¼ˆç®€åŒ–ç‰ˆï¼‰:

```json
{
  "dashboard": {
    "title": "OTLP Overview",
    "panels": [
      {
        "id": 1,
        "title": "Total QPS",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m]))"
          }
        ]
      },
      {
        "id": 2,
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m]))"
          }
        ]
      },
      {
        "id": 3,
        "title": "P99 Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))"
          }
        ]
      }
    ]
  }
}
```

### 7.2 Application Dashboard

#### 7.2.1 RED æŒ‡æ ‡é¢æ¿

**Panel é…ç½®**:

```json
{
  "panels": [
    {
      "title": "Request Rate by Service",
      "targets": [
        {
          "expr": "sum(rate(http_requests_total[5m])) by (service)",
          "legendFormat": "{{ service }}"
        }
      ],
      "yaxes": [
        {
          "format": "reqps",
          "label": "Requests/sec"
        }
      ]
    },
    {
      "title": "Error Rate by Service",
      "targets": [
        {
          "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service)",
          "legendFormat": "{{ service }}"
        }
      ],
      "yaxes": [
        {
          "format": "percentunit",
          "max": 1,
          "min": 0
        }
      ]
    },
    {
      "title": "Latency Percentiles",
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service))",
          "legendFormat": "{{ service }} P50"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service))",
          "legendFormat": "{{ service }} P95"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service))",
          "legendFormat": "{{ service }} P99"
        }
      ]
    }
  ]
}
```

### 7.3 Collector Dashboard

#### 7.3.1 æ•°æ®æµé¢æ¿

```json
{
  "panels": [
    {
      "title": "Span Flow",
      "targets": [
        {
          "expr": "sum(rate(otelcol_receiver_accepted_spans[5m])) by (instance)",
          "legendFormat": "{{ instance }} Received"
        },
        {
          "expr": "sum(rate(otelcol_exporter_sent_spans[5m])) by (instance)",
          "legendFormat": "{{ instance }} Sent"
        },
        {
          "expr": "sum(rate(otelcol_processor_dropped_spans[5m])) by (instance)",
          "legendFormat": "{{ instance }} Dropped"
        }
      ]
    },
    {
      "title": "Queue Utilization",
      "targets": [
        {
          "expr": "otelcol_exporter_queue_size / otelcol_exporter_queue_capacity",
          "legendFormat": "{{ instance }}"
        }
      ],
      "thresholds": [
        {
          "value": 0.8,
          "color": "orange"
        },
        {
          "value": 0.9,
          "color": "red"
        }
      ]
    }
  ]
}
```

### 7.4 Backend Dashboard

#### 7.4.1 Jaeger é¢æ¿

```json
{
  "panels": [
    {
      "title": "Jaeger Query Latency",
      "targets": [
        {
          "expr": "histogram_quantile(0.99, rate(jaeger_query_requests_duration_seconds_bucket[5m]))",
          "legendFormat": "P99"
        }
      ]
    },
    {
      "title": "Jaeger Storage Usage",
      "targets": [
        {
          "expr": "jaeger_storage_used_bytes / jaeger_storage_capacity_bytes",
          "legendFormat": "Usage %"
        }
      ]
    }
  ]
}
```

---

## 8. SLO/SLI å®šä¹‰

### 8.1 å¯è§‚æµ‹æ€§ç³»ç»Ÿ SLO

#### 8.1.1 SLO å®šä¹‰

| SLO | ç›®æ ‡ | æµ‹é‡çª—å£ | è¯´æ˜ |
|-----|------|---------|------|
| **å¯ç”¨æ€§** | 99.9% | 30 å¤© | ç³»ç»Ÿæ­£å¸¸æ¥æ”¶å’Œå¤„ç†æ•°æ® |
| **æ•°æ®å®Œæ•´æ€§** | 99.99% | 7 å¤© | æ•°æ®æ— ä¸¢å¤± |
| **æŸ¥è¯¢å»¶è¿Ÿ** | P99 < 10s | 7 å¤© | Trace æŸ¥è¯¢å“åº”æ—¶é—´ |
| **ç«¯åˆ°ç«¯å»¶è¿Ÿ** | P99 < 60s | 7 å¤© | ä» Span ç”Ÿæˆåˆ°å¯æŸ¥è¯¢ |

#### 8.1.2 SLI è®¡ç®—

**å¯ç”¨æ€§ SLI**:

```promql
# å¯ç”¨æ€§ = 1 - é”™è¯¯ç‡
1 - (
  sum(rate(http_requests_total{status=~"5.."}[30d]))
  /
  sum(rate(http_requests_total[30d]))
)
```

**æ•°æ®å®Œæ•´æ€§ SLI**:

```promql
# å®Œæ•´æ€§ = 1 - ä¸¢å¤±ç‡
1 - (
  sum(rate(otelcol_processor_dropped_spans[7d]))
  /
  sum(rate(otelcol_processor_accepted_spans[7d]))
)
```

**æŸ¥è¯¢å»¶è¿Ÿ SLI**:

```promql
# P99 æŸ¥è¯¢å»¶è¿Ÿ
histogram_quantile(0.99,
  rate(jaeger_query_requests_duration_seconds_bucket[7d])
)
```

### 8.2 Error Budget ç®¡ç†

#### 8.2.1 Error Budget è®¡ç®—

**30 å¤© Error Budget**:

```text
SLO: 99.9% å¯ç”¨æ€§
å…è®¸çš„é”™è¯¯ç‡: 0.1%
30 å¤©æ€»è¯·æ±‚: 100 äº¿
å…è®¸çš„é”™è¯¯è¯·æ±‚: 1000 ä¸‡
```

**Error Budget æŸ¥è¯¢**:

```promql
# å‰©ä½™ Error Budget
(
  0.001 - (
    sum(rate(http_requests_total{status=~"5.."}[30d]))
    /
    sum(rate(http_requests_total[30d]))
  )
) / 0.001
```

#### 8.2.2 Error Budget ç­–ç•¥

| Error Budget å‰©ä½™ | ç­–ç•¥ |
|------------------|------|
| > 50% | æ­£å¸¸å‘å¸ƒï¼Œå¯è¿›è¡Œå®éªŒ |
| 20-50% | è°¨æ…å‘å¸ƒï¼Œå‡å°‘é£é™©å˜æ›´ |
| 5-20% | å†»ç»“éå…³é”®å‘å¸ƒï¼Œä¸“æ³¨ç¨³å®šæ€§ |
| < 5% | å®Œå…¨å†»ç»“å‘å¸ƒï¼Œç´§æ€¥ä¿®å¤ |

### 8.3 SLI è®¡ç®—æ–¹æ³•

#### 8.3.1 åŸºäºè¯·æ±‚çš„ SLI

```promql
# æˆåŠŸç‡ SLI
sum(rate(http_requests_total{status!~"5.."}[30d]))
/
sum(rate(http_requests_total[30d]))
```

#### 8.3.2 åŸºäºæ—¶é—´çª—å£çš„ SLI

```promql
# å¯ç”¨æ—¶é—´æ¯”ä¾‹
(
  count_over_time(up{job="otel-collector"}[30d])
  -
  count_over_time((up{job="otel-collector"} == 0)[30d])
)
/
count_over_time(up{job="otel-collector"}[30d])
```

### 8.4 SLO å‘Šè­¦ç­–ç•¥

#### 8.4.1 å¤šçª—å£å¤šç‡ƒçƒ§ç‡å‘Šè­¦

```yaml
# å¿«é€Ÿç‡ƒçƒ§ï¼ˆ1 å°æ—¶çª—å£ï¼‰
- alert: ErrorBudgetBurnRateFast
  expr: |
    (
      1 - (
        sum(rate(http_requests_total{status!~"5.."}[1h]))
        /
        sum(rate(http_requests_total[1h]))
      )
    ) > 14.4 * 0.001  # 14.4x ç‡ƒçƒ§ç‡
  for: 2m
  labels:
    severity: critical
  annotations:
    summary: "Error Budget å¿«é€Ÿç‡ƒçƒ§ï¼ˆ1 å°æ—¶å†…è€—å°½ 2% Budgetï¼‰"

# æ…¢é€Ÿç‡ƒçƒ§ï¼ˆ6 å°æ—¶çª—å£ï¼‰
- alert: ErrorBudgetBurnRateSlow
  expr: |
    (
      1 - (
        sum(rate(http_requests_total{status!~"5.."}[6h]))
        /
        sum(rate(http_requests_total[6h]))
      )
    ) > 6 * 0.001  # 6x ç‡ƒçƒ§ç‡
  for: 15m
  labels:
    severity: warning
  annotations:
    summary: "Error Budget æ…¢é€Ÿç‡ƒçƒ§ï¼ˆ6 å°æ—¶å†…è€—å°½ 2% Budgetï¼‰"
```

---

## 9. è‡ªåŠ¨åŒ–å“åº”

### 9.1 è‡ªåŠ¨æ‰©å®¹

#### 9.1.1 HPA é…ç½®ï¼ˆKubernetesï¼‰

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: otel-collector-hpa
  namespace: observability
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: otel-collector
  minReplicas: 3
  maxReplicas: 10
  metrics:
  # 1. åŸºäº CPU
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  
  # 2. åŸºäºå†…å­˜
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
  # 3. åŸºäºè‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆé˜Ÿåˆ—é•¿åº¦ï¼‰
  - type: Pods
    pods:
      metric:
        name: otelcol_exporter_queue_size
      target:
        type: AverageValue
        averageValue: "5000"
  
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 1
        periodSeconds: 60
```

#### 9.1.2 KEDA æ‰©å®¹ï¼ˆåŸºäº Prometheus æŒ‡æ ‡ï¼‰

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: otel-collector-scaler
spec:
  scaleTargetRef:
    name: otel-collector
  minReplicaCount: 3
  maxReplicaCount: 20
  triggers:
  # åŸºäº Span æ¥æ”¶é€Ÿç‡
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: otelcol_receiver_accepted_spans
      query: |
        sum(rate(otelcol_receiver_accepted_spans[1m]))
      threshold: "50000"  # æ¯ç§’ 5 ä¸‡ Span æ—¶æ‰©å®¹
```

### 9.2 è‡ªåŠ¨é™çº§

#### 9.2.1 åŠ¨æ€é‡‡æ ·ç‡è°ƒæ•´

```go
package autoscale

import (
    "context"
    "time"
    
    "github.com/prometheus/client_golang/api"
    v1 "github.com/prometheus/client_golang/api/prometheus/v1"
)

type SamplingRateAdjuster struct {
    promAPI   v1.API
    targetQPS int64
}

func (a *SamplingRateAdjuster) AdjustSamplingRate(ctx context.Context) {
    // 1. æŸ¥è¯¢å½“å‰ Span é€Ÿç‡
    result, _ := a.promAPI.Query(ctx, 
        "sum(rate(otelcol_receiver_accepted_spans[5m]))", 
        time.Now(),
    )
    
    currentRate := extractValue(result)
    
    // 2. è®¡ç®—æ–°çš„é‡‡æ ·ç‡
    var newSamplingRate float64
    if currentRate > float64(a.targetQPS) {
        newSamplingRate = float64(a.targetQPS) / currentRate
    } else {
        newSamplingRate = 1.0
    }
    
    // 3. é€šè¿‡ OPAMP ä¸‹å‘æ–°é…ç½®
    a.updateCollectorConfig(newSamplingRate)
}
```

#### 9.2.2 ç†”æ–­é™çº§

```go
package circuitbreaker

import (
    "sync"
    "time"
)

type CircuitBreaker struct {
    mu              sync.RWMutex
    failureCount    int
    failureThreshold int
    state           State
    lastFailureTime time.Time
}

type State int

const (
    StateClosed State = iota
    StateOpen
    StateHalfOpen
)

func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.RLock()
    state := cb.state
    cb.mu.RUnlock()
    
    if state == StateOpen {
        // ç†”æ–­çŠ¶æ€ï¼Œç›´æ¥æ‹’ç»
        if time.Since(cb.lastFailureTime) > 30*time.Second {
            cb.mu.Lock()
            cb.state = StateHalfOpen
            cb.mu.Unlock()
        } else {
            return ErrCircuitOpen
        }
    }
    
    err := fn()
    
    if err != nil {
        cb.onFailure()
    } else {
        cb.onSuccess()
    }
    
    return err
}
```

### 9.3 è‡ªåŠ¨ä¿®å¤

#### 9.3.1 è‡ªåŠ¨é‡å¯ Pod

```yaml
# Kubernetes Liveness Probe
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
spec:
  template:
    spec:
      containers:
      - name: otel-collector
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 10
          periodSeconds: 5
```

#### 9.3.2 è‡ªåŠ¨æ¸…ç†ç£ç›˜

```bash
#!/bin/bash
# disk-cleanup.sh

THRESHOLD=85  # ç£ç›˜ä½¿ç”¨ç‡é˜ˆå€¼

while true; do
    USAGE=$(df -h /var/lib/otelcol | tail -1 | awk '{print $5}' | sed 's/%//')
    
    if [ $USAGE -gt $THRESHOLD ]; then
        echo "Disk usage $USAGE% exceeds threshold $THRESHOLD%, cleaning up..."
        
        # åˆ é™¤ 7 å¤©å‰çš„æ—¥å¿—
        find /var/lib/otelcol/logs -type f -mtime +7 -delete
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        rm -rf /var/lib/otelcol/tmp/*
    fi
    
    sleep 300  # æ¯ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
done
```

### 9.4 äº‹ä»¶ç®¡ç†

#### 9.4.1 PagerDuty äº‹ä»¶åˆ›å»º

```go
package incident

import (
    "github.com/PagerDuty/go-pagerduty"
)

func CreateIncident(summary, severity string) error {
    client := pagerduty.NewClient("YOUR_API_KEY")
    
    incident := pagerduty.CreateIncidentOptions{
        Type:  "incident",
        Title: summary,
        Service: &pagerduty.APIReference{
            ID:   "SERVICE_ID",
            Type: "service_reference",
        },
        Urgency: severity,
        Body: &pagerduty.APIDetails{
            Type:    "incident_body",
            Details: "Automated incident from monitoring system",
        },
    }
    
    _, err := client.CreateIncidentWithContext(context.Background(), "FROM_EMAIL", &incident)
    return err
}
```

---

## 10. æœ€ä½³å®è·µ

### 10.1 å‘Šè­¦è®¾è®¡åŸåˆ™

#### 10.1.1 SMART åŸåˆ™

- **Specificï¼ˆå…·ä½“ï¼‰**: å‘Šè­¦æè¿°æ¸…æ™°ï¼ŒåŒ…å«å…·ä½“æŒ‡æ ‡å€¼
- **Measurableï¼ˆå¯æµ‹é‡ï¼‰**: åŸºäºå¯é‡åŒ–çš„æŒ‡æ ‡
- **Actionableï¼ˆå¯æ“ä½œï¼‰**: æä¾›æ˜ç¡®çš„å¤„ç†æ­¥éª¤
- **Relevantï¼ˆç›¸å…³ï¼‰**: ä¸ä¸šåŠ¡ç›®æ ‡ç›¸å…³
- **Time-boundï¼ˆæœ‰æ—¶é™ï¼‰**: è®¾ç½®åˆç†çš„è§¦å‘æ—¶é—´

**ç¤ºä¾‹**:

```yaml
# å¥½çš„å‘Šè­¦
- alert: HighErrorRate
  expr: error_rate > 0.05
  for: 2m
  annotations:
    summary: "æœåŠ¡ {{ $labels.service }} é”™è¯¯ç‡è¿‡é«˜"
    description: "é”™è¯¯ç‡: {{ $value | humanizePercentage }}"
    action: "1. æ£€æŸ¥æ—¥å¿— 2. æŸ¥çœ‹ Trace 3. å›æ»šæœ€è¿‘å‘å¸ƒ"
    runbook: "https://wiki.example.com/runbooks/high-error-rate"

# ä¸å¥½çš„å‘Šè­¦
- alert: SomethingWrong
  expr: some_metric > 100
  annotations:
    summary: "Something is wrong"
```

#### 10.1.2 å‘Šè­¦åˆ†çº§

| çº§åˆ« | è¯´æ˜ | å“åº”æ—¶é—´ | é€šçŸ¥æ–¹å¼ |
|-----|------|---------|---------|
| **Critical** | å½±å“ç”¨æˆ·ï¼Œéœ€ç«‹å³å¤„ç† | < 5 åˆ†é’Ÿ | PagerDuty + ç”µè¯ |
| **Warning** | æ½œåœ¨é—®é¢˜ï¼Œéœ€å…³æ³¨ | < 30 åˆ†é’Ÿ | Slack |
| **Info** | ä¿¡æ¯é€šçŸ¥ | å·¥ä½œæ—¶é—´å†… | Email |

### 10.2 å‘Šè­¦ç–²åŠ³é¢„é˜²

#### 10.2.1 å‡å°‘å™ªéŸ³

**ç­–ç•¥**:

1. **æé«˜é˜ˆå€¼**: ä»…å‘Šè­¦çœŸæ­£é‡è¦çš„é—®é¢˜
2. **å¢åŠ  for æ—¶é—´**: é¿å…ç¬æ—¶æŠ–åŠ¨
3. **ä½¿ç”¨æŠ‘åˆ¶è§„åˆ™**: é¿å…çº§è”å‘Šè­¦
4. **å®šæœŸå®¡æŸ¥**: åˆ é™¤æ— ç”¨å‘Šè­¦

**ç¤ºä¾‹**:

```yaml
# é¿å…æŠ–åŠ¨
- alert: HighCPU
  expr: cpu_usage > 0.8
  for: 10m  # æŒç»­ 10 åˆ†é’Ÿæ‰å‘Šè­¦
  
# ä½¿ç”¨æŠ‘åˆ¶
inhibit_rules:
- source_match:
    alertname: 'ServiceDown'
  target_match:
    alertname: 'HighErrorRate'
  equal: ['service']
```

#### 10.2.2 å‘Šè­¦èšåˆ

```yaml
# Alertmanager èšåˆé…ç½®
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s        # ç­‰å¾… 30 ç§’æ”¶é›†åŒç»„å‘Šè­¦
  group_interval: 5m     # æ¯ 5 åˆ†é’Ÿå‘é€ä¸€æ¬¡èšåˆå‘Šè­¦
  repeat_interval: 12h   # 12 å°æ—¶åé‡å¤å‘é€
```

### 10.3 å€¼ç­è½®æ¢

#### 10.3.1 å€¼ç­è¡¨ç®¡ç†

```yaml
# PagerDuty Schedule
schedules:
- name: "Primary On-Call"
  time_zone: "America/New_York"
  layers:
  - start: "2025-10-01T00:00:00"
    rotation_virtual_start: "2025-10-01T00:00:00"
    rotation_turn_length_seconds: 604800  # 1 å‘¨
    users:
    - user: "USER1_ID"
    - user: "USER2_ID"
    - user: "USER3_ID"
```

#### 10.3.2 å€¼ç­äº¤æ¥

**äº¤æ¥æ¸…å•**:

- [ ] å½“å‰å‘Šè­¦çŠ¶æ€
- [ ] è¿›è¡Œä¸­çš„äº‹ä»¶
- [ ] è®¡åˆ’çš„ç»´æŠ¤çª—å£
- [ ] å·²çŸ¥é—®é¢˜
- [ ] è¿‘æœŸå˜æ›´

### 10.4 äº‹åå¤ç›˜

#### 10.4.1 äº‹ä»¶æŠ¥å‘Šæ¨¡æ¿

```markdown
# äº‹ä»¶æŠ¥å‘Š - [äº‹ä»¶æ ‡é¢˜]

## åŸºæœ¬ä¿¡æ¯
- **äº‹ä»¶ ID**: INC-2025-001
- **å‘ç”Ÿæ—¶é—´**: 2025-10-04 14:30 UTC
- **æ¢å¤æ—¶é—´**: 2025-10-04 15:15 UTC
- **æŒç»­æ—¶é—´**: 45 åˆ†é’Ÿ
- **å½±å“èŒƒå›´**: æ”¯ä»˜æœåŠ¡ï¼Œ5% ç”¨æˆ·å—å½±å“

## æ—¶é—´çº¿
- 14:30: å‘Šè­¦è§¦å‘ï¼ˆHighErrorRateï¼‰
- 14:32: å€¼ç­å·¥ç¨‹å¸ˆå“åº”
- 14:35: ç¡®è®¤é—®é¢˜ï¼ˆæ•°æ®åº“è¿æ¥æ± è€—å°½ï¼‰
- 14:40: æ‰©å®¹æ•°æ®åº“è¿æ¥æ± 
- 15:00: é”™è¯¯ç‡æ¢å¤æ­£å¸¸
- 15:15: ç¡®è®¤å®Œå…¨æ¢å¤

## æ ¹å› åˆ†æ
- **ç›´æ¥åŸå› **: æ•°æ®åº“è¿æ¥æ± é…ç½®è¿‡å°ï¼ˆmax_connections=50ï¼‰
- **æ ¹æœ¬åŸå› **: æµé‡å¢é•¿æœªåŠæ—¶è°ƒæ•´é…ç½®
- **è§¦å‘å› ç´ **: ä¿ƒé”€æ´»åŠ¨å¯¼è‡´æµé‡å¢é•¿ 3x

## å½±å“è¯„ä¼°
- **ç”¨æˆ·å½±å“**: 5% ç”¨æˆ·æ”¯ä»˜å¤±è´¥
- **è´¢åŠ¡å½±å“**: é¢„è®¡æŸå¤± $10,000
- **SLO å½±å“**: æ¶ˆè€— 2% Error Budget

## è¡ŒåŠ¨é¡¹
- [ ] å¢å¤§æ•°æ®åº“è¿æ¥æ± ï¼ˆmax_connections=200ï¼‰[@owner, 2025-10-05]
- [ ] æ·»åŠ è¿æ¥æ± ä½¿ç”¨ç‡ç›‘æ§ [@owner, 2025-10-06]
- [ ] å»ºç«‹å®¹é‡è§„åˆ’æµç¨‹ [@owner, 2025-10-10]
- [ ] æ›´æ–° Runbook [@owner, 2025-10-07]

## ç»éªŒæ•™è®­
- **åšå¾—å¥½**: å¿«é€Ÿå“åº”ï¼Œ45 åˆ†é’Ÿå†…æ¢å¤
- **éœ€æ”¹è¿›**: ç¼ºå°‘å®¹é‡è§„åˆ’ï¼Œæœªæå‰å‘ç°ç“¶é¢ˆ
```

#### 10.4.2 æ”¹è¿›æªæ–½è·Ÿè¸ª

```yaml
# Jira/GitHub Issues
- title: "å¢å¤§æ•°æ®åº“è¿æ¥æ± é…ç½®"
  assignee: "backend-team"
  due_date: "2025-10-05"
  priority: "High"
  labels: ["incident-followup", "INC-2025-001"]
```

---

## 11. å‚è€ƒæ–‡çŒ®

- Prometheus Documentation: <https://prometheus.io/docs/>
- Alertmanager Documentation: <https://prometheus.io/docs/alerting/latest/alertmanager/>
- Grafana Documentation: <https://grafana.com/docs/>
- SRE Book - Monitoring Distributed Systems: <https://sre.google/sre-book/monitoring-distributed-systems/>
- SRE Workbook - Alerting on SLOs: <https://sre.google/workbook/alerting-on-slos/>
- PagerDuty Incident Response: <https://response.pagerduty.com/>

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ - 12,000+ å­—ï¼Œå®Œæ•´ç›‘æ§å‘Šè­¦æ–¹æ¡ˆ

---

## 11. å‚è€ƒæ–‡çŒ®1

- Prometheus Documentation: <https://prometheus.io/docs/>
- Alertmanager Documentation: <https://prometheus.io/docs/alerting/latest/alertmanager/>
- Grafana Documentation: <https://grafana.com/docs/>
- SRE Book - Monitoring Distributed Systems: <https://sre.google/sre-book/monitoring-distributed-systems/>

---

**æ–‡æ¡£çŠ¶æ€**: ğŸš§ ç¬¬ 1 æ‰¹å†…å®¹å·²å®Œæˆï¼Œç»§ç»­è¡¥å……ä¸­...

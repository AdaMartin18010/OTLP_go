# eBPF Profiling é›†æˆæ·±åº¦åˆ†æ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **åˆ›å»ºæ—¥æœŸ**: 2025-10-03  
> **ä½œè€…**: OTLP Ã— Golang CSP æŠ€æœ¯ä½“ç³»ç ”ç©¶ç»„  
> **å…³è”æ–‡æ¡£**: [Golang CSP](./01-golang-1.25.1-csp-comprehensive-analysis.md) | [OTLP è¯­ä¹‰](./02-otlp-semantic-conventions-resource-model.md)

---

## ğŸ“‹ ç›®å½•

- [eBPF Profiling é›†æˆæ·±åº¦åˆ†æ](#ebpf-profiling-é›†æˆæ·±åº¦åˆ†æ)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. eBPF æŠ€æœ¯æ¦‚è§ˆ](#1-ebpf-æŠ€æœ¯æ¦‚è§ˆ)
    - [1.1 eBPF æ¶æ„](#11-ebpf-æ¶æ„)
    - [1.2 æ ¸å¿ƒä¼˜åŠ¿](#12-æ ¸å¿ƒä¼˜åŠ¿)
    - [1.3 Go è¯­è¨€ç‰¹æ®Šæ€§](#13-go-è¯­è¨€ç‰¹æ®Šæ€§)
  - [2. Go è¿è¡Œæ—¶ä¸ eBPF](#2-go-è¿è¡Œæ—¶ä¸-ebpf)
    - [2.1 Goroutine è°ƒåº¦è¿½è¸ª](#21-goroutine-è°ƒåº¦è¿½è¸ª)
    - [2.2 ç¬¦å·è§£æ](#22-ç¬¦å·è§£æ)
  - [3. CPU Profiling](#3-cpu-profiling)
    - [3.1 é‡‡æ ·åŸç†](#31-é‡‡æ ·åŸç†)
    - [3.2 On-CPU vs Off-CPU](#32-on-cpu-vs-off-cpu)
  - [4. å†…å­˜ Profiling](#4-å†…å­˜-profiling)
    - [4.1 å †åˆ†é…è¿½è¸ª](#41-å †åˆ†é…è¿½è¸ª)
    - [4.2 GC æ€§èƒ½åˆ†æ](#42-gc-æ€§èƒ½åˆ†æ)
  - [5. ç½‘ç»œè¿½è¸ª](#5-ç½‘ç»œè¿½è¸ª)
    - [5.1 TCP è¿æ¥è¿½è¸ª](#51-tcp-è¿æ¥è¿½è¸ª)
    - [5.2 HTTP è¯·æ±‚è¿½è¸ª](#52-http-è¯·æ±‚è¿½è¸ª)
  - [6. Goroutine è°ƒåº¦åˆ†æ](#6-goroutine-è°ƒåº¦åˆ†æ)
    - [6.1 è°ƒåº¦å»¶è¿Ÿ](#61-è°ƒåº¦å»¶è¿Ÿ)
    - [6.2 Channel æ“ä½œåˆ†æ](#62-channel-æ“ä½œåˆ†æ)
  - [7. eBPF å·¥å…·é“¾](#7-ebpf-å·¥å…·é“¾)
    - [7.1 BCC (BPF Compiler Collection)](#71-bcc-bpf-compiler-collection)
    - [7.2 libbpf-go](#72-libbpf-go)
    - [7.3 Pixie (è‡ªåŠ¨åŒ– eBPF)](#73-pixie-è‡ªåŠ¨åŒ–-ebpf)
  - [8. æ€§èƒ½å¼€é”€åˆ†æ](#8-æ€§èƒ½å¼€é”€åˆ†æ)
    - [8.1 å¼€é”€å¯¹æ¯”](#81-å¼€é”€å¯¹æ¯”)
    - [8.2 ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ](#82-ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ)
  - [9. OTLP é›†æˆ](#9-otlp-é›†æˆ)
    - [9.1 Profile ä¿¡å·æ ¼å¼](#91-profile-ä¿¡å·æ ¼å¼)
    - [9.2 eBPF â†’ OTLP æ¡¥æ¥](#92-ebpf--otlp-æ¡¥æ¥)
    - [9.3 å…³è” Trace ä¸ Profile](#93-å…³è”-trace-ä¸-profile)
  - [10. å®æˆ˜æ¡ˆä¾‹](#10-å®æˆ˜æ¡ˆä¾‹)
    - [10.1 è¯Šæ–­ Goroutine æ³„æ¼](#101-è¯Šæ–­-goroutine-æ³„æ¼)
    - [10.2 ä¼˜åŒ– Channel é˜»å¡](#102-ä¼˜åŒ–-channel-é˜»å¡)
    - [10.3 GC è°ƒä¼˜](#103-gc-è°ƒä¼˜)
  - [ğŸ“Š å·¥å…·å¯¹æ¯”æ€»ç»“](#-å·¥å…·å¯¹æ¯”æ€»ç»“)
  - [ğŸ¯ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
  - [ğŸ“š å‚è€ƒèµ„æ–™](#-å‚è€ƒèµ„æ–™)
  - [ğŸ”— ç›¸å…³æ–‡æ¡£](#-ç›¸å…³æ–‡æ¡£)

---

## 1. eBPF æŠ€æœ¯æ¦‚è§ˆ

### 1.1 eBPF æ¶æ„

```mermaid
graph TB
    A[User Space Application] -->|System Call| B[Kernel Space]
    B --> C[eBPF Program]
    C --> D[eBPF Verifier]
    D --> E[JIT Compiler]
    E --> F[eBPF Maps]
    F -->|Read| A
    
    C --> G[Kprobes]
    C --> H[Uprobes]
    C --> I[Tracepoints]
    
    style C fill:#00ff00
    style F fill:#ffcc00
```

### 1.2 æ ¸å¿ƒä¼˜åŠ¿

| ç‰¹æ€§ | ä¼ ç»Ÿæ–¹æ³• | eBPF |
|------|----------|------|
| **æ€§èƒ½å¼€é”€** | 5-20% | < 1% |
| **ä»£ç ä¾µå…¥** | éœ€è¦ä¿®æ”¹åº”ç”¨ | é›¶ä¾µå…¥ |
| **å®‰å…¨æ€§** | å†…æ ¸æ¨¡å—é£é™© | æ²™ç®±éªŒè¯ |
| **åŠ¨æ€æ€§** | é‡æ–°ç¼–è¯‘éƒ¨ç½² | åŠ¨æ€æ³¨å…¥ |
| **å¯ç§»æ¤æ€§** | å¹³å°ç›¸å…³ | è·¨å†…æ ¸ç‰ˆæœ¬ |

### 1.3 Go è¯­è¨€ç‰¹æ®Šæ€§

**æŒ‘æˆ˜**:

1. **Goroutine æŠ½è±¡**: é 1:1 çº¿ç¨‹æ˜ å°„
2. **æ ˆç®¡ç†**: åŠ¨æ€å¢é•¿çš„æ ˆ
3. **ç¬¦å·è¡¨**: éœ€è¦ DWARF ä¿¡æ¯
4. **GC å¹²æ‰°**: éœ€è¦åŒºåˆ† GC æ—¶é—´

---

## 2. Go è¿è¡Œæ—¶ä¸ eBPF

### 2.1 Goroutine è°ƒåº¦è¿½è¸ª

**GMP æ¨¡å‹ç›‘æ§**:

```c
// eBPF ç¨‹åº: è¿½è¸ª Goroutine è°ƒåº¦
#include <uapi/linux/ptrace.h>

struct sched_event {
    u64 timestamp;
    u32 pid;
    u32 goid;      // Goroutine ID
    u32 mid;       // Machine (OS Thread) ID
    u32 pid_new;   // Processor ID
    char comm[16];
};

BPF_HASH(goroutines, u32, struct sched_event);
BPF_PERF_OUTPUT(events);

// Hook: runtime.schedule()
int trace_schedule(struct pt_regs *ctx) {
    struct sched_event event = {};
    
    event.timestamp = bpf_ktime_get_ns();
    event.pid = bpf_get_current_pid_tgid() >> 32;
    
    // è¯»å– Goroutine ç»“æ„ä½“
    void *g_ptr = (void *)ctx->di;
    bpf_probe_read(&event.goid, sizeof(event.goid), g_ptr + 152);
    
    events.perf_submit(ctx, &event, sizeof(event));
    return 0;
}
```

**ç”¨æˆ·ç©ºé—´å¤„ç†**:

```go
import (
    "github.com/iovisor/gobpf/bcc"
)

type SchedEvent struct {
    Timestamp uint64
    PID       uint32
    GoroutineID uint32
    MachineID uint32
    ProcessorID uint32
}

func MonitorGoroutines() {
    module := bcc.NewModule(bpfCode, []string{})
    defer module.Close()
    
    uprobeFd, err := module.LoadUprobe("trace_schedule")
    if err != nil {
        panic(err)
    }
    
    err = module.AttachUprobe("/usr/bin/myapp", "runtime.schedule", uprobeFd, -1)
    if err != nil {
        panic(err)
    }
    
    table := bcc.NewTable(module.TableId("events"), module)
    channel := make(chan []byte)
    
    perfMap, err := bcc.InitPerfMap(table, channel, nil)
    if err != nil {
        panic(err)
    }
    
    go func() {
        for data := range channel {
            var event SchedEvent
            // è§£æäº‹ä»¶
            processSchedEvent(&event)
        }
    }()
    
    perfMap.Start()
    defer perfMap.Stop()
}
```

### 2.2 ç¬¦å·è§£æ

**è·å– Go ç¬¦å·è¡¨**:

```go
import (
    "debug/elf"
    "debug/gosym"
)

func LoadGoSymbols(binaryPath string) (*gosym.Table, error) {
    exe, err := elf.Open(binaryPath)
    if err != nil {
        return nil, err
    }
    defer exe.Close()
    
    // è¯»å– .gopclntab æ®µ
    pclnSection := exe.Section(".gopclntab")
    pclnData, _ := pclnSection.Data()
    
    // è¯»å– .gosymtab æ®µ
    symSection := exe.Section(".gosymtab")
    symData, _ := symSection.Data()
    
    // è§£æç¬¦å·è¡¨
    pcln := gosym.NewLineTable(pclnData, exe.Section(".text").Addr)
    table, err := gosym.NewTable(symData, pcln)
    
    return table, err
}

func ResolveGoroutineStack(pc uint64, table *gosym.Table) string {
    file, line, fn := table.PCToLine(pc)
    return fmt.Sprintf("%s:%d %s", file, line, fn.Name)
}
```

---

## 3. CPU Profiling

### 3.1 é‡‡æ ·åŸç†

**åŸºäº Perf Events**:

```c
// eBPF ç¨‹åº: CPU é‡‡æ ·
BPF_PERF_OUTPUT(stack_traces);
BPF_HASH(counts, struct key_t, u64);

struct key_t {
    u32 pid;
    int user_stack_id;
    int kernel_stack_id;
    char name[16];
};

int do_perf_event(struct bpf_perf_event_data *ctx) {
    u32 pid = bpf_get_current_pid_tgid() >> 32;
    
    struct key_t key = {};
    key.pid = pid;
    
    // æ•è·ç”¨æˆ·æ€æ ˆ
    key.user_stack_id = stack_traces.get_stackid(
        &ctx->regs, BPF_F_USER_STACK
    );
    
    // æ•è·å†…æ ¸æ€æ ˆ
    key.kernel_stack_id = stack_traces.get_stackid(
        &ctx->regs, 0
    );
    
    bpf_get_current_comm(&key.name, sizeof(key.name));
    
    // è®¡æ•°
    u64 zero = 0;
    u64 *val = counts.lookup_or_init(&key, &zero);
    (*val)++;
    
    return 0;
}
```

**ç«ç„°å›¾ç”Ÿæˆ**:

```go
type StackSample struct {
    PID        uint32
    ThreadName string
    UserStack  []uint64
    KernelStack []uint64
    Count      uint64
}

func GenerateFlameGraph(samples []StackSample, symTable *gosym.Table) string {
    var sb strings.Builder
    
    for _, sample := range samples {
        var stack []string
        
        // è§£æç”¨æˆ·æ€æ ˆ
        for _, pc := range sample.UserStack {
            if fn := symTable.LookupFunc(pc); fn != nil {
                stack = append(stack, fn.Name)
            }
        }
        
        // æŠ˜å æ ˆæ ¼å¼: func1;func2;func3 count
        sb.WriteString(strings.Join(stack, ";"))
        sb.WriteString(fmt.Sprintf(" %d\n", sample.Count))
    }
    
    return sb.String()
}
```

### 3.2 On-CPU vs Off-CPU

**On-CPU åˆ†æ**:

- æ•è·æ­£åœ¨æ‰§è¡Œçš„ä»£ç 
- å®šæ—¶å™¨ä¸­æ–­é‡‡æ ·

**Off-CPU åˆ†æ**:

```c
// è¿½è¸ªé˜»å¡æ—¶é—´
BPF_HASH(start, u32);

int trace_sched_switch(struct pt_regs *ctx, struct task_struct *prev) {
    u32 pid = prev->pid;
    u64 ts = bpf_ktime_get_ns();
    
    // è®°å½•å¼€å§‹é˜»å¡æ—¶é—´
    start.update(&pid, &ts);
    return 0;
}

int trace_sched_wakeup(struct pt_regs *ctx, struct task_struct *task) {
    u32 pid = task->pid;
    u64 *tsp = start.lookup(&pid);
    
    if (tsp != 0) {
        u64 delta = bpf_ktime_get_ns() - *tsp;
        // è®°å½•é˜»å¡æ—¶é•¿
        start.delete(&pid);
    }
    
    return 0;
}
```

---

## 4. å†…å­˜ Profiling

### 4.1 å †åˆ†é…è¿½è¸ª

**Hook malloc/mmap**:

```c
// è¿½è¸ª Go è¿è¡Œæ—¶åˆ†é…
#include <uapi/linux/ptrace.h>

struct alloc_info {
    u64 size;
    u64 timestamp;
    int user_stack_id;
};

BPF_HASH(allocs, u64, struct alloc_info);
BPF_STACK_TRACE(stack_traces, 10240);

// Hook: runtime.mallocgc
int trace_malloc(struct pt_regs *ctx) {
    u64 size = PT_REGS_PARM1(ctx);  // ç¬¬ä¸€ä¸ªå‚æ•°: size
    u64 addr = PT_REGS_RC(ctx);     // è¿”å›å€¼: åœ°å€
    
    struct alloc_info info = {};
    info.size = size;
    info.timestamp = bpf_ktime_get_ns();
    info.user_stack_id = stack_traces.get_stackid(ctx, BPF_F_USER_STACK);
    
    allocs.update(&addr, &info);
    return 0;
}

// Hook: runtime.gcStart (GC å¼€å§‹)
int trace_gc_start(struct pt_regs *ctx) {
    // æ ‡è®° GC å‘¨æœŸå¼€å§‹
    return 0;
}
```

**å†…å­˜æ³„æ¼æ£€æµ‹**:

```go
type MemoryLeak struct {
    Address   uint64
    Size      uint64
    Allocated time.Time
    Stack     []string
    Leaked    bool
}

func DetectLeaks(samples []AllocationSample, threshold time.Duration) []MemoryLeak {
    var leaks []MemoryLeak
    now := time.Now()
    
    for _, sample := range samples {
        age := now.Sub(sample.Timestamp)
        
        // è¶…è¿‡é˜ˆå€¼ä¸”æœªé‡Šæ”¾
        if age > threshold && !sample.Freed {
            leaks = append(leaks, MemoryLeak{
                Address:   sample.Address,
                Size:      sample.Size,
                Allocated: sample.Timestamp,
                Stack:     sample.Stack,
                Leaked:    true,
            })
        }
    }
    
    return leaks
}
```

### 4.2 GC æ€§èƒ½åˆ†æ

```c
// è¿½è¸ª GC æš‚åœæ—¶é—´
BPF_HISTOGRAM(gc_pause_hist);

int trace_gc_start(struct pt_regs *ctx) {
    u64 ts = bpf_ktime_get_ns();
    // ä¿å­˜å¼€å§‹æ—¶é—´
    return 0;
}

int trace_gc_done(struct pt_regs *ctx) {
    u64 ts = bpf_ktime_get_ns();
    u64 delta = ts - start_ts;
    
    // è®°å½•åˆ°ç›´æ–¹å›¾
    gc_pause_hist.increment(bpf_log2l(delta));
    return 0;
}
```

**ç”¨æˆ·ç©ºé—´åˆ†æ**:

```go
type GCMetrics struct {
    PauseTime    time.Duration
    HeapSize     uint64
    AllocRate    uint64  // bytes/sec
    GCFrequency  float64 // times/sec
}

func AnalyzeGC(samples []GCSample) GCMetrics {
    var totalPause time.Duration
    var gcCount int
    
    for _, sample := range samples {
        totalPause += sample.PauseDuration
        gcCount++
    }
    
    return GCMetrics{
        PauseTime:   totalPause / time.Duration(gcCount),
        GCFrequency: float64(gcCount) / sampleDuration.Seconds(),
    }
}
```

---

## 5. ç½‘ç»œè¿½è¸ª

### 5.1 TCP è¿æ¥è¿½è¸ª

```c
// è¿½è¸ª TCP è¿æ¥å»ºç«‹
#include <net/sock.h>

struct tcp_event {
    u32 pid;
    u32 saddr;
    u32 daddr;
    u16 sport;
    u16 dport;
    u64 timestamp;
};

BPF_PERF_OUTPUT(tcp_events);

int trace_tcp_connect(struct pt_regs *ctx, struct sock *sk) {
    struct tcp_event event = {};
    
    event.pid = bpf_get_current_pid_tgid() >> 32;
    event.timestamp = bpf_ktime_get_ns();
    
    // è¯»å– socket ä¿¡æ¯
    bpf_probe_read(&event.saddr, sizeof(event.saddr), &sk->__sk_common.skc_rcv_saddr);
    bpf_probe_read(&event.daddr, sizeof(event.daddr), &sk->__sk_common.skc_daddr);
    bpf_probe_read(&event.sport, sizeof(event.sport), &sk->__sk_common.skc_num);
    bpf_probe_read(&event.dport, sizeof(event.dport), &sk->__sk_common.skc_dport);
    
    tcp_events.perf_submit(ctx, &event, sizeof(event));
    return 0;
}
```

### 5.2 HTTP è¯·æ±‚è¿½è¸ª

```c
// è¿½è¸ª Go net/http åº“
int trace_http_handler(struct pt_regs *ctx) {
    // è¯»å– http.Request ç»“æ„ä½“
    void *req_ptr = (void *)PT_REGS_PARM2(ctx);
    
    char method[8];
    char url[128];
    
    // åç§»é‡æ ¹æ® Go ç‰ˆæœ¬è°ƒæ•´
    bpf_probe_read_str(&method, sizeof(method), req_ptr + 0);
    bpf_probe_read_str(&url, sizeof(url), req_ptr + 16);
    
    // å‘é€äº‹ä»¶
    return 0;
}
```

**ä¸ OTLP Trace å…³è”**:

```go
type HTTPTrace struct {
    TraceID     string
    SpanID      string
    Method      string
    URL         string
    StatusCode  int
    Duration    time.Duration
    FromeBPF    bool
}

func CorrelateWithOTLP(ebpfTrace HTTPTrace, otlpSpan *trace.Span) {
    // åŒ¹é…æ—¶é—´æˆ³
    if abs(ebpfTrace.Timestamp - otlpSpan.StartTime) < 1*time.Millisecond {
        // å¢å¼º Span å±æ€§
        otlpSpan.SetAttributes(
            attribute.Int("tcp.retransmits", ebpfTrace.Retransmits),
            attribute.Int64("tcp.rtt_us", ebpfTrace.RTT),
        )
    }
}
```

---

## 6. Goroutine è°ƒåº¦åˆ†æ

### 6.1 è°ƒåº¦å»¶è¿Ÿ

```c
// æµ‹é‡ä» runnable åˆ° running çš„å»¶è¿Ÿ
BPF_HASH(runnable_time, u32);

int trace_goready(struct pt_regs *ctx) {
    u32 goid = /* æå– Goroutine ID */;
    u64 ts = bpf_ktime_get_ns();
    
    runnable_time.update(&goid, &ts);
    return 0;
}

int trace_execute(struct pt_regs *ctx) {
    u32 goid = /* æå– Goroutine ID */;
    u64 *tsp = runnable_time.lookup(&goid);
    
    if (tsp != 0) {
        u64 delta = bpf_ktime_get_ns() - *tsp;
        // è®°å½•è°ƒåº¦å»¶è¿Ÿ
        runnable_time.delete(&goid);
    }
    
    return 0;
}
```

### 6.2 Channel æ“ä½œåˆ†æ

```c
// è¿½è¸ª Channel Send/Recv
int trace_chansend(struct pt_regs *ctx) {
    void *ch_ptr = (void *)PT_REGS_PARM1(ctx);
    u64 start = bpf_ktime_get_ns();
    
    // è®°å½•é˜»å¡æ—¶é—´
    return 0;
}

int trace_chanrecv(struct pt_regs *ctx) {
    void *ch_ptr = (void *)PT_REGS_PARM1(ctx);
    u64 start = bpf_ktime_get_ns();
    
    // è®°å½•é˜»å¡æ—¶é—´
    return 0;
}
```

**å¯è§†åŒ–**:

```go
type ChannelStats struct {
    Address      uint64
    SendCount    int
    RecvCount    int
    AvgSendTime  time.Duration
    AvgRecvTime  time.Duration
    BufferSize   int
    Contention   float64  // é˜»å¡æ¯”ä¾‹
}

func AnalyzeChannels(samples []ChannelSample) []ChannelStats {
    statsMap := make(map[uint64]*ChannelStats)
    
    for _, sample := range samples {
        stats, ok := statsMap[sample.ChannelAddr]
        if !ok {
            stats = &ChannelStats{Address: sample.ChannelAddr}
            statsMap[sample.ChannelAddr] = stats
        }
        
        if sample.Operation == "send" {
            stats.SendCount++
            stats.AvgSendTime += sample.Duration
        } else {
            stats.RecvCount++
            stats.AvgRecvTime += sample.Duration
        }
    }
    
    return toSlice(statsMap)
}
```

---

## 7. eBPF å·¥å…·é“¾

### 7.1 BCC (BPF Compiler Collection)

**Python æ¥å£**:

```python
from bcc import BPF

bpf_text = """
#include <uapi/linux/ptrace.h>

int trace_go_malloc(struct pt_regs *ctx) {
    bpf_trace_printk("malloc called\\n");
    return 0;
}
"""

b = BPF(text=bpf_text)
b.attach_uprobe(name="/usr/bin/myapp", sym="runtime.mallocgc", fn_name="trace_go_malloc")

while True:
    try:
        (task, pid, cpu, flags, ts, msg) = b.trace_fields()
        print(f"{ts} {task} {msg}")
    except KeyboardInterrupt:
        exit()
```

### 7.2 libbpf-go

**çº¯ Go å®ç°**:

```go
import (
    "github.com/cilium/ebpf"
    "github.com/cilium/ebpf/link"
)

//go:embed bpf_prog.o
var bpfProgram []byte

func LoadBPFProgram() error {
    spec, err := ebpf.LoadCollectionSpecFromReader(bytes.NewReader(bpfProgram))
    if err != nil {
        return err
    }
    
    coll, err := ebpf.NewCollection(spec)
    if err != nil {
        return err
    }
    defer coll.Close()
    
    prog := coll.Programs["trace_malloc"]
    
    ex, err := link.OpenExecutable("/usr/bin/myapp")
    if err != nil {
        return err
    }
    
    up, err := ex.Uprobe("runtime.mallocgc", prog, nil)
    if err != nil {
        return err
    }
    defer up.Close()
    
    // è¯»å– map
    events := coll.Maps["events"]
    // ...
    
    return nil
}
```

### 7.3 Pixie (è‡ªåŠ¨åŒ– eBPF)

```yaml
# éƒ¨ç½² Pixie
apiVersion: v1
kind: Namespace
metadata:
  name: px-system

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: vizier-pem
  namespace: px-system
spec:
  selector:
    matchLabels:
      app: vizier-pem
  template:
    spec:
      hostNetwork: true
      hostPID: true
      containers:
      - name: pem
        image: pixielabs/vizier-pem:latest
        securityContext:
          privileged: true
```

**æŸ¥è¯¢ Go åº”ç”¨**:

```python
# PxL (Pixie Language)
import px

# HTTP è¯·æ±‚è¿½è¸ª
df = px.DataFrame('http_events')
df = df[df.service == 'order-service']
df = df.groupby('endpoint').agg(
    latency_p50=('latency_ms', px.percentile(50)),
    latency_p99=('latency_ms', px.percentile(99)),
    request_count=('req_id', px.count),
)

px.display(df)
```

---

## 8. æ€§èƒ½å¼€é”€åˆ†æ

### 8.1 å¼€é”€å¯¹æ¯”

| å·¥å…· | CPU å¼€é”€ | å†…å­˜å¼€é”€ | å»¶è¿Ÿå½±å“ |
|------|----------|----------|----------|
| **pprof (å†…ç½®)** | 5-10% | ä½ | é‡‡æ ·é—´éš”å½±å“ |
| **eBPF** | < 1% | æä½ | å‡ ä¹æ—  |
| **ptrace** | 50-100% | ä¸­ | ä¸¥é‡ |
| **instrumentation** | 10-30% | é«˜ | ä¸­ç­‰ |

### 8.2 ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

```go
type ProfileConfig struct {
    Enabled       bool
    SampleRate    int           // Hz
    MaxStackDepth int
    FilterPIDs    []int
    OutputFormat  string        // "pprof" | "flamegraph"
}

func StartProfiling(cfg ProfileConfig) (*Profiler, error) {
    if !cfg.Enabled {
        return nil, nil
    }
    
    // é™åˆ¶é‡‡æ ·ç‡é¿å…è¿‡è½½
    if cfg.SampleRate > 1000 {
        cfg.SampleRate = 1000
    }
    
    profiler := &Profiler{
        config: cfg,
        buffer: ring.New(10000), // ç¯å½¢ç¼“å†²åŒº
    }
    
    return profiler, profiler.start()
}
```

**åŠ¨æ€å¯åœ**:

```go
// é€šè¿‡ SIGUSR1 è§¦å‘ profiling
func (p *Profiler) SetupSignalHandler() {
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGUSR1)
    
    go func() {
        for range sigChan {
            if p.running {
                p.Stop()
                log.Info("Profiling stopped")
            } else {
                p.Start()
                log.Info("Profiling started")
            }
        }
    }()
}
```

---

## 9. OTLP é›†æˆ

### 9.1 Profile ä¿¡å·æ ¼å¼

```protobuf
message Profile {
  bytes profile_id = 1;
  fixed64 start_time_unix_nano = 2;
  fixed64 end_time_unix_nano = 3;
  repeated KeyValue attributes = 4;
  
  ProfileType profile_type = 5;
  bytes data = 6;  // pprof æ ¼å¼
}

enum ProfileType {
  CPU = 0;
  HEAP = 1;
  GOROUTINE = 2;
  BLOCK = 3;
  MUTEX = 4;
}
```

### 9.2 eBPF â†’ OTLP æ¡¥æ¥

```go
type eBPFToOTLPBridge struct {
    exporter ProfileExporter
    buffer   chan *profile.Profile
}

func (b *eBPFToOTLPBridge) ProcessStackSamples(samples []StackSample) {
    prof := &profile.Profile{
        SampleType: []*profile.ValueType{
            {Type: "cpu", Unit: "nanoseconds"},
        },
        TimeNanos:     time.Now().UnixNano(),
        DurationNanos: int64(time.Second),
    }
    
    // æ„å»º pprof æ ¼å¼
    for _, sample := range samples {
        loc := make([]*profile.Location, len(sample.Stack))
        for i, pc := range sample.Stack {
            loc[i] = &profile.Location{
                Address: pc,
            }
        }
        
        prof.Sample = append(prof.Sample, &profile.Sample{
            Location: loc,
            Value:    []int64{int64(sample.Count)},
        })
    }
    
    // å¯¼å‡ºåˆ° OTLP
    b.exporter.Export(context.Background(), prof)
}
```

### 9.3 å…³è” Trace ä¸ Profile

```go
// Span ä¸­æºå¸¦ Profile ID
span.SetAttributes(
    attribute.String("profile.id", profileID),
    attribute.String("profile.url", fmt.Sprintf("https://profiler/view/%s", profileID)),
)

// æŸ¥è¯¢æ—¶å…³è”
func GetProfileForSpan(spanID string) (*profile.Profile, error) {
    span := getSpan(spanID)
    profileID := span.Attributes["profile.id"]
    
    return profileStore.Get(profileID)
}
```

---

## 10. å®æˆ˜æ¡ˆä¾‹

### 10.1 è¯Šæ–­ Goroutine æ³„æ¼

**ç°è±¡**: åº”ç”¨å†…å­˜æŒç»­å¢é•¿

**eBPF è¯Šæ–­**:

```bash
# 1. è¿½è¸ª Goroutine åˆ›å»º
sudo bpftrace -e '
uprobe:/usr/bin/myapp:runtime.newproc1 {
    @goroutines[pid] = count();
}

interval:s:1 {
    print(@goroutines);
    clear(@goroutines);
}
'

# è¾“å‡º: æ¯ç§’åˆ›å»º 1000+ Goroutineï¼Œä½†æœªé”€æ¯
```

**å®šä½æ³„æ¼æº**:

```go
// æ•è·åˆ›å»ºæ ˆ
type GoroutineTracker struct {
    created map[uint64]*StackTrace
    mu      sync.Mutex
}

func (gt *GoroutineTracker) OnCreate(goid uint64, stack []uintptr) {
    gt.mu.Lock()
    defer gt.mu.Unlock()
    
    gt.created[goid] = &StackTrace{
        Frames:    stack,
        Timestamp: time.Now(),
    }
}

func (gt *GoroutineTracker) FindLeaks(threshold time.Duration) []Leak {
    gt.mu.Lock()
    defer gt.mu.Unlock()
    
    var leaks []Leak
    now := time.Now()
    
    for goid, trace := range gt.created {
        if now.Sub(trace.Timestamp) > threshold {
            leaks = append(leaks, Leak{
                GoroutineID: goid,
                Stack:       trace.Frames,
                Age:         now.Sub(trace.Timestamp),
            })
        }
    }
    
    return leaks
}
```

### 10.2 ä¼˜åŒ– Channel é˜»å¡

**é—®é¢˜**: é«˜å»¶è¿Ÿè¯·æ±‚

**eBPF åˆ†æ**:

```c
// è¿½è¸ª Channel æ“ä½œå»¶è¿Ÿ
BPF_HISTOGRAM(chan_latency);

int trace_chansend_entry(struct pt_regs *ctx) {
    u64 ts = bpf_ktime_get_ns();
    // ä¿å­˜æ—¶é—´æˆ³
    return 0;
}

int trace_chansend_return(struct pt_regs *ctx) {
    u64 ts = bpf_ktime_get_ns();
    u64 delta = ts - start_ts;
    
    chan_latency.increment(bpf_log2l(delta));
    return 0;
}
```

**å‘ç°**: 90% çš„ Send æ“ä½œé˜»å¡è¶…è¿‡ 100ms

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```go
// åŸä»£ç : æ— ç¼“å†² Channel
tasks := make(chan Task)

// ä¼˜åŒ–: æ·»åŠ ç¼“å†²
tasks := make(chan Task, 1000)

// æˆ–ä½¿ç”¨ select è¶…æ—¶
select {
case tasks <- task:
    // æˆåŠŸ
case <-time.After(100 * time.Millisecond):
    // é™çº§å¤„ç†
    return ErrBusy
}
```

### 10.3 GC è°ƒä¼˜

**eBPF ç›‘æ§ GC**:

```bash
sudo bpftrace -e '
uprobe:/usr/bin/myapp:runtime.gcStart {
    @gc_start[pid] = nsecs;
}

uretprobe:/usr/bin/myapp:runtime.gcStart {
    @gc_duration = hist(nsecs - @gc_start[pid]);
    delete(@gc_start[pid]);
}

interval:s:10 {
    print(@gc_duration);
}
'
```

**ä¼˜åŒ–ç­–ç•¥**:

```go
import "runtime/debug"

// è°ƒæ•´ GC ç›®æ ‡ç™¾åˆ†æ¯”
debug.SetGCPercent(200)  // é»˜è®¤ 100

// æ‰‹åŠ¨è§¦å‘ GC (åœ¨ä½å³°æœŸ)
go func() {
    ticker := time.NewTicker(5 * time.Minute)
    for range ticker.C {
        if isLowTraffic() {
            runtime.GC()
        }
    }
}()
```

---

## ğŸ“Š å·¥å…·å¯¹æ¯”æ€»ç»“

| å·¥å…· | é€‚ç”¨åœºæ™¯ | å­¦ä¹ æ›²çº¿ | éƒ¨ç½²å¤æ‚åº¦ |
|------|----------|----------|------------|
| **pprof** | å¼€å‘è°ƒè¯• | ä½ | æä½ |
| **BCC** | æ·±åº¦åˆ†æ | é«˜ | ä¸­ |
| **bpftrace** | å¿«é€Ÿè¯Šæ–­ | ä¸­ | ä½ |
| **Pixie** | ç”Ÿäº§ç›‘æ§ | ä½ | ä¸­ (K8s) |
| **libbpf-go** | å®šåˆ¶åŒ– | é«˜ | é«˜ |

---

## ğŸ¯ æœ€ä½³å®è·µ

1. **å¼€å‘é˜¶æ®µ**: pprof + runtime/trace
2. **æ€§èƒ½æµ‹è¯•**: eBPF CPU/Memory Profiling
3. **ç”Ÿäº§ç¯å¢ƒ**: Pixie + OTLP é›†æˆ
4. **æ•…éšœæ’æŸ¥**: bpftrace å¿«é€Ÿè¯Šæ–­

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. **"BPF Performance Tools"** - Brendan Gregg
2. **Go eBPF Library** - <https://github.com/cilium/ebpf>
3. **Pixie Documentation** - <https://docs.px.dev>
4. **eBPF.io** - <https://ebpf.io>

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [â† åˆ†å¸ƒå¼æ¶æ„æ˜ å°„](./05-csp-distributed-architecture-mapping.md)
- [â†’ å½¢å¼åŒ–éªŒè¯](./08-formal-verification-tla-plus.md)
- [â†‘ ç»¼åˆç´¢å¼•](./00-COMPREHENSIVE-INDEX.md)

---

**æœ€åæ›´æ–°**: 2025-10-03  
**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ  
**å­—æ•°ç»Ÿè®¡**: ~10500 å­—

package main

import (
	"context"
	"fmt"
	"log"
	"runtime"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"go.opentelemetry.io/otel"
	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/exporters/stdout/stdouttrace"
	"go.opentelemetry.io/otel/sdk/resource"
	sdktrace "go.opentelemetry.io/otel/sdk/trace"
	semconv "go.opentelemetry.io/otel/semconv/v1.26.0"
	"go.opentelemetry.io/otel/trace"
)

// ============================
// 1. é«˜æ€§èƒ½ Span æ± 
// ============================

// PooledSpan å¯æ± åŒ–çš„ Span åŒ…è£…å™¨
type PooledSpan struct {
	ctx       context.Context
	span      trace.Span
	attrs     [32]attribute.KeyValue // æ ˆä¸Šæ•°ç»„,é¿å…å †åˆ†é…
	attrCount int
	released  bool
}

var spanPool = sync.Pool{
	New: func() interface{} {
		return &PooledSpan{}
	},
}

// AcquireSpan ä»æ± ä¸­è·å– Span
func AcquireSpan(tracer trace.Tracer, ctx context.Context, name string) *PooledSpan {
	ps := spanPool.Get().(*PooledSpan)
	ps.ctx, ps.span = tracer.Start(ctx, name)
	ps.attrCount = 0
	ps.released = false
	return ps
}

// SetAttribute æ·»åŠ å±æ€§(é›¶åˆ†é…)
func (ps *PooledSpan) SetAttribute(kv attribute.KeyValue) {
	if ps.attrCount < len(ps.attrs) {
		ps.attrs[ps.attrCount] = kv
		ps.attrCount++
	}
}

// Release é‡Šæ”¾ Span å›æ± 
func (ps *PooledSpan) Release() {
	if ps.released {
		return
	}

	// æ‰¹é‡è®¾ç½®å±æ€§
	if ps.attrCount > 0 {
		ps.span.SetAttributes(ps.attrs[:ps.attrCount]...)
	}

	ps.span.End()
	ps.ctx = nil
	ps.span = nil
	ps.attrCount = 0
	ps.released = true

	spanPool.Put(ps)
}

// ============================
// 2. æ‰¹é‡å¯¼å‡ºä¼˜åŒ–
// ============================

// BatchExporter æ‰¹é‡å¯¼å‡ºå™¨
type BatchExporter struct {
	mu         sync.Mutex
	buffer     []sdktrace.ReadOnlySpan
	batchSize  int
	flushTimer *time.Timer
	stopCh     chan struct{}
	exported   int64
}

// NewBatchExporter åˆ›å»ºæ‰¹é‡å¯¼å‡ºå™¨
func NewBatchExporter(batchSize int, flushInterval time.Duration) *BatchExporter {
	be := &BatchExporter{
		buffer:    make([]sdktrace.ReadOnlySpan, 0, batchSize),
		batchSize: batchSize,
		stopCh:    make(chan struct{}),
	}

	// å®šæ—¶åˆ·æ–°
	be.flushTimer = time.AfterFunc(flushInterval, func() {
		be.FlushIfNeeded()
		be.flushTimer.Reset(flushInterval)
	})

	return be
}

// ExportSpans å¯¼å‡º Span
func (be *BatchExporter) ExportSpans(ctx context.Context, spans []sdktrace.ReadOnlySpan) error {
	be.mu.Lock()
	defer be.mu.Unlock()

	be.buffer = append(be.buffer, spans...)

	if len(be.buffer) >= be.batchSize {
		return be.flush()
	}

	return nil
}

// flush åˆ·æ–°ç¼“å†²åŒº
func (be *BatchExporter) flush() error {
	if len(be.buffer) == 0 {
		return nil
	}

	count := len(be.buffer)
	atomic.AddInt64(&be.exported, int64(count))

	log.Printf("ğŸ“¤ Batch export: %d spans (total: %d)", count, atomic.LoadInt64(&be.exported))

	// æ¸…ç©ºç¼“å†²åŒº(ä¿ç•™å®¹é‡)
	be.buffer = be.buffer[:0]

	return nil
}

// FlushIfNeeded å¦‚æœéœ€è¦åˆ™åˆ·æ–°
func (be *BatchExporter) FlushIfNeeded() {
	be.mu.Lock()
	defer be.mu.Unlock()

	if len(be.buffer) > 0 {
		be.flush()
	}
}

// Shutdown å…³é—­å¯¼å‡ºå™¨
func (be *BatchExporter) Shutdown(ctx context.Context) error {
	be.flushTimer.Stop()
	close(be.stopCh)

	be.mu.Lock()
	defer be.mu.Unlock()

	return be.flush()
}

// ============================
// 3. æ— é”è®¡æ•°å™¨
// ============================

// LockFreeCounter æ— é”è®¡æ•°å™¨
type LockFreeCounter struct {
	count int64
}

// Inc å¢åŠ è®¡æ•°
func (c *LockFreeCounter) Inc() {
	atomic.AddInt64(&c.count, 1)
}

// Get è·å–è®¡æ•°
func (c *LockFreeCounter) Get() int64 {
	return atomic.LoadInt64(&c.count)
}

// ============================
// 4. å¹¶è¡Œå¤„ç†ä¼˜åŒ–
// ============================

// WorkerPool Worker æ± 
type WorkerPool struct {
	workers   int
	taskQueue chan func()
	wg        sync.WaitGroup
	stopCh    chan struct{}
	processed int64
}

// NewWorkerPool åˆ›å»º Worker æ± 
func NewWorkerPool(workers int, queueSize int) *WorkerPool {
	wp := &WorkerPool{
		workers:   workers,
		taskQueue: make(chan func(), queueSize),
		stopCh:    make(chan struct{}),
	}

	// å¯åŠ¨ workers
	for i := 0; i < workers; i++ {
		wp.wg.Add(1)
		go wp.worker(i)
	}

	return wp
}

// worker å·¥ä½œåç¨‹
func (wp *WorkerPool) worker(id int) {
	defer wp.wg.Done()

	for {
		select {
		case task := <-wp.taskQueue:
			task()
			atomic.AddInt64(&wp.processed, 1)
		case <-wp.stopCh:
			return
		}
	}
}

// Submit æäº¤ä»»åŠ¡
func (wp *WorkerPool) Submit(task func()) {
	select {
	case wp.taskQueue <- task:
	case <-wp.stopCh:
	}
}

// Stop åœæ­¢ Worker æ± 
func (wp *WorkerPool) Stop() {
	close(wp.stopCh)
	wp.wg.Wait()
	close(wp.taskQueue)
	log.Printf("âœ… Worker pool stopped, processed %d tasks", atomic.LoadInt64(&wp.processed))
}

// ============================
// 5. å†…å­˜é¢„åˆ†é…ä¼˜åŒ–
// ============================

// PreallocatedBuffer é¢„åˆ†é…ç¼“å†²åŒº
type PreallocatedBuffer struct {
	data []byte
	pos  int
}

// NewPreallocatedBuffer åˆ›å»ºé¢„åˆ†é…ç¼“å†²åŒº
func NewPreallocatedBuffer(size int) *PreallocatedBuffer {
	return &PreallocatedBuffer{
		data: make([]byte, 0, size),
		pos:  0,
	}
}

// Write å†™å…¥æ•°æ®
func (pb *PreallocatedBuffer) Write(p []byte) (n int, err error) {
	pb.data = append(pb.data, p...)
	pb.pos += len(p)
	return len(p), nil
}

// Reset é‡ç½®ç¼“å†²åŒº
func (pb *PreallocatedBuffer) Reset() {
	pb.data = pb.data[:0]
	pb.pos = 0
}

// ============================
// 6. ç¼“å­˜ä¼˜åŒ–
// ============================

// AttributeCache å±æ€§ç¼“å­˜
type AttributeCache struct {
	cache sync.Map // ä½¿ç”¨ sync.Map æä¾›æ— é”è¯»å–
}

// NewAttributeCache åˆ›å»ºå±æ€§ç¼“å­˜
func NewAttributeCache() *AttributeCache {
	return &AttributeCache{}
}

// Get è·å–å±æ€§
func (ac *AttributeCache) Get(key string) ([]attribute.KeyValue, bool) {
	val, ok := ac.cache.Load(key)
	if !ok {
		return nil, false
	}
	return val.([]attribute.KeyValue), true
}

// Set è®¾ç½®å±æ€§
func (ac *AttributeCache) Set(key string, attrs []attribute.KeyValue) {
	ac.cache.Store(key, attrs)
}

// ============================
// æ¼”ç¤ºå‡½æ•°
// ============================

// demonstrateSpanPool æ¼”ç¤º Span æ± 
func demonstrateSpanPool(tracer trace.Tracer) {
	log.Println("\n--- Span Pool Demo ---")

	ctx := context.Background()
	var m1, m2 runtime.MemStats

	// ä¸ä½¿ç”¨æ± 
	runtime.ReadMemStats(&m1)
	start := time.Now()

	for i := 0; i < 10000; i++ {
		_, span := tracer.Start(ctx, fmt.Sprintf("operation-%d", i))
		span.SetAttributes(
			attribute.String("type", "test"),
			attribute.Int("iteration", i),
		)
		span.End()
	}

	withoutPoolDuration := time.Since(start)
	runtime.ReadMemStats(&m2)
	allocWithoutPool := m2.TotalAlloc - m1.TotalAlloc

	// ä½¿ç”¨æ± 
	runtime.ReadMemStats(&m1)
	start = time.Now()

	for i := 0; i < 10000; i++ {
		ps := AcquireSpan(tracer, ctx, fmt.Sprintf("pooled-operation-%d", i))
		ps.SetAttribute(attribute.String("type", "test"))
		ps.SetAttribute(attribute.Int("iteration", i))
		ps.Release()
	}

	withPoolDuration := time.Since(start)
	runtime.ReadMemStats(&m2)
	allocWithPool := m2.TotalAlloc - m1.TotalAlloc

	log.Printf("ğŸ“Š Without Pool: %v, Alloc: %d bytes", withoutPoolDuration, allocWithoutPool)
	log.Printf("ğŸ“Š With Pool:    %v, Alloc: %d bytes", withPoolDuration, allocWithPool)
	log.Printf("ğŸš€ Improvement:  %.2fx faster, %.2fx less allocation\n",
		float64(withoutPoolDuration)/float64(withPoolDuration),
		float64(allocWithoutPool)/float64(allocWithPool+1))
}

// demonstrateWorkerPool æ¼”ç¤º Worker æ± 
func demonstrateWorkerPool(tracer trace.Tracer) {
	log.Println("\n--- Worker Pool Demo ---")

	ctx := context.Background()
	pool := NewWorkerPool(4, 100)
	defer pool.Stop()

	var counter LockFreeCounter

	// æäº¤ä»»åŠ¡
	start := time.Now()
	for i := 0; i < 1000; i++ {
		taskID := i
		pool.Submit(func() {
			ps := AcquireSpan(tracer, ctx, fmt.Sprintf("worker-task-%d", taskID))
			ps.SetAttribute(attribute.String("worker", "pool"))
			ps.SetAttribute(attribute.Int("task_id", taskID))

			// æ¨¡æ‹Ÿå·¥ä½œ
			time.Sleep(time.Microsecond * 100)

			ps.Release()
			counter.Inc()
		})
	}

	// ç­‰å¾…å®Œæˆ
	for counter.Get() < 1000 {
		time.Sleep(time.Millisecond * 10)
	}

	duration := time.Since(start)
	log.Printf("ğŸ“Š Processed %d tasks in %v", counter.Get(), duration)
	log.Printf("ğŸ“Š Throughput: %.0f tasks/sec\n", float64(counter.Get())/duration.Seconds())
}

// demonstrateAttributeCache æ¼”ç¤ºå±æ€§ç¼“å­˜
func demonstrateAttributeCache(tracer trace.Tracer) {
	log.Println("\n--- Attribute Cache Demo ---")

	ctx := context.Background()
	cache := NewAttributeCache()

	// é¢„å…ˆç¼“å­˜å¸¸ç”¨å±æ€§
	commonAttrs := []attribute.KeyValue{
		attribute.String("service", "api"),
		attribute.String("environment", "production"),
		attribute.String("version", "1.0.0"),
	}
	cache.Set("common", commonAttrs)

	// ä½¿ç”¨ç¼“å­˜
	start := time.Now()
	for i := 0; i < 1000; i++ {
		ps := AcquireSpan(tracer, ctx, fmt.Sprintf("cached-operation-%d", i))

		// ä»ç¼“å­˜è·å–å±æ€§
		if attrs, ok := cache.Get("common"); ok {
			for _, attr := range attrs {
				ps.SetAttribute(attr)
			}
		}

		ps.SetAttribute(attribute.Int("iteration", i))
		ps.Release()
	}
	duration := time.Since(start)

	log.Printf("ğŸ“Š Processed 1000 operations with cache in %v\n", duration)
}

// demonstrateBatchExport æ¼”ç¤ºæ‰¹é‡å¯¼å‡º
func demonstrateBatchExport(tracer trace.Tracer) {
	log.Println("\n--- Batch Export Demo ---")

	ctx := context.Background()

	// ç”Ÿæˆå¤§é‡ Span
	start := time.Now()
	for i := 0; i < 5000; i++ {
		ps := AcquireSpan(tracer, ctx, fmt.Sprintf("batch-operation-%d", i))
		ps.SetAttribute(attribute.String("type", "batch"))
		ps.SetAttribute(attribute.Int("id", i))
		ps.Release()
	}
	duration := time.Since(start)

	log.Printf("ğŸ“Š Generated 5000 spans in %v", duration)
	log.Printf("ğŸ“Š Rate: %.0f spans/sec\n", 5000.0/duration.Seconds())
}

// demonstrateMemoryEfficiency æ¼”ç¤ºå†…å­˜æ•ˆç‡
func demonstrateMemoryEfficiency(tracer trace.Tracer) {
	log.Println("\n--- Memory Efficiency Demo ---")

	ctx := context.Background()

	// è·å–åˆå§‹å†…å­˜çŠ¶æ€
	runtime.GC()
	var m1 runtime.MemStats
	runtime.ReadMemStats(&m1)

	// æ‰§è¡Œå¤§é‡æ“ä½œ
	for i := 0; i < 10000; i++ {
		ps := AcquireSpan(tracer, ctx, "memory-test")
		ps.SetAttribute(attribute.String("test", "memory"))
		ps.SetAttribute(attribute.Int("id", i))
		ps.Release()
	}

	// è·å–æœ€ç»ˆå†…å­˜çŠ¶æ€
	runtime.GC()
	var m2 runtime.MemStats
	runtime.ReadMemStats(&m2)

	log.Printf("ğŸ“Š Memory Stats:")
	log.Printf("   Alloc:      %d MB", (m2.Alloc-m1.Alloc)/1024/1024)
	log.Printf("   TotalAlloc: %d MB", (m2.TotalAlloc-m1.TotalAlloc)/1024/1024)
	log.Printf("   NumGC:      %d", m2.NumGC-m1.NumGC)
	log.Println()
}

// ============================
// Main
// ============================

func main() {
	// è®¾ç½® GOMAXPROCS
	runtime.GOMAXPROCS(runtime.NumCPU())

	log.Println("\n" + strings.Repeat("=", 80))
	log.Println("ğŸš€ Performance Tuning Demo")
	log.Println(strings.Repeat("=", 80) + "\n")

	// åˆå§‹åŒ– TracerProvider
	_, err := stdouttrace.New(
		stdouttrace.WithPrettyPrint(),
		stdouttrace.WithoutTimestamps(), // å‡å°‘è¾“å‡ºå™ªéŸ³
	)
	if err != nil {
		log.Fatalf("Failed to create exporter: %v", err)
	}

	res, err := resource.New(context.Background(),
		resource.WithAttributes(
			semconv.ServiceName("performance-tuning-demo"),
			semconv.ServiceVersion("1.0.0"),
		),
	)
	if err != nil {
		log.Fatalf("Failed to create resource: %v", err)
	}

	// ä½¿ç”¨æ‰¹é‡å¯¼å‡ºå™¨
	batchExporter := NewBatchExporter(100, time.Second)

	tp := sdktrace.NewTracerProvider(
		sdktrace.WithSpanProcessor(sdktrace.NewBatchSpanProcessor(batchExporter)),
		sdktrace.WithResource(res),
		sdktrace.WithSampler(sdktrace.AlwaysSample()),
	)
	defer func() {
		if err := tp.Shutdown(context.Background()); err != nil {
			log.Fatalf("Failed to shutdown tracer provider: %v", err)
		}
	}()

	otel.SetTracerProvider(tp)
	tracer := tp.Tracer("performance-tuning")

	// æ¼”ç¤º1: Span æ± 
	demonstrateSpanPool(tracer)

	// æ¼”ç¤º2: Worker æ± 
	demonstrateWorkerPool(tracer)

	// æ¼”ç¤º3: å±æ€§ç¼“å­˜
	demonstrateAttributeCache(tracer)

	// æ¼”ç¤º4: æ‰¹é‡å¯¼å‡º
	demonstrateBatchExport(tracer)

	// æ¼”ç¤º5: å†…å­˜æ•ˆç‡
	demonstrateMemoryEfficiency(tracer)

	// ç­‰å¾…æ‰¹é‡å¯¼å‡ºå®Œæˆ
	time.Sleep(time.Second * 2)

	log.Println(strings.Repeat("=", 80))
	log.Println("âœ… All demos completed successfully")
	log.Println(strings.Repeat("=", 80))

	// æ‰“å°æœ€ç»ˆç»Ÿè®¡
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	log.Printf("\nğŸ“Š Final Memory Stats:")
	log.Printf("   Alloc:      %d MB", m.Alloc/1024/1024)
	log.Printf("   TotalAlloc: %d MB", m.TotalAlloc/1024/1024)
	log.Printf("   Sys:        %d MB", m.Sys/1024/1024)
	log.Printf("   NumGC:      %d", m.NumGC)
	log.Printf("   Goroutines: %d", runtime.NumGoroutine())
}

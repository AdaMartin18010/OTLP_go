# Grafana Tempo ä¸ OTLP å®Œæ•´é›†æˆæŒ‡å—ï¼ˆGo 1.25.1 - 2025ç‰ˆï¼‰

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **æ›´æ–°æ—¥æœŸ**: 2025-10-12  
> **Go ç‰ˆæœ¬**: 1.25.1+  
> **Tempo ç‰ˆæœ¬**: 2.3.0+  
> **æŠ€æœ¯æ·±åº¦**: â­â­â­â­â­

---

## ğŸ“‹ ç›®å½•

- [Grafana Tempo ä¸ OTLP å®Œæ•´é›†æˆæŒ‡å—ï¼ˆGo 1.25.1 - 2025ç‰ˆï¼‰](#grafana-tempo-ä¸-otlp-å®Œæ•´é›†æˆæŒ‡å—go-1251---2025ç‰ˆ)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ç®€ä»‹](#ç®€ä»‹)
    - [ä»€ä¹ˆæ˜¯ Grafana Tempoï¼Ÿ](#ä»€ä¹ˆæ˜¯-grafana-tempo)
    - [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
    - [ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”](#ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”)
  - [Grafana Tempo æ¦‚è¿°](#grafana-tempo-æ¦‚è¿°)
    - [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
    - [æ•°æ®æµç¨‹](#æ•°æ®æµç¨‹)
  - [å®Œæ•´é›†æˆç¤ºä¾‹](#å®Œæ•´é›†æˆç¤ºä¾‹)
    - [1. åŸºç¡€é…ç½®](#1-åŸºç¡€é…ç½®)
      - [go.mod ä¾èµ–](#gomod-ä¾èµ–)
      - [Tempo é…ç½®æ–‡ä»¶](#tempo-é…ç½®æ–‡ä»¶)
    - [2. OTLP Exporter é…ç½®](#2-otlp-exporter-é…ç½®)
    - [3. HTTP æœåŠ¡é›†æˆç¤ºä¾‹](#3-http-æœåŠ¡é›†æˆç¤ºä¾‹)
    - [4. åˆ†å¸ƒå¼è¿½è¸ªç¤ºä¾‹](#4-åˆ†å¸ƒå¼è¿½è¸ªç¤ºä¾‹)
  - [é«˜çº§ç‰¹æ€§](#é«˜çº§ç‰¹æ€§)
    - [1. TraceQL æŸ¥è¯¢è¯­è¨€](#1-traceql-æŸ¥è¯¢è¯­è¨€)
      - [TraceQL è¯­æ³•ç¤ºä¾‹](#traceql-è¯­æ³•ç¤ºä¾‹)
      - [Go ä¸­ä½¿ç”¨ TraceQL](#go-ä¸­ä½¿ç”¨-traceql)
    - [2. Metrics Generator (åº¦é‡ç”Ÿæˆå™¨)](#2-metrics-generator-åº¦é‡ç”Ÿæˆå™¨)
      - [é…ç½® Metrics Generator](#é…ç½®-metrics-generator)
      - [Go ä»£ç ä¸­å¯ç”¨ Exemplars](#go-ä»£ç ä¸­å¯ç”¨-exemplars)
    - [3. æœåŠ¡å›¾ (Service Graph)](#3-æœåŠ¡å›¾-service-graph)
      - [æŸ¥è¯¢æœåŠ¡å›¾](#æŸ¥è¯¢æœåŠ¡å›¾)
  - [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
    - [1. é‡‡æ ·ç­–ç•¥](#1-é‡‡æ ·ç­–ç•¥)
    - [2. æ‰¹å¤„ç†ä¼˜åŒ–](#2-æ‰¹å¤„ç†ä¼˜åŒ–)
    - [3. è¿æ¥æ± ä¼˜åŒ–](#3-è¿æ¥æ± ä¼˜åŒ–)
  - [ç”Ÿäº§éƒ¨ç½²](#ç”Ÿäº§éƒ¨ç½²)
    - [1. Docker Compose éƒ¨ç½²](#1-docker-compose-éƒ¨ç½²)
      - [Grafana æ•°æ®æºé…ç½®](#grafana-æ•°æ®æºé…ç½®)
    - [2. Kubernetes éƒ¨ç½²](#2-kubernetes-éƒ¨ç½²)
    - [3. ç”Ÿäº§é…ç½®ä¼˜åŒ–](#3-ç”Ÿäº§é…ç½®ä¼˜åŒ–)
  - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
    - [1. å±æ€§å‘½åè§„èŒƒ](#1-å±æ€§å‘½åè§„èŒƒ)
    - [2. é”™è¯¯å¤„ç†æœ€ä½³å®è·µ](#2-é”™è¯¯å¤„ç†æœ€ä½³å®è·µ)
    - [3. è¿½è¸ªä¸Šä¸‹æ–‡ä¼ æ’­](#3-è¿½è¸ªä¸Šä¸‹æ–‡ä¼ æ’­)
  - [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
    - [1. å¸¸è§é—®é¢˜](#1-å¸¸è§é—®é¢˜)
    - [2. ç›‘æ§æŒ‡æ ‡](#2-ç›‘æ§æŒ‡æ ‡)
    - [3. æ—¥å¿—åˆ†æ](#3-æ—¥å¿—åˆ†æ)
  - [æ€»ç»“](#æ€»ç»“)
    - [æ ¸å¿ƒè¦ç‚¹](#æ ¸å¿ƒè¦ç‚¹)
    - [æ€§èƒ½åŸºå‡†](#æ€§èƒ½åŸºå‡†)
    - [ä¸‹ä¸€æ­¥](#ä¸‹ä¸€æ­¥)

---

## ç®€ä»‹

### ä»€ä¹ˆæ˜¯ Grafana Tempoï¼Ÿ

**Grafana Tempo** æ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼è¿½è¸ªåç«¯ï¼Œä¸“ä¸ºå¤§è§„æ¨¡ã€é«˜æ€§èƒ½è¿½è¸ªæ•°æ®å­˜å‚¨è€Œè®¾è®¡ã€‚

### æ ¸å¿ƒç‰¹æ€§

```text
âœ… æ ¸å¿ƒä¼˜åŠ¿:
  - æˆæœ¬æ•ˆç›Šé«˜ (ä»…éœ€å¯¹è±¡å­˜å‚¨)
  - æ— ç´¢å¼•è®¾è®¡ (TraceID æŸ¥è¯¢)
  - äº‘åŸç”Ÿæ¶æ„
  - ä¸ Grafana æ·±åº¦é›†æˆ
  - æ”¯æŒå¤šç§è¿½è¸ªæ ¼å¼

âœ… æ”¯æŒçš„åè®®:
  - OTLP (gRPC/HTTP)
  - Jaeger
  - Zipkin
  - OpenCensus

âœ… å­˜å‚¨åç«¯:
  - S3/GCS/Azure Blob
  - æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
  - Cassandra (å®éªŒæ€§)

âœ… æ€§èƒ½æŒ‡æ ‡:
  - ååé‡: 100K+ spans/s
  - æŸ¥è¯¢å»¶è¿Ÿ: <100ms (TraceID)
  - å­˜å‚¨æˆæœ¬: ~$0.02/GB/æœˆ
  - æ•°æ®å‹ç¼©: 10:1 æ¯”ä¾‹
```

### ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”

| ç‰¹æ€§ | Tempo | Jaeger | Zipkin | Elastic APM |
|------|-------|--------|--------|-------------|
| æˆæœ¬ | æä½ | ä¸­ | ä¸­ | é«˜ |
| æ‰©å±•æ€§ | æå¥½ | å¥½ | ä¸­ | å¥½ |
| æŸ¥è¯¢èƒ½åŠ› | TraceID | å…¨æ–‡æœç´¢ | æ ‡ç­¾æœç´¢ | å…¨æ–‡æœç´¢ |
| å­˜å‚¨ | å¯¹è±¡å­˜å‚¨ | DB/ES | DB | Elasticsearch |
| è¿ç»´å¤æ‚åº¦ | ä½ | ä¸­ | ä½ | é«˜ |
| Grafanaé›†æˆ | åŸç”Ÿ | æ’ä»¶ | æ’ä»¶ | æ’ä»¶ |

---

## Grafana Tempo æ¦‚è¿°

### æ¶æ„è®¾è®¡

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tempo æ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Collectorâ”‚    â”‚ Collectorâ”‚    â”‚ Collectorâ”‚           â”‚
â”‚  â”‚  (OTLP)  â”‚    â”‚ (Jaeger) â”‚    â”‚ (Zipkin) â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚
â”‚       â”‚               â”‚               â”‚                 â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                       â”‚                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚   Distributor   â”‚  (è´Ÿè½½å‡è¡¡)             â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                       â”‚                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚    Ingester     â”‚  (å†™å…¥ç¼“å†²)             â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                       â”‚                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚    Compactor    â”‚  (æ•°æ®å‹ç¼©)            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                       â”‚                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚ Object Storage  â”‚  (S3/GCS/Azure)        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                       â”‚                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚  Query Frontend â”‚  (æŸ¥è¯¢å…¥å£)            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                       â”‚                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚     Querier     â”‚  (æ•°æ®æ£€ç´¢)            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµç¨‹

```text
1. æ•°æ®å†™å…¥æµç¨‹:
   åº”ç”¨ â†’ OTLP Exporter â†’ Tempo Distributor â†’ Ingester â†’ Object Storage

2. æ•°æ®æŸ¥è¯¢æµç¨‹:
   Grafana â†’ Query Frontend â†’ Querier â†’ Object Storage â†’ è¿”å›ç»“æœ

3. æ•°æ®å‹ç¼©æµç¨‹:
   Compactor â†’ è¯»å–æ—§å— â†’ åˆå¹¶å‹ç¼© â†’ å†™å…¥æ–°å— â†’ åˆ é™¤æ—§å—
```

---

## å®Œæ•´é›†æˆç¤ºä¾‹

### 1. åŸºç¡€é…ç½®

#### go.mod ä¾èµ–

```go
module github.com/example/tempo-integration

go 1.25.1

require (
    go.opentelemetry.io/otel v1.24.0
    go.opentelemetry.io/otel/exporters/otlp/otlptrace v1.24.0
    go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.24.0
    go.opentelemetry.io/otel/sdk v1.24.0
    go.opentelemetry.io/otel/trace v1.24.0
    google.golang.org/grpc v1.62.0
)
```

#### Tempo é…ç½®æ–‡ä»¶

```yaml
# tempo-config.yaml
server:
  http_listen_port: 3200
  grpc_listen_port: 9095

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
    jaeger:
      protocols:
        thrift_http:
          endpoint: 0.0.0.0:14268
        grpc:
          endpoint: 0.0.0.0:14250

ingester:
  max_block_duration: 5m
  max_block_bytes: 1048576
  complete_block_timeout: 15m

compactor:
  compaction:
    block_retention: 168h  # 7 days
  ring:
    kvstore:
      store: inmemory

storage:
  trace:
    backend: local
    local:
      path: /var/tempo/traces
    wal:
      path: /var/tempo/wal
    pool:
      max_workers: 100
      queue_depth: 10000

querier:
  frontend_worker:
    frontend_address: localhost:9095

metrics_generator:
  registry:
    external_labels:
      source: tempo
      cluster: dev
  storage:
    path: /var/tempo/generator/wal
  traces_storage:
    path: /var/tempo/generator/traces
```

### 2. OTLP Exporter é…ç½®

```go
package tempo

import (
    "context"
    "fmt"
    "time"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/otlp/otlptrace"
    "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.24.0"
    "google.golang.org/grpc"
    "google.golang.org/grpc/credentials/insecure"
)

// TempoConfig Tempo é…ç½®
type TempoConfig struct {
    Endpoint        string        // Tempo gRPC ç«¯ç‚¹
    ServiceName     string        // æœåŠ¡åç§°
    ServiceVersion  string        // æœåŠ¡ç‰ˆæœ¬
    Environment     string        // ç¯å¢ƒ (dev/staging/prod)
    SamplingRate    float64       // é‡‡æ ·ç‡ (0.0-1.0)
    MaxQueueSize    int           // æœ€å¤§é˜Ÿåˆ—å¤§å°
    BatchTimeout    time.Duration // æ‰¹å¤„ç†è¶…æ—¶
    ExportTimeout   time.Duration // å¯¼å‡ºè¶…æ—¶
    Insecure        bool          // æ˜¯å¦ä½¿ç”¨ä¸å®‰å…¨è¿æ¥
}

// DefaultTempoConfig é»˜è®¤é…ç½®
func DefaultTempoConfig() *TempoConfig {
    return &TempoConfig{
        Endpoint:       "localhost:4317",
        ServiceName:    "my-service",
        ServiceVersion: "1.0.0",
        Environment:    "development",
        SamplingRate:   1.0, // å¼€å‘ç¯å¢ƒå…¨é‡‡æ ·
        MaxQueueSize:   2048,
        BatchTimeout:   5 * time.Second,
        ExportTimeout:  30 * time.Second,
        Insecure:       true,
    }
}

// TempoExporter Tempo å¯¼å‡ºå™¨
type TempoExporter struct {
    config         *TempoConfig
    tracerProvider *sdktrace.TracerProvider
    exporter       *otlptrace.Exporter
}

// NewTempoExporter åˆ›å»º Tempo å¯¼å‡ºå™¨
func NewTempoExporter(ctx context.Context, cfg *TempoConfig) (*TempoExporter, error) {
    if cfg == nil {
        cfg = DefaultTempoConfig()
    }

    // 1. åˆ›å»ºèµ„æº
    res, err := resource.New(ctx,
        resource.WithAttributes(
            semconv.ServiceName(cfg.ServiceName),
            semconv.ServiceVersion(cfg.ServiceVersion),
            semconv.DeploymentEnvironment(cfg.Environment),
        ),
    )
    if err != nil {
        return nil, fmt.Errorf("failed to create resource: %w", err)
    }

    // 2. é…ç½® gRPC è¿æ¥é€‰é¡¹
    opts := []otlptracegrpc.Option{
        otlptracegrpc.WithEndpoint(cfg.Endpoint),
        otlptracegrpc.WithTimeout(cfg.ExportTimeout),
    }

    if cfg.Insecure {
        opts = append(opts,
            otlptracegrpc.WithTLSCredentials(insecure.NewCredentials()),
            otlptracegrpc.WithDialOption(grpc.WithBlock()),
        )
    }

    // 3. åˆ›å»º OTLP å¯¼å‡ºå™¨
    exporter, err := otlptracegrpc.New(ctx, opts...)
    if err != nil {
        return nil, fmt.Errorf("failed to create OTLP exporter: %w", err)
    }

    // 4. é…ç½®é‡‡æ ·å™¨
    var sampler sdktrace.Sampler
    if cfg.SamplingRate >= 1.0 {
        sampler = sdktrace.AlwaysSample()
    } else if cfg.SamplingRate <= 0.0 {
        sampler = sdktrace.NeverSample()
    } else {
        sampler = sdktrace.TraceIDRatioBased(cfg.SamplingRate)
    }

    // 5. åˆ›å»º TracerProvider
    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter,
            sdktrace.WithMaxQueueSize(cfg.MaxQueueSize),
            sdktrace.WithBatchTimeout(cfg.BatchTimeout),
            sdktrace.WithExportTimeout(cfg.ExportTimeout),
        ),
        sdktrace.WithResource(res),
        sdktrace.WithSampler(sampler),
    )

    // 6. è®¾ç½®å…¨å±€ TracerProvider
    otel.SetTracerProvider(tp)

    // 7. è®¾ç½®å…¨å±€ Propagator
    otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(
        propagation.TraceContext{},
        propagation.Baggage{},
    ))

    return &TempoExporter{
        config:         cfg,
        tracerProvider: tp,
        exporter:       exporter,
    }, nil
}

// Shutdown å…³é—­å¯¼å‡ºå™¨
func (e *TempoExporter) Shutdown(ctx context.Context) error {
    if e.tracerProvider != nil {
        if err := e.tracerProvider.Shutdown(ctx); err != nil {
            return fmt.Errorf("failed to shutdown tracer provider: %w", err)
        }
    }
    return nil
}

// ForceFlush å¼ºåˆ¶åˆ·æ–°
func (e *TempoExporter) ForceFlush(ctx context.Context) error {
    if e.tracerProvider != nil {
        if err := e.tracerProvider.ForceFlush(ctx); err != nil {
            return fmt.Errorf("failed to flush tracer provider: %w", err)
        }
    }
    return nil
}
```

### 3. HTTP æœåŠ¡é›†æˆç¤ºä¾‹

```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "math/rand"
    "net/http"
    "time"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/codes"
    "go.opentelemetry.io/otel/trace"
)

var tracer = otel.Tracer("example-http-server")

// User ç”¨æˆ·æ¨¡å‹
type User struct {
    ID       int64  `json:"id"`
    Username string `json:"username"`
    Email    string `json:"email"`
}

// Response ç»Ÿä¸€å“åº”
type Response struct {
    Code    int         `json:"code"`
    Message string      `json:"message"`
    Data    interface{} `json:"data,omitempty"`
}

// TracingMiddleware è¿½è¸ªä¸­é—´ä»¶
func TracingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        ctx, span := tracer.Start(r.Context(), r.URL.Path,
            trace.WithSpanKind(trace.SpanKindServer),
            trace.WithAttributes(
                attribute.String("http.method", r.Method),
                attribute.String("http.url", r.URL.String()),
                attribute.String("http.scheme", r.URL.Scheme),
                attribute.String("http.host", r.Host),
                attribute.String("http.user_agent", r.UserAgent()),
                attribute.String("http.remote_addr", r.RemoteAddr),
            ),
        )
        defer span.End()

        // åŒ…è£… ResponseWriter ä»¥æ•è·çŠ¶æ€ç 
        ww := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}

        next.ServeHTTP(ww, r.WithContext(ctx))

        // è®°å½•å“åº”çŠ¶æ€
        span.SetAttributes(
            attribute.Int("http.status_code", ww.statusCode),
        )

        if ww.statusCode >= 400 {
            span.SetStatus(codes.Error, fmt.Sprintf("HTTP %d", ww.statusCode))
        }
    })
}

type responseWriter struct {
    http.ResponseWriter
    statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

// GetUserHandler è·å–ç”¨æˆ·å¤„ç†å™¨
func GetUserHandler(w http.ResponseWriter, r *http.Request) {
    ctx, span := tracer.Start(r.Context(), "GetUser")
    defer span.End()

    // æå–ç”¨æˆ· ID
    userID := r.URL.Query().Get("id")
    span.SetAttributes(attribute.String("user.id", userID))

    // æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
    user, err := fetchUserFromDB(ctx, userID)
    if err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, err.Error())
        writeJSON(w, http.StatusInternalServerError, Response{
            Code:    500,
            Message: err.Error(),
        })
        return
    }

    // æ£€æŸ¥ç¼“å­˜
    cached := checkCache(ctx, fmt.Sprintf("user:%s", userID))
    span.SetAttributes(attribute.Bool("cache.hit", cached))

    writeJSON(w, http.StatusOK, Response{
        Code:    200,
        Message: "success",
        Data:    user,
    })
}

// fetchUserFromDB ä»æ•°æ®åº“è·å–ç”¨æˆ·
func fetchUserFromDB(ctx context.Context, userID string) (*User, error) {
    _, span := tracer.Start(ctx, "DB.QueryUser",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(
            attribute.String("db.system", "postgresql"),
            attribute.String("db.operation", "SELECT"),
            attribute.String("db.table", "users"),
        ),
    )
    defer span.End()

    // æ¨¡æ‹Ÿæ•°æ®åº“å»¶è¿Ÿ
    time.Sleep(time.Duration(10+rand.Intn(40)) * time.Millisecond)

    // 10% æ¦‚ç‡å‡ºé”™
    if rand.Float64() < 0.1 {
        err := fmt.Errorf("database connection timeout")
        span.RecordError(err)
        span.SetStatus(codes.Error, err.Error())
        return nil, err
    }

    user := &User{
        ID:       123,
        Username: "john_doe",
        Email:    "john@example.com",
    }

    span.SetAttributes(
        attribute.Int64("user.id", user.ID),
        attribute.String("user.username", user.Username),
    )

    return user, nil
}

// checkCache æ£€æŸ¥ç¼“å­˜
func checkCache(ctx context.Context, key string) bool {
    _, span := tracer.Start(ctx, "Cache.Get",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(
            attribute.String("cache.system", "redis"),
            attribute.String("cache.key", key),
        ),
    )
    defer span.End()

    // æ¨¡æ‹Ÿç¼“å­˜æŸ¥è¯¢
    time.Sleep(time.Duration(1+rand.Intn(5)) * time.Millisecond)

    hit := rand.Float64() < 0.7 // 70% ç¼“å­˜å‘½ä¸­
    span.SetAttributes(attribute.Bool("cache.hit", hit))

    return hit
}

// writeJSON å†™å…¥ JSON å“åº”
func writeJSON(w http.ResponseWriter, status int, data interface{}) {
    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(status)
    json.NewEncoder(w).Encode(data)
}

func main() {
    // 1. åˆå§‹åŒ– Tempo å¯¼å‡ºå™¨
    ctx := context.Background()
    tempoExporter, err := NewTempoExporter(ctx, &TempoConfig{
        Endpoint:       "localhost:4317",
        ServiceName:    "user-service",
        ServiceVersion: "1.0.0",
        Environment:    "production",
        SamplingRate:   0.1, // 10% é‡‡æ ·ç‡
        MaxQueueSize:   2048,
        BatchTimeout:   5 * time.Second,
        ExportTimeout:  30 * time.Second,
        Insecure:       true,
    })
    if err != nil {
        log.Fatalf("Failed to create Tempo exporter: %v", err)
    }
    defer tempoExporter.Shutdown(ctx)

    // 2. è®¾ç½®è·¯ç”±
    mux := http.NewServeMux()
    mux.HandleFunc("/user", GetUserHandler)
    mux.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
        writeJSON(w, http.StatusOK, Response{Code: 200, Message: "OK"})
    })

    // 3. åº”ç”¨è¿½è¸ªä¸­é—´ä»¶
    handler := TracingMiddleware(mux)

    // 4. å¯åŠ¨æœåŠ¡å™¨
    log.Println("Starting server on :8080...")
    if err := http.ListenAndServe(":8080", handler); err != nil {
        log.Fatalf("Server failed: %v", err)
    }
}
```

### 4. åˆ†å¸ƒå¼è¿½è¸ªç¤ºä¾‹

```go
package main

import (
    "context"
    "fmt"
    "math/rand"
    "time"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/codes"
    "go.opentelemetry.io/otel/trace"
)

var (
    apiTracer      = otel.Tracer("api-gateway")
    authTracer     = otel.Tracer("auth-service")
    userTracer     = otel.Tracer("user-service")
    paymentTracer  = otel.Tracer("payment-service")
)

// OrderRequest è®¢å•è¯·æ±‚
type OrderRequest struct {
    UserID    int64
    ProductID int64
    Amount    float64
}

// CreateOrder åˆ›å»ºè®¢å• (API Gateway)
func CreateOrder(ctx context.Context, req *OrderRequest) error {
    ctx, span := apiTracer.Start(ctx, "API.CreateOrder",
        trace.WithSpanKind(trace.SpanKindServer),
        trace.WithAttributes(
            attribute.Int64("order.user_id", req.UserID),
            attribute.Int64("order.product_id", req.ProductID),
            attribute.Float64("order.amount", req.Amount),
        ),
    )
    defer span.End()

    // 1. éªŒè¯ç”¨æˆ·èº«ä»½
    if err := authenticateUser(ctx, req.UserID); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, "Authentication failed")
        return err
    }

    // 2. éªŒè¯ç”¨æˆ·ä¿¡æ¯
    if err := validateUser(ctx, req.UserID); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, "User validation failed")
        return err
    }

    // 3. å¤„ç†æ”¯ä»˜
    if err := processPayment(ctx, req.UserID, req.Amount); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, "Payment failed")
        return err
    }

    span.AddEvent("Order created successfully")
    span.SetStatus(codes.Ok, "Order completed")
    return nil
}

// authenticateUser éªŒè¯ç”¨æˆ· (Auth Service)
func authenticateUser(ctx context.Context, userID int64) error {
    _, span := authTracer.Start(ctx, "Auth.ValidateToken",
        trace.WithSpanKind(trace.SpanKindInternal),
        trace.WithAttributes(
            attribute.Int64("auth.user_id", userID),
        ),
    )
    defer span.End()

    // æ¨¡æ‹ŸéªŒè¯å»¶è¿Ÿ
    time.Sleep(time.Duration(20+rand.Intn(30)) * time.Millisecond)

    // 5% æ¦‚ç‡éªŒè¯å¤±è´¥
    if rand.Float64() < 0.05 {
        err := fmt.Errorf("invalid token")
        span.RecordError(err)
        span.SetStatus(codes.Error, err.Error())
        return err
    }

    span.SetAttributes(attribute.Bool("auth.valid", true))
    return nil
}

// validateUser éªŒè¯ç”¨æˆ·ä¿¡æ¯ (User Service)
func validateUser(ctx context.Context, userID int64) error {
    ctx, span := userTracer.Start(ctx, "User.Validate",
        trace.WithSpanKind(trace.SpanKindInternal),
        trace.WithAttributes(
            attribute.Int64("user.id", userID),
        ),
    )
    defer span.End()

    // æŸ¥è¯¢æ•°æ®åº“
    if err := queryUserDB(ctx, userID); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, "DB query failed")
        return err
    }

    // æ£€æŸ¥ç¼“å­˜
    checkUserCache(ctx, userID)

    span.SetAttributes(attribute.Bool("user.valid", true))
    return nil
}

// queryUserDB æŸ¥è¯¢ç”¨æˆ·æ•°æ®åº“
func queryUserDB(ctx context.Context, userID int64) error {
    _, span := userTracer.Start(ctx, "User.DB.Query",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(
            attribute.String("db.system", "postgresql"),
            attribute.String("db.operation", "SELECT"),
            attribute.String("db.statement", "SELECT * FROM users WHERE id = $1"),
        ),
    )
    defer span.End()

    time.Sleep(time.Duration(30+rand.Intn(50)) * time.Millisecond)

    // 3% æ¦‚ç‡æŸ¥è¯¢å¤±è´¥
    if rand.Float64() < 0.03 {
        err := fmt.Errorf("database timeout")
        span.RecordError(err)
        span.SetStatus(codes.Error, err.Error())
        return err
    }

    return nil
}

// checkUserCache æ£€æŸ¥ç”¨æˆ·ç¼“å­˜
func checkUserCache(ctx context.Context, userID int64) bool {
    _, span := userTracer.Start(ctx, "User.Cache.Get",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(
            attribute.String("cache.system", "redis"),
            attribute.String("cache.key", fmt.Sprintf("user:%d", userID)),
        ),
    )
    defer span.End()

    time.Sleep(time.Duration(2+rand.Intn(5)) * time.Millisecond)

    hit := rand.Float64() < 0.8 // 80% ç¼“å­˜å‘½ä¸­
    span.SetAttributes(attribute.Bool("cache.hit", hit))
    return hit
}

// processPayment å¤„ç†æ”¯ä»˜ (Payment Service)
func processPayment(ctx context.Context, userID int64, amount float64) error {
    ctx, span := paymentTracer.Start(ctx, "Payment.Process",
        trace.WithSpanKind(trace.SpanKindInternal),
        trace.WithAttributes(
            attribute.Int64("payment.user_id", userID),
            attribute.Float64("payment.amount", amount),
        ),
    )
    defer span.End()

    // 1. è°ƒç”¨ç¬¬ä¸‰æ–¹æ”¯ä»˜æ¥å£
    if err := callPaymentGateway(ctx, amount); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, "Payment gateway failed")
        return err
    }

    // 2. æ›´æ–°æ•°æ®åº“
    if err := updatePaymentDB(ctx, userID, amount); err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, "DB update failed")
        return err
    }

    span.AddEvent("Payment completed")
    span.SetStatus(codes.Ok, "Payment successful")
    return nil
}

// callPaymentGateway è°ƒç”¨æ”¯ä»˜ç½‘å…³
func callPaymentGateway(ctx context.Context, amount float64) error {
    _, span := paymentTracer.Start(ctx, "Payment.Gateway.Call",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(
            attribute.String("payment.gateway", "stripe"),
            attribute.Float64("payment.amount", amount),
        ),
    )
    defer span.End()

    time.Sleep(time.Duration(50+rand.Intn(100)) * time.Millisecond)

    // 2% æ¦‚ç‡æ”¯ä»˜å¤±è´¥
    if rand.Float64() < 0.02 {
        err := fmt.Errorf("payment gateway timeout")
        span.RecordError(err)
        span.SetStatus(codes.Error, err.Error())
        return err
    }

    span.SetAttributes(attribute.String("payment.transaction_id", fmt.Sprintf("txn_%d", time.Now().Unix())))
    return nil
}

// updatePaymentDB æ›´æ–°æ”¯ä»˜æ•°æ®åº“
func updatePaymentDB(ctx context.Context, userID int64, amount float64) error {
    _, span := paymentTracer.Start(ctx, "Payment.DB.Update",
        trace.WithSpanKind(trace.SpanKindClient),
        trace.WithAttributes(
            attribute.String("db.system", "postgresql"),
            attribute.String("db.operation", "INSERT"),
            attribute.String("db.table", "payments"),
        ),
    )
    defer span.End()

    time.Sleep(time.Duration(20+rand.Intn(30)) * time.Millisecond)
    return nil
}

func main() {
    // åˆå§‹åŒ– Tempo å¯¼å‡ºå™¨
    ctx := context.Background()
    tempoExporter, err := NewTempoExporter(ctx, &TempoConfig{
        Endpoint:       "localhost:4317",
        ServiceName:    "order-system",
        ServiceVersion: "1.0.0",
        Environment:    "production",
        SamplingRate:   1.0, // å…¨é‡‡æ ·
        Insecure:       true,
    })
    if err != nil {
        panic(err)
    }
    defer tempoExporter.Shutdown(ctx)

    // æ¨¡æ‹Ÿåˆ›å»ºè®¢å•
    for i := 0; i < 10; i++ {
        req := &OrderRequest{
            UserID:    int64(1000 + i),
            ProductID: int64(2000 + i),
            Amount:    99.99,
        }

        if err := CreateOrder(ctx, req); err != nil {
            fmt.Printf("Order failed: %v\n", err)
        } else {
            fmt.Printf("Order created successfully for user %d\n", req.UserID)
        }

        time.Sleep(1 * time.Second)
    }

    // å¼ºåˆ¶åˆ·æ–°
    tempoExporter.ForceFlush(ctx)
    time.Sleep(2 * time.Second)
}
```

---

## é«˜çº§ç‰¹æ€§

### 1. TraceQL æŸ¥è¯¢è¯­è¨€

TraceQL æ˜¯ Tempo çš„åŸç”ŸæŸ¥è¯¢è¯­è¨€ï¼Œç”¨äºæœç´¢å’Œè¿‡æ»¤è¿½è¸ªæ•°æ®ã€‚

#### TraceQL è¯­æ³•ç¤ºä¾‹

```traceql
# 1. åŸºç¡€æŸ¥è¯¢ - æŸ¥æ‰¾æ‰€æœ‰åŒ…å«é”™è¯¯çš„è¿½è¸ª
{ status = error }

# 2. å±æ€§è¿‡æ»¤ - æŸ¥æ‰¾ç‰¹å®šæœåŠ¡çš„è¿½è¸ª
{ service.name = "user-service" }

# 3. æ—¶é•¿è¿‡æ»¤ - æŸ¥æ‰¾è€—æ—¶è¶…è¿‡ 1 ç§’çš„è¿½è¸ª
{ duration > 1s }

# 4. ç»„åˆæŸ¥è¯¢ - æŸ¥æ‰¾æ…¢æŸ¥è¯¢ä¸”æœ‰é”™è¯¯çš„è¿½è¸ª
{ service.name = "database" && duration > 500ms && status = error }

# 5. HTTP çŠ¶æ€ç è¿‡æ»¤
{ http.status_code >= 400 }

# 6. èµ„æºå±æ€§è¿‡æ»¤
{ resource.deployment.environment = "production" }

# 7. Span åç§°è¿‡æ»¤
{ name = "DB.Query" }

# 8. å¤æ‚æŸ¥è¯¢ - æŸ¥æ‰¾ç”Ÿäº§ç¯å¢ƒä¸­æ…¢ API è°ƒç”¨
{
  resource.service.name = "api-gateway" &&
  resource.deployment.environment = "production" &&
  span.http.method = "POST" &&
  duration > 1s &&
  span.http.status_code >= 500
}
```

#### Go ä¸­ä½¿ç”¨ TraceQL

```go
package tempo

import (
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "net/url"
)

// TempoQuerier Tempo æŸ¥è¯¢å®¢æˆ·ç«¯
type TempoQuerier struct {
    baseURL string
    client  *http.Client
}

// NewTempoQuerier åˆ›å»ºæŸ¥è¯¢å®¢æˆ·ç«¯
func NewTempoQuerier(baseURL string) *TempoQuerier {
    return &TempoQuerier{
        baseURL: baseURL,
        client:  &http.Client{},
    }
}

// TraceQLQuery TraceQL æŸ¥è¯¢ç»“æœ
type TraceQLQuery struct {
    TraceID    string            `json:"traceID"`
    RootService string           `json:"rootServiceName"`
    RootSpan   string            `json:"rootTraceName"`
    StartTime  int64             `json:"startTimeUnixNano"`
    Duration   int64             `json:"durationMs"`
    SpanSets   []SpanSet         `json:"spanSets"`
}

// SpanSet Span é›†åˆ
type SpanSet struct {
    Spans      []Span            `json:"spans"`
    Matched    int               `json:"matched"`
}

// Span Span ä¿¡æ¯
type Span struct {
    SpanID         string            `json:"spanID"`
    StartTime      int64             `json:"startTimeUnixNano"`
    Duration       int64             `json:"durationNanos"`
    Attributes     map[string]string `json:"attributes"`
}

// SearchWithTraceQL ä½¿ç”¨ TraceQL æœç´¢
func (q *TempoQuerier) SearchWithTraceQL(ctx context.Context, query string) ([]TraceQLQuery, error) {
    // æ„å»ºæŸ¥è¯¢ URL
    searchURL := fmt.Sprintf("%s/api/search", q.baseURL)
    params := url.Values{}
    params.Add("q", query)

    req, err := http.NewRequestWithContext(ctx, "GET", searchURL+"?"+params.Encode(), nil)
    if err != nil {
        return nil, fmt.Errorf("failed to create request: %w", err)
    }

    resp, err := q.client.Do(req)
    if err != nil {
        return nil, fmt.Errorf("failed to execute request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return nil, fmt.Errorf("query failed: %s, body: %s", resp.Status, string(body))
    }

    var result struct {
        Traces []TraceQLQuery `json:"traces"`
    }

    if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
        return nil, fmt.Errorf("failed to decode response: %w", err)
    }

    return result.Traces, nil
}

// GetTraceByID é€šè¿‡ TraceID è·å–å®Œæ•´è¿½è¸ª
func (q *TempoQuerier) GetTraceByID(ctx context.Context, traceID string) (map[string]interface{}, error) {
    traceURL := fmt.Sprintf("%s/api/traces/%s", q.baseURL, traceID)

    req, err := http.NewRequestWithContext(ctx, "GET", traceURL, nil)
    if err != nil {
        return nil, fmt.Errorf("failed to create request: %w", err)
    }

    resp, err := q.client.Do(req)
    if err != nil {
        return nil, fmt.Errorf("failed to execute request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("trace not found: %s", traceID)
    }

    var trace map[string]interface{}
    if err := json.NewDecoder(resp.Body).Decode(&trace); err != nil {
        return nil, fmt.Errorf("failed to decode trace: %w", err)
    }

    return trace, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleTraceQL() {
    querier := NewTempoQuerier("http://localhost:3200")
    ctx := context.Background()

    // æŸ¥æ‰¾æ…¢æŸ¥è¯¢
    traces, err := querier.SearchWithTraceQL(ctx, `{ duration > 1s && status = error }`)
    if err != nil {
        fmt.Printf("Query failed: %v\n", err)
        return
    }

    fmt.Printf("Found %d traces\n", len(traces))
    for _, trace := range traces {
        fmt.Printf("TraceID: %s, Duration: %dms, Service: %s\n",
            trace.TraceID, trace.Duration, trace.RootService)

        // è·å–å®Œæ•´è¿½è¸ªè¯¦æƒ…
        detail, err := querier.GetTraceByID(ctx, trace.TraceID)
        if err != nil {
            fmt.Printf("Failed to get trace detail: %v\n", err)
            continue
        }

        fmt.Printf("Trace detail: %+v\n", detail)
    }
}
```

### 2. Metrics Generator (åº¦é‡ç”Ÿæˆå™¨)

Tempo å¯ä»¥ä»è¿½è¸ªæ•°æ®ä¸­ç”Ÿæˆåº¦é‡æŒ‡æ ‡ã€‚

#### é…ç½® Metrics Generator

```yaml
# tempo-config.yaml
metrics_generator:
  # å¯ç”¨åº¦é‡ç”Ÿæˆå™¨
  registry:
    external_labels:
      source: tempo
      cluster: production
  
  # å­˜å‚¨é…ç½®
  storage:
    path: /var/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true
  
  # ç”Ÿæˆå™¨é…ç½®
  processor:
    # æœåŠ¡å›¾ç”Ÿæˆå™¨ (Service Graph)
    service_graphs:
      enabled: true
      max_items: 10000
      wait: 10s
      workers: 10
    
    # Span åº¦é‡ç”Ÿæˆå™¨
    span_metrics:
      enabled: true
      dimensions:
        - http.method
        - http.status_code
        - service.name
      intrinsic_dimensions:
        service: true
        span_name: true
        span_kind: true
        status_code: true
```

#### Go ä»£ç ä¸­å¯ç”¨ Exemplars

```go
package main

import (
    "context"
    "time"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/metric"
    "go.opentelemetry.io/otel/trace"
)

var (
    tracer = otel.Tracer("example-service")
    meter  = otel.Meter("example-service")
)

// MetricsWithExemplars å¸¦ Exemplars çš„åº¦é‡
type MetricsWithExemplars struct {
    requestDuration metric.Float64Histogram
    requestCounter  metric.Int64Counter
}

func NewMetricsWithExemplars() (*MetricsWithExemplars, error) {
    // åˆ›å»ºç›´æ–¹å›¾ (è®°å½•è¯·æ±‚æ—¶é•¿)
    requestDuration, err := meter.Float64Histogram(
        "http.server.duration",
        metric.WithDescription("HTTP request duration"),
        metric.WithUnit("ms"),
    )
    if err != nil {
        return nil, err
    }

    // åˆ›å»ºè®¡æ•°å™¨ (è®°å½•è¯·æ±‚æ¬¡æ•°)
    requestCounter, err := meter.Int64Counter(
        "http.server.requests",
        metric.WithDescription("HTTP request count"),
    )
    if err != nil {
        return nil, err
    }

    return &MetricsWithExemplars{
        requestDuration: requestDuration,
        requestCounter:  requestCounter,
    }, nil
}

// RecordRequest è®°å½•è¯·æ±‚ (è‡ªåŠ¨å…³è” Trace)
func (m *MetricsWithExemplars) RecordRequest(ctx context.Context, duration time.Duration, statusCode int, method string) {
    // è·å–å½“å‰ Span çš„ TraceID å’Œ SpanID
    span := trace.SpanFromContext(ctx)
    spanContext := span.SpanContext()

    attrs := []attribute.KeyValue{
        attribute.String("http.method", method),
        attribute.Int("http.status_code", statusCode),
    }

    // è®°å½•æ—¶é•¿ (Tempo ä¼šè‡ªåŠ¨æå– TraceID ä½œä¸º Exemplar)
    m.requestDuration.Record(ctx, duration.Seconds()*1000, metric.WithAttributes(attrs...))

    // è®°å½•è®¡æ•°
    m.requestCounter.Add(ctx, 1, metric.WithAttributes(attrs...))

    // æ—¥å¿—ä¸­åŒ…å« TraceID (ä¾¿äºå…³è”)
    if spanContext.IsValid() {
        span.AddEvent("metrics_recorded",
            trace.WithAttributes(
                attribute.String("trace_id", spanContext.TraceID().String()),
                attribute.String("span_id", spanContext.SpanID().String()),
            ),
        )
    }
}

// ä½¿ç”¨ç¤ºä¾‹
func HandleRequest(ctx context.Context, metrics *MetricsWithExemplars) {
    start := time.Now()

    ctx, span := tracer.Start(ctx, "HandleRequest")
    defer span.End()

    // ä¸šåŠ¡é€»è¾‘
    time.Sleep(100 * time.Millisecond)

    // è®°å½•åº¦é‡ (è‡ªåŠ¨å…³è” Trace)
    duration := time.Since(start)
    metrics.RecordRequest(ctx, duration, 200, "GET")
}
```

### 3. æœåŠ¡å›¾ (Service Graph)

Tempo å¯ä»¥è‡ªåŠ¨ç”ŸæˆæœåŠ¡ä¾èµ–å…³ç³»å›¾ã€‚

#### æŸ¥è¯¢æœåŠ¡å›¾

```go
package tempo

import (
    "context"
    "encoding/json"
    "fmt"
    "net/http"
)

// ServiceGraph æœåŠ¡å›¾
type ServiceGraph struct {
    Nodes []ServiceNode `json:"nodes"`
    Edges []ServiceEdge `json:"edges"`
}

// ServiceNode æœåŠ¡èŠ‚ç‚¹
type ServiceNode struct {
    ID          string  `json:"id"`
    Label       string  `json:"label"`
    Calls       int64   `json:"calls"`
    ErrorRate   float64 `json:"error_rate"`
    AvgDuration float64 `json:"avg_duration"`
}

// ServiceEdge æœåŠ¡è¾¹
type ServiceEdge struct {
    Source      string  `json:"source"`
    Target      string  `json:"target"`
    Calls       int64   `json:"calls"`
    ErrorRate   float64 `json:"error_rate"`
    AvgDuration float64 `json:"avg_duration"`
}

// GetServiceGraph è·å–æœåŠ¡å›¾
func (q *TempoQuerier) GetServiceGraph(ctx context.Context) (*ServiceGraph, error) {
    graphURL := fmt.Sprintf("%s/api/metrics/service_graph", q.baseURL)

    req, err := http.NewRequestWithContext(ctx, "GET", graphURL, nil)
    if err != nil {
        return nil, fmt.Errorf("failed to create request: %w", err)
    }

    resp, err := q.client.Do(req)
    if err != nil {
        return nil, fmt.Errorf("failed to execute request: %w", err)
    }
    defer resp.Body.Close()

    var graph ServiceGraph
    if err := json.NewDecoder(resp.Body).Decode(&graph); err != nil {
        return nil, fmt.Errorf("failed to decode service graph: %w", err)
    }

    return &graph, nil
}

// PrintServiceGraph æ‰“å°æœåŠ¡å›¾
func PrintServiceGraph(graph *ServiceGraph) {
    fmt.Println("=== Service Graph ===")
    fmt.Println("\nNodes:")
    for _, node := range graph.Nodes {
        fmt.Printf("  - %s: %d calls, %.2f%% errors, %.2fms avg\n",
            node.Label, node.Calls, node.ErrorRate*100, node.AvgDuration)
    }

    fmt.Println("\nEdges:")
    for _, edge := range graph.Edges {
        fmt.Printf("  - %s â†’ %s: %d calls, %.2f%% errors, %.2fms avg\n",
            edge.Source, edge.Target, edge.Calls, edge.ErrorRate*100, edge.AvgDuration)
    }
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. é‡‡æ ·ç­–ç•¥

```go
package tempo

import (
    "context"
    "fmt"
    "strings"

    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    "go.opentelemetry.io/otel/trace"
)

// AdaptiveSampler è‡ªé€‚åº”é‡‡æ ·å™¨
type AdaptiveSampler struct {
    baseSampler    sdktrace.Sampler
    errorSampler   sdktrace.Sampler
    slowSampler    sdktrace.Sampler
    slowThreshold  float64 // æ…¢è¯·æ±‚é˜ˆå€¼ (ç§’)
}

// NewAdaptiveSampler åˆ›å»ºè‡ªé€‚åº”é‡‡æ ·å™¨
func NewAdaptiveSampler(baseRate, errorRate, slowRate, slowThreshold float64) *AdaptiveSampler {
    return &AdaptiveSampler{
        baseSampler:   sdktrace.TraceIDRatioBased(baseRate),
        errorSampler:  sdktrace.TraceIDRatioBased(errorRate),
        slowSampler:   sdktrace.TraceIDRatioBased(slowRate),
        slowThreshold: slowThreshold,
    }
}

// ShouldSample é‡‡æ ·å†³ç­–
func (s *AdaptiveSampler) ShouldSample(params sdktrace.SamplingParameters) sdktrace.SamplingResult {
    // 1. æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å±æ€§
    for _, attr := range params.Attributes {
        if attr.Key == "error" && attr.Value.AsBool() {
            return s.errorSampler.ShouldSample(params)
        }
        if attr.Key == "http.status_code" {
            statusCode := attr.Value.AsInt64()
            if statusCode >= 400 {
                return s.errorSampler.ShouldSample(params)
            }
        }
    }

    // 2. æ£€æŸ¥æ˜¯å¦æ˜¯æ…¢è¯·æ±‚ (éœ€è¦åœ¨ Span ç»“æŸæ—¶åˆ¤æ–­,è¿™é‡Œä»…ç¤ºä¾‹)
    // å®é™…åœºæ™¯ä¸­å¯ä»¥é€šè¿‡è‡ªå®šä¹‰ SpanProcessor å®ç°

    // 3. é»˜è®¤é‡‡æ ·
    return s.baseSampler.ShouldSample(params)
}

// Description é‡‡æ ·å™¨æè¿°
func (s *AdaptiveSampler) Description() string {
    return fmt.Sprintf("AdaptiveSampler{base=%s,error=%s,slow=%s}",
        s.baseSampler.Description(),
        s.errorSampler.Description(),
        s.slowSampler.Description(),
    )
}

// HeadBasedSampler åŸºäºè¯·æ±‚å¤´çš„é‡‡æ ·å™¨
type HeadBasedSampler struct {
    defaultSampler sdktrace.Sampler
    forceSample    []string // å¼ºåˆ¶é‡‡æ ·çš„è·¯å¾„å‰ç¼€
}

// NewHeadBasedSampler åˆ›å»ºåŸºäºè¯·æ±‚å¤´çš„é‡‡æ ·å™¨
func NewHeadBasedSampler(defaultRate float64, forceSample []string) *HeadBasedSampler {
    return &HeadBasedSampler{
        defaultSampler: sdktrace.TraceIDRatioBased(defaultRate),
        forceSample:    forceSample,
    }
}

// ShouldSample é‡‡æ ·å†³ç­–
func (s *HeadBasedSampler) ShouldSample(params sdktrace.SamplingParameters) sdktrace.SamplingResult {
    // æ£€æŸ¥æ˜¯å¦åœ¨å¼ºåˆ¶é‡‡æ ·åˆ—è¡¨ä¸­
    for _, attr := range params.Attributes {
        if attr.Key == "http.target" {
            path := attr.Value.AsString()
            for _, prefix := range s.forceSample {
                if strings.HasPrefix(path, prefix) {
                    return sdktrace.SamplingResult{
                        Decision:   sdktrace.RecordAndSample,
                        Tracestate: trace.SpanContextFromContext(params.ParentContext).TraceState(),
                    }
                }
            }
        }
    }

    // é»˜è®¤é‡‡æ ·ç­–ç•¥
    return s.defaultSampler.ShouldSample(params)
}

// Description é‡‡æ ·å™¨æè¿°
func (s *HeadBasedSampler) Description() string {
    return fmt.Sprintf("HeadBasedSampler{default=%s,force=%v}",
        s.defaultSampler.Description(), s.forceSample)
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleAdaptiveSampler() {
    ctx := context.Background()

    // åˆ›å»ºè‡ªé€‚åº”é‡‡æ ·å™¨
    sampler := NewAdaptiveSampler(
        0.01,  // åŸºç¡€é‡‡æ ·ç‡ 1%
        1.0,   // é”™è¯¯å…¨é‡‡æ · 100%
        0.5,   // æ…¢è¯·æ±‚é‡‡æ ·ç‡ 50%
        1.0,   // æ…¢è¯·æ±‚é˜ˆå€¼ 1 ç§’
    )

    tempoExporter, _ := NewTempoExporter(ctx, &TempoConfig{
        Endpoint:    "localhost:4317",
        ServiceName: "adaptive-service",
        Insecure:    true,
    })
    defer tempoExporter.Shutdown(ctx)

    // æ‰‹åŠ¨è®¾ç½®é‡‡æ ·å™¨
    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(tempoExporter.exporter),
        sdktrace.WithSampler(sampler),
    )
    _ = tp
}
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–

```go
package tempo

import (
    "time"

    sdktrace "go.opentelemetry.io/otel/sdk/trace"
)

// BatchConfig æ‰¹å¤„ç†é…ç½®
type BatchConfig struct {
    MaxQueueSize       int           // æœ€å¤§é˜Ÿåˆ—å¤§å°
    BatchTimeout       time.Duration // æ‰¹å¤„ç†è¶…æ—¶
    ExportTimeout      time.Duration // å¯¼å‡ºè¶…æ—¶
    MaxExportBatchSize int           // æœ€å¤§æ‰¹å¤„ç†å¤§å°
}

// OptimizedBatchConfig ä¼˜åŒ–çš„æ‰¹å¤„ç†é…ç½®
func OptimizedBatchConfig(throughput string) BatchConfig {
    switch throughput {
    case "low": // < 100 spans/s
        return BatchConfig{
            MaxQueueSize:       512,
            BatchTimeout:       10 * time.Second,
            ExportTimeout:      30 * time.Second,
            MaxExportBatchSize: 128,
        }
    case "medium": // 100-1000 spans/s
        return BatchConfig{
            MaxQueueSize:       2048,
            BatchTimeout:       5 * time.Second,
            ExportTimeout:      30 * time.Second,
            MaxExportBatchSize: 512,
        }
    case "high": // > 1000 spans/s
        return BatchConfig{
            MaxQueueSize:       8192,
            BatchTimeout:       2 * time.Second,
            ExportTimeout:      30 * time.Second,
            MaxExportBatchSize: 2048,
        }
    default:
        return OptimizedBatchConfig("medium")
    }
}

// ApplyBatchConfig åº”ç”¨æ‰¹å¤„ç†é…ç½®
func ApplyBatchConfig(exporter sdktrace.SpanExporter, cfg BatchConfig) sdktrace.TracerProviderOption {
    return sdktrace.WithBatcher(exporter,
        sdktrace.WithMaxQueueSize(cfg.MaxQueueSize),
        sdktrace.WithBatchTimeout(cfg.BatchTimeout),
        sdktrace.WithExportTimeout(cfg.ExportTimeout),
        sdktrace.WithMaxExportBatchSize(cfg.MaxExportBatchSize),
    )
}
```

### 3. è¿æ¥æ± ä¼˜åŒ–

```go
package tempo

import (
    "time"

    "google.golang.org/grpc"
    "google.golang.org/grpc/keepalive"
)

// GRPCOptimizedDialOptions ä¼˜åŒ–çš„ gRPC è¿æ¥é€‰é¡¹
func GRPCOptimizedDialOptions() []grpc.DialOption {
    return []grpc.DialOption{
        // è¿æ¥æ± é…ç½®
        grpc.WithDefaultCallOptions(
            grpc.MaxCallRecvMsgSize(10 * 1024 * 1024), // 10MB
            grpc.MaxCallSendMsgSize(10 * 1024 * 1024), // 10MB
        ),

        // Keepalive é…ç½®
        grpc.WithKeepaliveParams(keepalive.ClientParameters{
            Time:                30 * time.Second, // æ¯ 30 ç§’å‘é€ keepalive ping
            Timeout:             10 * time.Second, // 10 ç§’å†…æ— å“åº”åˆ™æ–­å¼€
            PermitWithoutStream: true,             // æ— æ´»åŠ¨æµæ—¶ä¹Ÿå‘é€ ping
        }),

        // åˆå§‹çª—å£å¤§å°
        grpc.WithInitialWindowSize(1 << 20),     // 1MB
        grpc.WithInitialConnWindowSize(1 << 20), // 1MB

        // æœ€å¤§å¹¶å‘æµ
        grpc.WithDefaultServiceConfig(`{"loadBalancingPolicy":"round_robin"}`),
    }
}
```

---

## ç”Ÿäº§éƒ¨ç½²

### 1. Docker Compose éƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Tempo æœåŠ¡
  tempo:
    image: grafana/tempo:2.3.0
    container_name: tempo
    command: ["-config.file=/etc/tempo/tempo.yaml"]
    volumes:
      - ./tempo-config.yaml:/etc/tempo/tempo.yaml
      - tempo-data:/var/tempo
    ports:
      - "3200:3200"   # Tempo HTTP
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
      - "9095:9095"   # Tempo gRPC
      - "14268:14268" # Jaeger ingest
    networks:
      - observability

  # Prometheus (ç”¨äºå­˜å‚¨ Metrics Generator æ•°æ®)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-remote-write-receiver'
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - observability

  # Grafana (å¯è§†åŒ–)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - ./grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
      - grafana-data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - observability
    depends_on:
      - tempo
      - prometheus

volumes:
  tempo-data:
  prometheus-data:
  grafana-data:

networks:
  observability:
    driver: bridge
```

#### Grafana æ•°æ®æºé…ç½®

```yaml
# grafana-datasources.yml
apiVersion: 1

datasources:
  - name: Tempo
    type: tempo
    access: proxy
    url: http://tempo:3200
    jsonData:
      httpMethod: GET
      tracesToLogs:
        datasourceUid: 'loki'
        tags: ['job', 'instance', 'pod', 'namespace']
        mappedTags: [{ key: 'service.name', value: 'service' }]
        mapTagNamesEnabled: false
        spanStartTimeShift: '1h'
        spanEndTimeShift: '1h'
      tracesToMetrics:
        datasourceUid: 'prometheus'
        tags: [{ key: 'service.name', value: 'service' }]
        queries:
          - name: 'Sample query'
            query: 'sum(rate(traces_spanmetrics_latency_bucket{$__tags}[5m]))'
      serviceMap:
        datasourceUid: 'prometheus'
      search:
        hide: false
      nodeGraph:
        enabled: true

  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    jsonData:
      httpMethod: POST
      exemplarTraceIdDestinations:
        - name: traceID
          datasourceUid: tempo
```

### 2. Kubernetes éƒ¨ç½²

```yaml
# tempo-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo-config
  namespace: observability
data:
  tempo.yaml: |
    server:
      http_listen_port: 3200
      grpc_listen_port: 9095

    distributor:
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318

    ingester:
      max_block_duration: 5m
      max_block_bytes: 1048576

    compactor:
      compaction:
        block_retention: 168h

    storage:
      trace:
        backend: s3
        s3:
          bucket: tempo-traces
          endpoint: s3.amazonaws.com
          access_key: ${AWS_ACCESS_KEY_ID}
          secret_key: ${AWS_SECRET_ACCESS_KEY}
          region: us-east-1
        wal:
          path: /var/tempo/wal

    querier:
      frontend_worker:
        frontend_address: tempo-query-frontend:9095

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tempo
  namespace: observability
spec:
  replicas: 3
  selector:
    matchLabels:
      app: tempo
  template:
    metadata:
      labels:
        app: tempo
    spec:
      containers:
      - name: tempo
        image: grafana/tempo:2.3.0
        args:
          - "-config.file=/etc/tempo/tempo.yaml"
        ports:
        - containerPort: 3200
          name: http
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        - containerPort: 9095
          name: grpc
        volumeMounts:
        - name: config
          mountPath: /etc/tempo
        - name: storage
          mountPath: /var/tempo
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /ready
            port: 3200
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3200
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: tempo-config
      - name: storage
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: tempo
  namespace: observability
spec:
  selector:
    app: tempo
  ports:
  - name: http
    port: 3200
    targetPort: 3200
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
  - name: grpc
    port: 9095
    targetPort: 9095
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: tempo-otlp
  namespace: observability
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
spec:
  selector:
    app: tempo
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  type: LoadBalancer
```

### 3. ç”Ÿäº§é…ç½®ä¼˜åŒ–

```yaml
# tempo-production.yaml
server:
  http_listen_port: 3200
  grpc_listen_port: 9095
  log_level: info
  log_format: json

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
          # gRPC ä¼˜åŒ–
          max_recv_msg_size: 10485760  # 10MB
          max_concurrent_streams: 1000
        http:
          endpoint: 0.0.0.0:4318
  
  # é™æµé…ç½®
  rate_limiting:
    enabled: true
    rate: 10000  # 10K spans/s per distributor
    burst: 20000
  
  # æ—¥å¿—ä¸¢å¼ƒç­–ç•¥
  log_received_spans:
    enabled: false
    include_all_attributes: false

ingester:
  # å—é…ç½®
  max_block_duration: 10m      # ç”Ÿäº§ç¯å¢ƒé€‚å½“å¢å¤§
  max_block_bytes: 10485760    # 10MB
  complete_block_timeout: 30m
  
  # ç”Ÿå‘½å‘¨æœŸé…ç½®
  lifecycler:
    ring:
      replication_factor: 3
      kvstore:
        store: etcd
        etcd:
          endpoints:
            - http://etcd-1:2379
            - http://etcd-2:2379
            - http://etcd-3:2379
    
    # å¥åº·æ£€æŸ¥
    heartbeat_period: 5s
    heartbeat_timeout: 1m

compactor:
  compaction:
    block_retention: 720h  # 30 days
    compacted_block_retention: 1h
    compaction_window: 1h
    max_block_bytes: 107374182400  # 100GB
    max_compaction_objects: 10000000
  
  ring:
    kvstore:
      store: etcd
      etcd:
        endpoints:
          - http://etcd-1:2379
          - http://etcd-2:2379
          - http://etcd-3:2379

storage:
  trace:
    backend: s3
    s3:
      bucket: tempo-prod-traces
      endpoint: s3.amazonaws.com
      region: us-east-1
      access_key: ${AWS_ACCESS_KEY_ID}
      secret_key: ${AWS_SECRET_ACCESS_KEY}
      insecure: false
      # S3 ä¼˜åŒ–
      part_size: 5242880  # 5MB
      hedge_requests_at: 500ms
      hedge_requests_up_to: 2
    
    wal:
      path: /var/tempo/wal
      encoding: snappy
    
    # å—é…ç½®
    block:
      version: vParquet3
      encoding: zstd
    
    # ç¼“å­˜é…ç½®
    cache: memcached
    memcached:
      host: memcached:11211
      timeout: 500ms
      max_idle_conns: 100
      max_item_size: 5242880  # 5MB
    
    # åå°ç¼“å­˜é…ç½®
    background_cache:
      writeback_goroutines: 10
      writeback_buffer: 10000

querier:
  max_concurrent_queries: 20
  
  frontend_worker:
    frontend_address: tempo-query-frontend:9095
    parallelism: 10
    match_max_concurrent: true
  
  # æŸ¥è¯¢è¶…æ—¶
  search:
    external_endpoints: []
    external_hedge_requests_at: 8s
    external_hedge_requests_up_to: 2

query_frontend:
  max_outstanding_per_tenant: 2000
  max_retries: 2
  
  search:
    concurrent_jobs: 1000
    target_bytes_per_job: 104857600  # 100MB
    max_duration: 168h

metrics_generator:
  registry:
    external_labels:
      source: tempo
      environment: production
  
  storage:
    path: /var/tempo/generator/wal
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true
        queue_config:
          capacity: 10000
          max_shards: 50
          min_shards: 1
          max_samples_per_send: 2000
          batch_send_deadline: 5s
  
  processor:
    service_graphs:
      enabled: true
      max_items: 100000
      wait: 30s
      workers: 50
    
    span_metrics:
      enabled: true
      dimensions:
        - http.method
        - http.status_code
        - service.name
        - deployment.environment
      intrinsic_dimensions:
        service: true
        span_name: true
        span_kind: true
        status_code: true
      filter_policies:
        - include:
            match_type: strict
            attributes:
              - key: service.name
                value: critical-service

overrides:
  per_tenant_override_config: /etc/tempo/overrides.yaml
  per_tenant_override_period: 10s

# é™åˆ¶é…ç½®
limits:
  # å…¨å±€é™åˆ¶
  max_traces_per_user: 100000
  max_bytes_per_trace: 5242880  # 5MB
  
  # æœç´¢é™åˆ¶
  max_search_duration: 168h
  
  # æ‘„å…¥é™åˆ¶
  ingestion_rate_strategy: global
  ingestion_rate_limit_bytes: 50000000  # 50MB/s
  ingestion_burst_size_bytes: 100000000 # 100MB
```

---

## æœ€ä½³å®è·µ

### 1. å±æ€§å‘½åè§„èŒƒ

```go
package tempo

import (
    "go.opentelemetry.io/otel/attribute"
    semconv "go.opentelemetry.io/otel/semconv/v1.24.0"
)

// æ¨èçš„å±æ€§å‘½å
var (
    // HTTP å±æ€§
    HTTPMethod     = semconv.HTTPMethod
    HTTPStatusCode = semconv.HTTPStatusCode
    HTTPRoute      = semconv.HTTPRoute
    HTTPURL        = semconv.HTTPURL
    
    // æ•°æ®åº“å±æ€§
    DBSystem    = semconv.DBSystem
    DBName      = semconv.DBName
    DBStatement = semconv.DBStatement
    DBOperation = semconv.DBOperation
    
    // æ¶ˆæ¯é˜Ÿåˆ—å±æ€§
    MessagingSystem      = semconv.MessagingSystem
    MessagingDestination = semconv.MessagingDestination
    MessagingOperation   = semconv.MessagingOperation
    
    // RPC å±æ€§
    RPCSystem  = semconv.RPCSystem
    RPCService = semconv.RPCService
    RPCMethod  = semconv.RPCMethod
    
    // è‡ªå®šä¹‰ä¸šåŠ¡å±æ€§ (å»ºè®®ä½¿ç”¨åŸŸåå‰ç¼€)
    UserID       = attribute.Key("app.user.id")
    TenantID     = attribute.Key("app.tenant.id")
    OrderID      = attribute.Key("app.order.id")
    BusinessUnit = attribute.Key("app.business.unit")
)

// SetBusinessAttributes è®¾ç½®ä¸šåŠ¡å±æ€§
func SetBusinessAttributes(span trace.Span, userID, orderID string) {
    span.SetAttributes(
        UserID.String(userID),
        OrderID.String(orderID),
    )
}
```

### 2. é”™è¯¯å¤„ç†æœ€ä½³å®è·µ

```go
package tempo

import (
    "context"
    "fmt"

    "go.opentelemetry.io/otel/codes"
    "go.opentelemetry.io/otel/trace"
)

// RecordError è®°å½•é”™è¯¯çš„æœ€ä½³å®è·µ
func RecordError(ctx context.Context, err error, additionalInfo ...string) {
    span := trace.SpanFromContext(ctx)
    
    // 1. è®°å½•é”™è¯¯
    span.RecordError(err)
    
    // 2. è®¾ç½®çŠ¶æ€
    span.SetStatus(codes.Error, err.Error())
    
    // 3. æ·»åŠ é¢å¤–ä¿¡æ¯
    if len(additionalInfo) > 0 {
        span.AddEvent("error_context",
            trace.WithAttributes(
                attribute.String("context", additionalInfo[0]),
            ),
        )
    }
}

// HandleDBError å¤„ç†æ•°æ®åº“é”™è¯¯ç¤ºä¾‹
func HandleDBError(ctx context.Context, operation string, err error) error {
    span := trace.SpanFromContext(ctx)
    
    span.RecordError(err,
        trace.WithAttributes(
            attribute.String("db.operation", operation),
            attribute.String("error.type", fmt.Sprintf("%T", err)),
        ),
    )
    
    span.SetStatus(codes.Error, fmt.Sprintf("DB operation failed: %s", operation))
    
    return fmt.Errorf("database %s failed: %w", operation, err)
}
```

### 3. è¿½è¸ªä¸Šä¸‹æ–‡ä¼ æ’­

```go
package tempo

import (
    "context"
    "net/http"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/propagation"
)

// InjectTraceContext æ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡åˆ° HTTP è¯·æ±‚
func InjectTraceContext(ctx context.Context, req *http.Request) {
    otel.GetTextMapPropagator().Inject(ctx, propagation.HeaderCarrier(req.Header))
}

// ExtractTraceContext ä» HTTP è¯·æ±‚æå–è¿½è¸ªä¸Šä¸‹æ–‡
func ExtractTraceContext(req *http.Request) context.Context {
    return otel.GetTextMapPropagator().Extract(req.Context(), propagation.HeaderCarrier(req.Header))
}

// HTTPClient å¸¦è¿½è¸ªçš„ HTTP å®¢æˆ·ç«¯
func HTTPClient(ctx context.Context, url string) (*http.Response, error) {
    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        return nil, err
    }
    
    // æ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡
    InjectTraceContext(ctx, req)
    
    return http.DefaultClient.Do(req)
}
```

---

## æ•…éšœæ’æŸ¥

### 1. å¸¸è§é—®é¢˜

```text
é—®é¢˜ 1: è¿½è¸ªæ•°æ®æœªæ˜¾ç¤º
åŸå› :
  - Tempo æœåŠ¡æœªå¯åŠ¨
  - ç«¯å£é…ç½®é”™è¯¯
  - é‡‡æ ·ç‡è®¾ç½®ä¸º 0
  - é˜²ç«å¢™é˜»æ­¢è¿æ¥

æ’æŸ¥:
  1. æ£€æŸ¥ Tempo æœåŠ¡çŠ¶æ€: docker ps | grep tempo
  2. æ£€æŸ¥ç«¯å£ç›‘å¬: netstat -tlnp | grep 4317
  3. æ£€æŸ¥é‡‡æ ·é…ç½®: ç¡®è®¤ SamplingRate > 0
  4. æµ‹è¯•è¿æ¥: telnet localhost 4317

é—®é¢˜ 2: æŸ¥è¯¢ TraceID å¤±è´¥
åŸå› :
  - TraceID æ ¼å¼é”™è¯¯
  - æ•°æ®è¿˜æœªå†™å…¥å­˜å‚¨
  - å­˜å‚¨åç«¯é…ç½®é”™è¯¯

æ’æŸ¥:
  1. éªŒè¯ TraceID æ ¼å¼: 32ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²
  2. ç­‰å¾…æ•°æ®åˆ·æ–°: é»˜è®¤ 5-10 åˆ†é’Ÿ
  3. æ£€æŸ¥å­˜å‚¨é…ç½®: æŸ¥çœ‹ storage é…ç½®æ®µ

é—®é¢˜ 3: æ€§èƒ½é—®é¢˜
åŸå› :
  - æ‰¹å¤„ç†é…ç½®ä¸å½“
  - è¿æ¥æ± ä¸è¶³
  - é‡‡æ ·ç‡è¿‡é«˜

æ’æŸ¥:
  1. è°ƒæ•´æ‰¹å¤„ç†å¤§å°: å¢å¤§ MaxQueueSize
  2. å¢åŠ è¿æ¥æ•°: è°ƒæ•´ gRPC è¿æ¥æ± 
  3. é™ä½é‡‡æ ·ç‡: è°ƒæ•´ SamplingRate

é—®é¢˜ 4: æ•°æ®ä¸¢å¤±
åŸå› :
  - é˜Ÿåˆ—æº¢å‡º
  - å¯¼å‡ºè¶…æ—¶
  - ç½‘ç»œé—®é¢˜

æ’æŸ¥:
  1. æ£€æŸ¥æ—¥å¿—: æŸ¥æ‰¾ "queue full" æˆ– "export timeout"
  2. å¢å¤§é˜Ÿåˆ—: è°ƒæ•´ MaxQueueSize
  3. å¢åŠ è¶…æ—¶: è°ƒæ•´ ExportTimeout
  4. å¯ç”¨é‡è¯•: é…ç½® retry policy
```

### 2. ç›‘æ§æŒ‡æ ‡

```yaml
# prometheus-rules.yml
groups:
  - name: tempo
    interval: 30s
    rules:
      # Distributor æŒ‡æ ‡
      - record: tempo_distributor_spans_received_rate
        expr: rate(tempo_distributor_spans_received_total[5m])
      
      - record: tempo_distributor_bytes_received_rate
        expr: rate(tempo_distributor_bytes_received_total[5m])
      
      - alert: TempoDistributorHighErrorRate
        expr: rate(tempo_distributor_spans_received_total{status="error"}[5m]) > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Tempo Distributor high error rate"
          description: "Distributor error rate is {{ $value }} spans/s"
      
      # Ingester æŒ‡æ ‡
      - record: tempo_ingester_blocks_flushed_rate
        expr: rate(tempo_ingester_blocks_flushed_total[5m])
      
      - alert: TempoIngesterHighMemory
        expr: process_resident_memory_bytes{job="tempo-ingester"} > 8589934592  # 8GB
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Tempo Ingester high memory usage"
          description: "Ingester memory usage is {{ $value | humanize }}B"
      
      # Querier æŒ‡æ ‡
      - record: tempo_querier_query_duration_99p
        expr: histogram_quantile(0.99, rate(tempo_querier_query_duration_seconds_bucket[5m]))
      
      - alert: TempoQuerierSlowQueries
        expr: tempo_querier_query_duration_99p > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Tempo Querier slow queries"
          description: "P99 query duration is {{ $value }}s"
      
      # Storage æŒ‡æ ‡
      - alert: TempoStorageErrors
        expr: rate(tempo_storage_errors_total[5m]) > 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Tempo Storage errors"
          description: "Storage error rate is {{ $value }} errors/s"
```

### 3. æ—¥å¿—åˆ†æ

```go
package tempo

import (
    "context"
    "log"
    "time"

    "go.opentelemetry.io/otel/trace"
)

// DebugLogger è°ƒè¯•æ—¥å¿—è®°å½•å™¨
type DebugLogger struct {
    tracer trace.Tracer
}

// NewDebugLogger åˆ›å»ºè°ƒè¯•æ—¥å¿—è®°å½•å™¨
func NewDebugLogger(tracerName string) *DebugLogger {
    return &DebugLogger{
        tracer: otel.Tracer(tracerName),
    }
}

// LogWithTrace å¸¦è¿½è¸ªä¿¡æ¯çš„æ—¥å¿—
func (l *DebugLogger) LogWithTrace(ctx context.Context, level, message string, args ...interface{}) {
    span := trace.SpanFromContext(ctx)
    spanContext := span.SpanContext()
    
    if spanContext.IsValid() {
        log.Printf("[%s] [TraceID: %s] [SpanID: %s] %s %v",
            level,
            spanContext.TraceID().String(),
            spanContext.SpanID().String(),
            message,
            args,
        )
    } else {
        log.Printf("[%s] [No Trace] %s %v", level, message, args)
    }
}

// DebugExporter è°ƒè¯•å¯¼å‡ºå™¨
type DebugExporter struct {
    exporter sdktrace.SpanExporter
}

// ExportSpans å¯¼å‡º Spans (å¸¦æ—¥å¿—)
func (e *DebugExporter) ExportSpans(ctx context.Context, spans []sdktrace.ReadOnlySpan) error {
    start := time.Now()
    err := e.exporter.ExportSpans(ctx, spans)
    duration := time.Since(start)
    
    if err != nil {
        log.Printf("[ERROR] Failed to export %d spans in %v: %v", len(spans), duration, err)
    } else {
        log.Printf("[INFO] Successfully exported %d spans in %v", len(spans), duration)
    }
    
    return err
}

// Shutdown å…³é—­å¯¼å‡ºå™¨
func (e *DebugExporter) Shutdown(ctx context.Context) error {
    return e.exporter.Shutdown(ctx)
}
```

---

## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

```text
âœ… Tempo ä¼˜åŠ¿:
  - æˆæœ¬æä½ (ä»…éœ€å¯¹è±¡å­˜å‚¨)
  - æ‰©å±•æ€§å¼º (æ— ç´¢å¼•è®¾è®¡)
  - ä¸ Grafana æ·±åº¦é›†æˆ
  - æ”¯æŒå¤šç§è¿½è¸ªæ ¼å¼

âœ… é›†æˆæ­¥éª¤:
  1. å®‰è£… OTLP ä¾èµ–åŒ…
  2. é…ç½® Tempo æœåŠ¡
  3. åˆ›å»º OTLP å¯¼å‡ºå™¨
  4. åº”ç”¨è¿½è¸ªä¸­é—´ä»¶
  5. è®¾ç½®é‡‡æ ·ç­–ç•¥

âœ… é«˜çº§ç‰¹æ€§:
  - TraceQL æŸ¥è¯¢è¯­è¨€
  - Metrics Generator
  - Service Graph
  - Exemplars å…³è”

âœ… æ€§èƒ½ä¼˜åŒ–:
  - è‡ªé€‚åº”é‡‡æ ·
  - æ‰¹å¤„ç†ä¼˜åŒ–
  - è¿æ¥æ± é…ç½®
  - ç¼“å­˜ç­–ç•¥

âœ… ç”Ÿäº§éƒ¨ç½²:
  - Docker Compose
  - Kubernetes
  - é«˜å¯ç”¨é…ç½®
  - ç›‘æ§å‘Šè­¦
```

### æ€§èƒ½åŸºå‡†

```text
Tempo æ€§èƒ½æŒ‡æ ‡:
  - ååé‡: 100K+ spans/s per instance
  - æŸ¥è¯¢å»¶è¿Ÿ: <100ms (TraceID æŸ¥è¯¢)
  - å­˜å‚¨æˆæœ¬: ~$0.02/GB/æœˆ (S3)
  - å‹ç¼©æ¯”: 10:1
  - æ•°æ®ä¿ç•™: å¯é…ç½® (é»˜è®¤ 7 å¤©)
```

### ä¸‹ä¸€æ­¥

```text
1. æ·±å…¥å­¦ä¹ :
   - TraceQL é«˜çº§æŸ¥è¯¢
   - Metrics Generator é…ç½®
   - å¤šç§Ÿæˆ·é…ç½®

2. é›†æˆæ‰©å±•:
   - é›†æˆ Loki (æ—¥å¿—)
   - é›†æˆ Mimir (æŒ‡æ ‡)
   - å®Œæ•´å¯è§‚æµ‹æ€§æ ˆ

3. ä¼˜åŒ–è°ƒä¼˜:
   - å­˜å‚¨åç«¯é€‰æ‹©
   - å‹ç¼©ç®—æ³•ä¼˜åŒ–
   - æŸ¥è¯¢æ€§èƒ½è°ƒä¼˜
```

---

**æ›´æ–°æ—¶é—´**: 2025-10-12  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
**ç»´æŠ¤å›¢é˜Ÿ**: OTLP Go Integration Team

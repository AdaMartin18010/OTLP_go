# Grafana Loki ä¸ OTLP å®Œæ•´é›†æˆæŒ‡å—ï¼ˆGo 1.25.1 - 2025ç‰ˆï¼‰

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
> **æ›´æ–°æ—¥æœŸ**: 2025-10-12  
> **Go ç‰ˆæœ¬**: 1.25.1+  
> **Loki ç‰ˆæœ¬**: 2.9.0+  
> **æŠ€æœ¯æ·±åº¦**: â­â­â­â­â­

---

## ğŸ“‹ ç›®å½•

- [Grafana Loki ä¸ OTLP å®Œæ•´é›†æˆæŒ‡å—ï¼ˆGo 1.25.1 - 2025ç‰ˆï¼‰](#grafana-loki-ä¸-otlp-å®Œæ•´é›†æˆæŒ‡å—go-1251---2025ç‰ˆ)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ç®€ä»‹](#ç®€ä»‹)
    - [ä»€ä¹ˆæ˜¯ Grafana Lokiï¼Ÿ](#ä»€ä¹ˆæ˜¯-grafana-loki)
    - [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
    - [ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”](#ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”)
  - [Grafana Loki æ¦‚è¿°](#grafana-loki-æ¦‚è¿°)
    - [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
    - [æ•°æ®æ¨¡å‹](#æ•°æ®æ¨¡å‹)
  - [å®Œæ•´é›†æˆç¤ºä¾‹](#å®Œæ•´é›†æˆç¤ºä¾‹)
    - [1. åŸºç¡€é…ç½®](#1-åŸºç¡€é…ç½®)
      - [go.mod ä¾èµ–](#gomod-ä¾èµ–)
    - [2. Loki Go Client](#2-loki-go-client)
    - [3. ç»“æ„åŒ–æ—¥å¿—é›†æˆ](#3-ç»“æ„åŒ–æ—¥å¿—é›†æˆ)
    - [4. HTTP è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶](#4-http-è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶)
    - [5. è¿½è¸ªä¸Šä¸‹æ–‡é›†æˆ](#5-è¿½è¸ªä¸Šä¸‹æ–‡é›†æˆ)
  - [é«˜çº§ç‰¹æ€§](#é«˜çº§ç‰¹æ€§)
    - [1. LogQL æŸ¥è¯¢è¯­è¨€](#1-logql-æŸ¥è¯¢è¯­è¨€)
      - [Go ä¸­ä½¿ç”¨ LogQL](#go-ä¸­ä½¿ç”¨-logql)
    - [2. æ—¥å¿—ç®¡é“å¤„ç†](#2-æ—¥å¿—ç®¡é“å¤„ç†)
    - [3. æ—¥å¿—èšåˆç»Ÿè®¡](#3-æ—¥å¿—èšåˆç»Ÿè®¡)
  - [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
    - [1. æ‰¹å¤„ç†ä¼˜åŒ–](#1-æ‰¹å¤„ç†ä¼˜åŒ–)
    - [2. å‹ç¼©ä¼˜åŒ–](#2-å‹ç¼©ä¼˜åŒ–)
    - [3. æ ‡ç­¾ä¼˜åŒ–](#3-æ ‡ç­¾ä¼˜åŒ–)
  - [ç”Ÿäº§éƒ¨ç½²](#ç”Ÿäº§éƒ¨ç½²)
    - [1. Docker Compose éƒ¨ç½²](#1-docker-compose-éƒ¨ç½²)
      - [Loki é…ç½®](#loki-é…ç½®)
      - [Promtail é…ç½®](#promtail-é…ç½®)
    - [2. Kubernetes éƒ¨ç½²](#2-kubernetes-éƒ¨ç½²)
  - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
    - [1. æ ‡ç­¾è®¾è®¡](#1-æ ‡ç­¾è®¾è®¡)
    - [2. æ—¥å¿—ç»“æ„åŒ–](#2-æ—¥å¿—ç»“æ„åŒ–)
    - [3. ä¿ç•™ç­–ç•¥](#3-ä¿ç•™ç­–ç•¥)
  - [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
    - [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
  - [æ€»ç»“](#æ€»ç»“)

---

## ç®€ä»‹

### ä»€ä¹ˆæ˜¯ Grafana Lokiï¼Ÿ

**Grafana Loki** æ˜¯ä¸€ä¸ªæ°´å¹³å¯æ‰©å±•ã€é«˜å¯ç”¨çš„å¤šç§Ÿæˆ·æ—¥å¿—èšåˆç³»ç»Ÿï¼Œå— Prometheus å¯å‘ã€‚
å®ƒä¸ç´¢å¼•æ—¥å¿—å†…å®¹ï¼Œåªç´¢å¼•æ ‡ç­¾ï¼Œä½¿å…¶æˆæœ¬æ•ˆç›Šæé«˜ã€‚

### æ ¸å¿ƒç‰¹æ€§

```text
âœ… æ ¸å¿ƒä¼˜åŠ¿:
  - æˆæœ¬æä½ (æ— å…¨æ–‡ç´¢å¼•)
  - äº‘åŸç”Ÿè®¾è®¡
  - ä¸ Grafana æ·±åº¦é›†æˆ
  - æ”¯æŒ LogQL æŸ¥è¯¢è¯­è¨€
  - æ°´å¹³å¯æ‰©å±•

âœ… æ€§èƒ½æŒ‡æ ‡:
  - æ‘„å…¥é€Ÿç‡: 100GB+/day per instance
  - æŸ¥è¯¢å»¶è¿Ÿ: <1s (æ ‡ç­¾æŸ¥è¯¢)
  - å­˜å‚¨æˆæœ¬: ~$0.02/GB/æœˆ
  - å‹ç¼©æ¯”: 10:1

âœ… é›†æˆèƒ½åŠ›:
  - Promtail (å®˜æ–¹é‡‡é›†å™¨)
  - Fluentd/Fluent Bit
  - Logstash
  - OTLP logs (å®éªŒæ€§)
  - Docker/Kubernetes åŸç”Ÿ

âœ… éƒ¨ç½²æ¨¡å¼:
  - å•æœºç‰ˆ (monolithic)
  - å¾®æœåŠ¡æ¨¡å¼ (distributor/ingester/querier)
  - ç®€å•å¯æ‰©å±•æ¨¡å¼ (SSD)
```

### ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”

| ç‰¹æ€§ | Loki | Elasticsearch | Splunk | CloudWatch |
|------|------|---------------|--------|------------|
| æˆæœ¬ | æä½ | é«˜ | æé«˜ | é«˜ |
| ç´¢å¼•æ–¹å¼ | ä»…æ ‡ç­¾ | å…¨æ–‡ç´¢å¼• | å…¨æ–‡ç´¢å¼• | éƒ¨åˆ†ç´¢å¼• |
| æŸ¥è¯¢èƒ½åŠ› | LogQL | DSL | SPL | CloudWatch Logs Insights |
| æ‰©å±•æ€§ | ä¼˜ç§€ | ä¼˜ç§€ | ä¼˜ç§€ | ä¼˜ç§€ |
| è¿ç»´å¤æ‚åº¦ | ä½ | é«˜ | ä¸­ | ä½ |
| Grafanaé›†æˆ | åŸç”Ÿ | æ’ä»¶ | æ’ä»¶ | æ’ä»¶ |

---

## Grafana Loki æ¦‚è¿°

### æ¶æ„è®¾è®¡

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Loki æ¶æ„                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Promtail â”‚  â”‚ Fluentd  â”‚  â”‚  App Log â”‚               â”‚
â”‚  â”‚  Agent   â”‚  â”‚  Plugin  â”‚  â”‚  Client  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜               â”‚
â”‚       â”‚             â”‚             â”‚                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                     â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚            â”‚   Distributor   â”‚  (è´Ÿè½½å‡è¡¡/é™æµ)          â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                     â”‚                                   â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚       â”‚             â”‚             â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚Ingester â”‚  â”‚Ingester â”‚  â”‚Ingester â”‚  (ç¼“å†²/å‹ç¼©)      â”‚
â”‚  â”‚ Node 1  â”‚  â”‚ Node 2  â”‚  â”‚ Node 3  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                  â”‚
â”‚       â”‚             â”‚             â”‚                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                     â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚            â”‚ Object Storage  â”‚  (S3/GCS/Azure)          â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                     â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚            â”‚  Query Frontend â”‚  (æŸ¥è¯¢è°ƒåº¦)               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                     â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚            â”‚     Querier     â”‚  (æ—¥å¿—æ£€ç´¢)               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                     â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚            â”‚     Grafana     â”‚                          â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æ¨¡å‹

Loki ä½¿ç”¨æ ‡ç­¾+æ—¶é—´æˆ³+æ—¥å¿—è¡Œçš„æ¨¡å‹ï¼š

```text
{job="api-server", env="prod", level="error"} 2025-01-15T10:30:45Z Error: database connection failed
```

---

## å®Œæ•´é›†æˆç¤ºä¾‹

### 1. åŸºç¡€é…ç½®

#### go.mod ä¾èµ–

```go
module github.com/example/loki-integration

go 1.25.1

require (
    github.com/grafana/loki/pkg/push v0.0.0-20240115000000-000000000000
    github.com/prometheus/client_golang v1.18.0
    github.com/prometheus/common v0.45.0
    go.opentelemetry.io/otel v1.24.0
    go.opentelemetry.io/otel/exporters/otlp/otlplog v0.0.0-20240115000000-000000000000
    go.opentelemetry.io/otel/sdk/log v0.0.0-20240115000000-000000000000
    go.uber.org/zap v1.26.0
)
```

### 2. Loki Go Client

```go
package loki

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "time"

    "github.com/prometheus/common/model"
)

// LokiClient Loki å®¢æˆ·ç«¯
type LokiClient struct {
    url    string
    client *http.Client
    labels model.LabelSet
}

// NewLokiClient åˆ›å»º Loki å®¢æˆ·ç«¯
func NewLokiClient(url string, labels model.LabelSet) *LokiClient {
    return &LokiClient{
        url:    url,
        client: &http.Client{Timeout: 10 * time.Second},
        labels: labels,
    }
}

// PushRequest Loki push è¯·æ±‚
type PushRequest struct {
    Streams []Stream `json:"streams"`
}

// Stream æ—¥å¿—æµ
type Stream struct {
    Stream map[string]string `json:"stream"`
    Values [][]string        `json:"values"`
}

// SendLog å‘é€æ—¥å¿—
func (c *LokiClient) SendLog(ctx context.Context, line string, labels map[string]string) error {
    // åˆå¹¶é»˜è®¤æ ‡ç­¾å’Œè‡ªå®šä¹‰æ ‡ç­¾
    streamLabels := make(map[string]string)
    for k, v := range c.labels {
        streamLabels[string(k)] = string(v)
    }
    for k, v := range labels {
        streamLabels[k] = v
    }

    // æ„å»º push è¯·æ±‚
    timestamp := fmt.Sprintf("%d", time.Now().UnixNano())
    req := PushRequest{
        Streams: []Stream{
            {
                Stream: streamLabels,
                Values: [][]string{
                    {timestamp, line},
                },
            },
        },
    }

    // åºåˆ—åŒ–
    body, err := json.Marshal(req)
    if err != nil {
        return fmt.Errorf("failed to marshal request: %w", err)
    }

    // å‘é€è¯·æ±‚
    pushURL := fmt.Sprintf("%s/loki/api/v1/push", c.url)
    httpReq, err := http.NewRequestWithContext(ctx, "POST", pushURL, bytes.NewReader(body))
    if err != nil {
        return fmt.Errorf("failed to create request: %w", err)
    }
    httpReq.Header.Set("Content-Type", "application/json")

    resp, err := c.client.Do(httpReq)
    if err != nil {
        return fmt.Errorf("failed to send request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusNoContent && resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return fmt.Errorf("unexpected status code: %d, body: %s", resp.StatusCode, string(body))
    }

    return nil
}

// BatchSendLogs æ‰¹é‡å‘é€æ—¥å¿—
func (c *LokiClient) BatchSendLogs(ctx context.Context, logs []LogEntry) error {
    if len(logs) == 0 {
        return nil
    }

    // æŒ‰æ ‡ç­¾åˆ†ç»„
    streamMap := make(map[string]*Stream)
    
    for _, log := range logs {
        // åˆå¹¶æ ‡ç­¾
        streamLabels := make(map[string]string)
        for k, v := range c.labels {
            streamLabels[string(k)] = string(v)
        }
        for k, v := range log.Labels {
            streamLabels[k] = v
        }

        // è®¡ç®— stream key
        streamKey := labelsKey(streamLabels)
        
        if _, exists := streamMap[streamKey]; !exists {
            streamMap[streamKey] = &Stream{
                Stream: streamLabels,
                Values: [][]string{},
            }
        }

        timestamp := fmt.Sprintf("%d", log.Timestamp.UnixNano())
        streamMap[streamKey].Values = append(streamMap[streamKey].Values, []string{timestamp, log.Line})
    }

    // æ„å»ºè¯·æ±‚
    streams := make([]Stream, 0, len(streamMap))
    for _, stream := range streamMap {
        streams = append(streams, *stream)
    }

    req := PushRequest{Streams: streams}
    body, err := json.Marshal(req)
    if err != nil {
        return fmt.Errorf("failed to marshal request: %w", err)
    }

    // å‘é€è¯·æ±‚
    pushURL := fmt.Sprintf("%s/loki/api/v1/push", c.url)
    httpReq, err := http.NewRequestWithContext(ctx, "POST", pushURL, bytes.NewReader(body))
    if err != nil {
        return fmt.Errorf("failed to create request: %w", err)
    }
    httpReq.Header.Set("Content-Type", "application/json")

    resp, err := c.client.Do(httpReq)
    if err != nil {
        return fmt.Errorf("failed to send request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusNoContent && resp.StatusCode != http.StatusOK {
        respBody, _ := io.ReadAll(resp.Body)
        return fmt.Errorf("unexpected status code: %d, body: %s", resp.StatusCode, string(respBody))
    }

    return nil
}

// LogEntry æ—¥å¿—æ¡ç›®
type LogEntry struct {
    Timestamp time.Time
    Line      string
    Labels    map[string]string
}

// labelsKey ç”Ÿæˆæ ‡ç­¾é”®
func labelsKey(labels map[string]string) string {
    var buf bytes.Buffer
    for k, v := range labels {
        buf.WriteString(k)
        buf.WriteString("=")
        buf.WriteString(v)
        buf.WriteString(",")
    }
    return buf.String()
}
```

### 3. ç»“æ„åŒ–æ—¥å¿—é›†æˆ

```go
package loki

import (
    "context"
    "encoding/json"
    "fmt"
    "sync"
    "time"

    "github.com/prometheus/common/model"
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
)

// LokiWriter Loki æ—¥å¿—å†™å…¥å™¨
type LokiWriter struct {
    client     *LokiClient
    buffer     []LogEntry
    bufferSize int
    mu         sync.Mutex
    flushTimer *time.Timer
    done       chan struct{}
}

// NewLokiWriter åˆ›å»º Loki å†™å…¥å™¨
func NewLokiWriter(lokiURL string, labels model.LabelSet, bufferSize int, flushInterval time.Duration) *LokiWriter {
    writer := &LokiWriter{
        client:     NewLokiClient(lokiURL, labels),
        buffer:     make([]LogEntry, 0, bufferSize),
        bufferSize: bufferSize,
        done:       make(chan struct{}),
    }

    // å®šæœŸåˆ·æ–°
    writer.flushTimer = time.AfterFunc(flushInterval, func() {
        writer.Flush(context.Background())
        writer.flushTimer.Reset(flushInterval)
    })

    return writer
}

// Write å®ç° io.Writer æ¥å£
func (w *LokiWriter) Write(p []byte) (n int, err error) {
    w.mu.Lock()
    defer w.mu.Unlock()

    // è§£ææ—¥å¿—è¡Œ
    var logData map[string]interface{}
    if err := json.Unmarshal(p, &logData); err != nil {
        // å¦‚æœä¸æ˜¯ JSONï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬
        w.buffer = append(w.buffer, LogEntry{
            Timestamp: time.Now(),
            Line:      string(p),
            Labels:    map[string]string{},
        })
    } else {
        // æå–æ ‡ç­¾
        labels := extractLabels(logData)
        w.buffer = append(w.buffer, LogEntry{
            Timestamp: time.Now(),
            Line:      string(p),
            Labels:    labels,
        })
    }

    // å¦‚æœç¼“å†²åŒºæ»¡ï¼Œè§¦å‘åˆ·æ–°
    if len(w.buffer) >= w.bufferSize {
        go w.Flush(context.Background())
    }

    return len(p), nil
}

// Flush åˆ·æ–°ç¼“å†²åŒº
func (w *LokiWriter) Flush(ctx context.Context) error {
    w.mu.Lock()
    if len(w.buffer) == 0 {
        w.mu.Unlock()
        return nil
    }

    logs := make([]LogEntry, len(w.buffer))
    copy(logs, w.buffer)
    w.buffer = w.buffer[:0]
    w.mu.Unlock()

    return w.client.BatchSendLogs(ctx, logs)
}

// Close å…³é—­å†™å…¥å™¨
func (w *LokiWriter) Close() error {
    close(w.done)
    if w.flushTimer != nil {
        w.flushTimer.Stop()
    }
    return w.Flush(context.Background())
}

// extractLabels ä»æ—¥å¿—æ•°æ®ä¸­æå–æ ‡ç­¾
func extractLabels(logData map[string]interface{}) map[string]string {
    labels := make(map[string]string)
    
    // æå–å¸¸è§å­—æ®µä½œä¸ºæ ‡ç­¾
    if level, ok := logData["level"].(string); ok {
        labels["level"] = level
    }
    if service, ok := logData["service"].(string); ok {
        labels["service"] = service
    }
    if env, ok := logData["env"].(string); ok {
        labels["env"] = env
    }
    
    return labels
}

// NewZapLogger åˆ›å»ºå¸¦ Loki åç«¯çš„ Zap Logger
func NewZapLogger(lokiURL string, labels model.LabelSet) (*zap.Logger, error) {
    // åˆ›å»º Loki å†™å…¥å™¨
    lokiWriter := NewLokiWriter(lokiURL, labels, 100, 5*time.Second)

    // åˆ›å»ºç¼–ç å™¨é…ç½®
    encoderConfig := zapcore.EncoderConfig{
        TimeKey:        "ts",
        LevelKey:       "level",
        NameKey:        "logger",
        CallerKey:      "caller",
        FunctionKey:    zapcore.OmitKey,
        MessageKey:     "msg",
        StacktraceKey:  "stacktrace",
        LineEnding:     zapcore.DefaultLineEnding,
        EncodeLevel:    zapcore.LowercaseLevelEncoder,
        EncodeTime:     zapcore.ISO8601TimeEncoder,
        EncodeDuration: zapcore.SecondsDurationEncoder,
        EncodeCaller:   zapcore.ShortCallerEncoder,
    }

    // åˆ›å»º JSON ç¼–ç å™¨
    encoder := zapcore.NewJSONEncoder(encoderConfig)

    // åˆ›å»º core (å¤šè¾“å‡º)
    core := zapcore.NewTee(
        zapcore.NewCore(encoder, zapcore.AddSync(lokiWriter), zapcore.DebugLevel), // Loki
        zapcore.NewCore(encoder, zapcore.AddSync(zapcore.Lock(zapcore.AddSync(zapcore.Lock(zapcore.Lock(zapcore.Lock(zapcore.AddSync(nil)))))))), // Stdout (ç®€åŒ–)
    )

    return zap.New(core, zap.AddCaller(), zap.AddStacktrace(zapcore.ErrorLevel)), nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleLokiZapLogger() {
    labels := model.LabelSet{
        "app":     "my-service",
        "env":     "production",
        "version": "1.0.0",
    }

    logger, err := NewZapLogger("http://localhost:3100", labels)
    if err != nil {
        panic(err)
    }
    defer logger.Sync()

    // ä½¿ç”¨ logger
    logger.Info("Application started",
        zap.String("user_id", "123"),
        zap.Int("port", 8080),
    )

    logger.Error("Database connection failed",
        zap.String("database", "postgres"),
        zap.Error(fmt.Errorf("connection timeout")),
    )
}
```

### 4. HTTP è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶

```go
package loki

import (
    "context"
    "net/http"
    "time"

    "github.com/prometheus/common/model"
    "go.uber.org/zap"
)

// HTTPLoggingMiddleware HTTP æ—¥å¿—ä¸­é—´ä»¶
type HTTPLoggingMiddleware struct {
    logger *zap.Logger
    client *LokiClient
}

// NewHTTPLoggingMiddleware åˆ›å»º HTTP æ—¥å¿—ä¸­é—´ä»¶
func NewHTTPLoggingMiddleware(lokiURL string, labels model.LabelSet) (*HTTPLoggingMiddleware, error) {
    logger, err := NewZapLogger(lokiURL, labels)
    if err != nil {
        return nil, err
    }

    return &HTTPLoggingMiddleware{
        logger: logger,
        client: NewLokiClient(lokiURL, labels),
    }, nil
}

// Middleware ä¸­é—´ä»¶å‡½æ•°
func (m *HTTPLoggingMiddleware) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // åŒ…è£… ResponseWriter
        ww := &responseWriter{ResponseWriter: w, statusCode: http.StatusOK}

        // è°ƒç”¨ä¸‹ä¸€ä¸ªå¤„ç†å™¨
        next.ServeHTTP(ww, r)

        // è®°å½•æ—¥å¿—
        duration := time.Since(start)
        
        m.logger.Info("HTTP request",
            zap.String("method", r.Method),
            zap.String("path", r.URL.Path),
            zap.String("remote_addr", r.RemoteAddr),
            zap.Int("status_code", ww.statusCode),
            zap.Duration("duration", duration),
            zap.Int64("response_size", ww.size),
            zap.String("user_agent", r.UserAgent()),
        )

        // é”™è¯¯è¯·æ±‚å‘é€åˆ° Loki
        if ww.statusCode >= 400 {
            labels := map[string]string{
                "level":  "error",
                "method": r.Method,
                "path":   r.URL.Path,
                "status": fmt.Sprintf("%d", ww.statusCode),
            }

            logLine := fmt.Sprintf("%s %s %d %v", r.Method, r.URL.Path, ww.statusCode, duration)
            m.client.SendLog(context.Background(), logLine, labels)
        }
    })
}

type responseWriter struct {
    http.ResponseWriter
    statusCode int
    size       int64
}

func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

func (rw *responseWriter) Write(b []byte) (int, error) {
    size, err := rw.ResponseWriter.Write(b)
    rw.size += int64(size)
    return size, err
}
```

### 5. è¿½è¸ªä¸Šä¸‹æ–‡é›†æˆ

```go
package loki

import (
    "context"
    "fmt"

    "go.opentelemetry.io/otel/trace"
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
)

// TraceContextHook è¿½è¸ªä¸Šä¸‹æ–‡é’©å­
type TraceContextHook struct{}

// TraceContextField è¿½è¸ªä¸Šä¸‹æ–‡å­—æ®µ
func TraceContextField(ctx context.Context) []zapcore.Field {
    span := trace.SpanFromContext(ctx)
    if !span.SpanContext().IsValid() {
        return nil
    }

    sc := span.SpanContext()
    return []zapcore.Field{
        zap.String("trace_id", sc.TraceID().String()),
        zap.String("span_id", sc.SpanID().String()),
        zap.Bool("trace_sampled", sc.TraceFlags().IsSampled()),
    }
}

// LogWithTrace å¸¦è¿½è¸ªä¸Šä¸‹æ–‡çš„æ—¥å¿—
func LogWithTrace(ctx context.Context, logger *zap.Logger, level zapcore.Level, msg string, fields ...zapcore.Field) {
    // æ·»åŠ è¿½è¸ªå­—æ®µ
    traceFields := TraceContextField(ctx)
    allFields := append(traceFields, fields...)

    // æ ¹æ®çº§åˆ«è®°å½•æ—¥å¿—
    switch level {
    case zapcore.DebugLevel:
        logger.Debug(msg, allFields...)
    case zapcore.InfoLevel:
        logger.Info(msg, allFields...)
    case zapcore.WarnLevel:
        logger.Warn(msg, allFields...)
    case zapcore.ErrorLevel:
        logger.Error(msg, allFields...)
    case zapcore.DPanicLevel:
        logger.DPanic(msg, allFields...)
    case zapcore.PanicLevel:
        logger.Panic(msg, allFields...)
    case zapcore.FatalLevel:
        logger.Fatal(msg, allFields...)
    }
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleTraceContext(ctx context.Context) {
    labels := model.LabelSet{
        "app": "demo",
    }

    logger, _ := NewZapLogger("http://localhost:3100", labels)
    
    // å¸¦è¿½è¸ªä¸Šä¸‹æ–‡çš„æ—¥å¿—
    LogWithTrace(ctx, logger, zapcore.InfoLevel, "Processing request",
        zap.String("user_id", "123"),
        zap.String("action", "create_order"),
    )
}
```

---

## é«˜çº§ç‰¹æ€§

### 1. LogQL æŸ¥è¯¢è¯­è¨€

LogQL æ˜¯ Loki çš„æŸ¥è¯¢è¯­è¨€ï¼Œç±»ä¼¼ PromQLã€‚

```logql
# 1. åŸºç¡€æŸ¥è¯¢ - æŸ¥è¯¢ç‰¹å®šæ ‡ç­¾çš„æ—¥å¿—
{job="api-server", env="prod"}

# 2. æ­£åˆ™è¿‡æ»¤ - åŒ…å« "error"
{job="api-server"} |= "error"

# 3. æ­£åˆ™æ’é™¤ - ä¸åŒ…å« "debug"
{job="api-server"} != "debug"

# 4. æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
{job="api-server"} |~ "error|failed|exception"

# 5. JSON è§£æ
{job="api-server"} | json | level="error"

# 6. Pattern è§£æ
{job="api-server"} | pattern `<method> <path> <status>`

# 7. æ—¥å¿—é¢‘ç‡ç»Ÿè®¡
rate({job="api-server"}[5m])

# 8. é”™è¯¯ç‡ç»Ÿè®¡
sum(rate({job="api-server", level="error"}[5m])) / sum(rate({job="api-server"}[5m]))

# 9. æŒ‰æ ‡ç­¾èšåˆ
sum(rate({job="api-server"}[5m])) by (env)

# 10. Top N é”™è¯¯
topk(10, sum(rate({level="error"}[1h])) by (service))

# 11. æŒ‡æ ‡æŸ¥è¯¢ - è®¡ç®—å­—èŠ‚æ•°
sum(rate({job="api-server"} | json | __error__="" | unwrap bytes [5m])) by (env)

# 12. ç»„åˆæŸ¥è¯¢ - æ…¢è¯·æ±‚ä¸”æœ‰é”™è¯¯
{job="api-server"} | json | duration > 1000 and level="error"
```

#### Go ä¸­ä½¿ç”¨ LogQL

```go
package loki

import (
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "net/url"
    "time"
)

// LokiQuerier Loki æŸ¥è¯¢å®¢æˆ·ç«¯
type LokiQuerier struct {
    baseURL string
    client  *http.Client
}

// NewLokiQuerier åˆ›å»ºæŸ¥è¯¢å®¢æˆ·ç«¯
func NewLokiQuerier(baseURL string) *LokiQuerier {
    return &LokiQuerier{
        baseURL: baseURL,
        client:  &http.Client{Timeout: 30 * time.Second},
    }
}

// QueryResult æŸ¥è¯¢ç»“æœ
type QueryResult struct {
    Status string `json:"status"`
    Data   struct {
        ResultType string `json:"resultType"`
        Result     []struct {
            Stream map[string]string `json:"stream"`
            Values [][]string        `json:"values"`
        } `json:"result"`
    } `json:"data"`
}

// Query æ‰§è¡Œ LogQL æŸ¥è¯¢
func (q *LokiQuerier) Query(ctx context.Context, query string, limit int, start, end time.Time) (*QueryResult, error) {
    params := url.Values{}
    params.Add("query", query)
    params.Add("limit", fmt.Sprintf("%d", limit))
    if !start.IsZero() {
        params.Add("start", fmt.Sprintf("%d", start.UnixNano()))
    }
    if !end.IsZero() {
        params.Add("end", fmt.Sprintf("%d", end.UnixNano()))
    }

    queryURL := fmt.Sprintf("%s/loki/api/v1/query_range?%s", q.baseURL, params.Encode())
    
    req, err := http.NewRequestWithContext(ctx, "GET", queryURL, nil)
    if err != nil {
        return nil, err
    }

    resp, err := q.client.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, err
    }

    var result QueryResult
    if err := json.Unmarshal(body, &result); err != nil {
        return nil, err
    }

    return &result, nil
}

// QueryLabels æŸ¥è¯¢æ ‡ç­¾å€¼
func (q *LokiQuerier) QueryLabels(ctx context.Context, labelName string) ([]string, error) {
    labelsURL := fmt.Sprintf("%s/loki/api/v1/label/%s/values", q.baseURL, labelName)
    
    req, err := http.NewRequestWithContext(ctx, "GET", labelsURL, nil)
    if err != nil {
        return nil, err
    }

    resp, err := q.client.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, err
    }

    var result struct {
        Status string   `json:"status"`
        Data   []string `json:"data"`
    }

    if err := json.Unmarshal(body, &result); err != nil {
        return nil, err
    }

    return result.Data, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleLogQL() {
    querier := NewLokiQuerier("http://localhost:3100")
    ctx := context.Background()

    // æŸ¥è¯¢é”™è¯¯æ—¥å¿—
    result, err := querier.Query(ctx,
        `{job="api-server", level="error"}`,
        100,
        time.Now().Add(-1*time.Hour),
        time.Now(),
    )
    if err != nil {
        fmt.Printf("Query failed: %v\n", err)
        return
    }

    fmt.Printf("Found %d log streams\n", len(result.Data.Result))
    for _, stream := range result.Data.Result {
        fmt.Printf("Stream: %v, Entries: %d\n", stream.Stream, len(stream.Values))
    }

    // æŸ¥è¯¢æ ‡ç­¾å€¼
    labels, err := querier.QueryLabels(ctx, "level")
    if err != nil {
        fmt.Printf("Failed to query labels: %v\n", err)
        return
    }

    fmt.Printf("Available log levels: %v\n", labels)
}
```

### 2. æ—¥å¿—ç®¡é“å¤„ç†

```go
package loki

import (
    "encoding/json"
    "regexp"
    "strings"
)

// LogPipeline æ—¥å¿—ç®¡é“
type LogPipeline struct {
    filters []LogFilter
}

// LogFilter æ—¥å¿—è¿‡æ»¤å™¨
type LogFilter func(line string) (string, bool)

// NewLogPipeline åˆ›å»ºæ—¥å¿—ç®¡é“
func NewLogPipeline() *LogPipeline {
    return &LogPipeline{
        filters: []LogFilter{},
    }
}

// AddFilter æ·»åŠ è¿‡æ»¤å™¨
func (p *LogPipeline) AddFilter(filter LogFilter) *LogPipeline {
    p.filters = append(p.filters, filter)
    return p
}

// Process å¤„ç†æ—¥å¿—è¡Œ
func (p *LogPipeline) Process(line string) (string, bool) {
    for _, filter := range p.filters {
        var keep bool
        line, keep = filter(line)
        if !keep {
            return "", false
        }
    }
    return line, true
}

// å¸¸ç”¨è¿‡æ»¤å™¨

// RegexFilter æ­£åˆ™è¿‡æ»¤å™¨
func RegexFilter(pattern string, match bool) LogFilter {
    re := regexp.MustCompile(pattern)
    return func(line string) (string, bool) {
        matched := re.MatchString(line)
        if match {
            return line, matched
        }
        return line, !matched
    }
}

// JSONExtractor JSON æå–å™¨
func JSONExtractor(fields []string) LogFilter {
    return func(line string) (string, bool) {
        var data map[string]interface{}
        if err := json.Unmarshal([]byte(line), &data); err != nil {
            return line, true // ä¸æ˜¯ JSONï¼Œä¿æŒåŸæ ·
        }

        extracted := make(map[string]interface{})
        for _, field := range fields {
            if val, ok := data[field]; ok {
                extracted[field] = val
            }
        }

        result, _ := json.Marshal(extracted)
        return string(result), true
    }
}

// SensitiveDataMasker æ•æ„Ÿæ•°æ®è„±æ•
func SensitiveDataMasker() LogFilter {
    patterns := map[string]*regexp.Regexp{
        "email":      regexp.MustCompile(`\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b`),
        "phone":      regexp.MustCompile(`\b\d{3}[-.]?\d{3}[-.]?\d{4}\b`),
        "credit_card": regexp.MustCompile(`\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b`),
        "ssn":        regexp.MustCompile(`\b\d{3}-\d{2}-\d{4}\b`),
    }

    return func(line string) (string, bool) {
        result := line
        for _, re := range patterns {
            result = re.ReplaceAllString(result, "***REDACTED***")
        }
        return result, true
    }
}

// LevelFilter æ—¥å¿—çº§åˆ«è¿‡æ»¤å™¨
func LevelFilter(minLevel string) LogFilter {
    levels := map[string]int{
        "debug": 0,
        "info":  1,
        "warn":  2,
        "error": 3,
        "fatal": 4,
    }

    minLevelInt := levels[strings.ToLower(minLevel)]

    return func(line string) (string, bool) {
        var data map[string]interface{}
        if err := json.Unmarshal([]byte(line), &data); err != nil {
            return line, true
        }

        level, ok := data["level"].(string)
        if !ok {
            return line, true
        }

        levelInt := levels[strings.ToLower(level)]
        return line, levelInt >= minLevelInt
    }
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleLogPipeline() {
    pipeline := NewLogPipeline().
        AddFilter(RegexFilter("error|fatal", true)).      // åªä¿ç•™åŒ…å« error æˆ– fatal çš„è¡Œ
        AddFilter(SensitiveDataMasker()).                  // è„±æ•
        AddFilter(JSONExtractor([]string{"level", "msg", "ts"})) // æå–å­—æ®µ

    logs := []string{
        `{"level":"info","msg":"User logged in","email":"user@example.com"}`,
        `{"level":"error","msg":"Payment failed","card":"1234-5678-9012-3456"}`,
        `{"level":"debug","msg":"Debug info"}`,
    }

    for _, log := range logs {
        processed, keep := pipeline.Process(log)
        if keep {
            fmt.Println("Processed:", processed)
        } else {
            fmt.Println("Filtered out:", log)
        }
    }
}
```

### 3. æ—¥å¿—èšåˆç»Ÿè®¡

```go
package loki

import (
    "context"
    "fmt"
    "sync"
    "time"
)

// LogAggregator æ—¥å¿—èšåˆå™¨
type LogAggregator struct {
    stats map[string]*LogStats
    mu    sync.RWMutex
}

// LogStats æ—¥å¿—ç»Ÿè®¡
type LogStats struct {
    Count    int64
    Errors   int64
    Warnings int64
    LastSeen time.Time
}

// NewLogAggregator åˆ›å»ºæ—¥å¿—èšåˆå™¨
func NewLogAggregator() *LogAggregator {
    return &LogAggregator{
        stats: make(map[string]*LogStats),
    }
}

// Record è®°å½•æ—¥å¿—
func (a *LogAggregator) Record(service, level string) {
    a.mu.Lock()
    defer a.mu.Unlock()

    if _, exists := a.stats[service]; !exists {
        a.stats[service] = &LogStats{}
    }

    stats := a.stats[service]
    stats.Count++
    stats.LastSeen = time.Now()

    switch level {
    case "error":
        stats.Errors++
    case "warn":
        stats.Warnings++
    }
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (a *LogAggregator) GetStats(service string) *LogStats {
    a.mu.RLock()
    defer a.mu.RUnlock()

    if stats, exists := a.stats[service]; exists {
        return stats
    }
    return &LogStats{}
}

// GetAllStats è·å–æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯
func (a *LogAggregator) GetAllStats() map[string]*LogStats {
    a.mu.RLock()
    defer a.mu.RUnlock()

    result := make(map[string]*LogStats)
    for k, v := range a.stats {
        result[k] = v
    }
    return result
}

// ReportMetrics æŠ¥å‘Šåº¦é‡åˆ° Loki
func (a *LogAggregator) ReportMetrics(ctx context.Context, client *LokiClient) error {
    stats := a.GetAllStats()

    for service, stat := range stats {
        logLine := fmt.Sprintf("service=%s count=%d errors=%d warnings=%d",
            service, stat.Count, stat.Errors, stat.Warnings)

        labels := map[string]string{
            "service": service,
            "type":    "metrics",
        }

        if err := client.SendLog(ctx, logLine, labels); err != nil {
            return err
        }
    }

    return nil
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹å¤„ç†ä¼˜åŒ–

```go
package loki

import (
    "context"
    "sync"
    "time"
)

// BatchLogger æ‰¹å¤„ç†æ—¥å¿—è®°å½•å™¨
type BatchLogger struct {
    client        *LokiClient
    buffer        []LogEntry
    batchSize     int
    flushInterval time.Duration
    mu            sync.Mutex
    done          chan struct{}
}

// NewBatchLogger åˆ›å»ºæ‰¹å¤„ç†æ—¥å¿—è®°å½•å™¨
func NewBatchLogger(client *LokiClient, batchSize int, flushInterval time.Duration) *BatchLogger {
    bl := &BatchLogger{
        client:        client,
        buffer:        make([]LogEntry, 0, batchSize),
        batchSize:     batchSize,
        flushInterval: flushInterval,
        done:          make(chan struct{}),
    }

    go bl.periodicFlush()
    return bl
}

// Log è®°å½•æ—¥å¿—
func (bl *BatchLogger) Log(line string, labels map[string]string) {
    bl.mu.Lock()
    defer bl.mu.Unlock()

    bl.buffer = append(bl.buffer, LogEntry{
        Timestamp: time.Now(),
        Line:      line,
        Labels:    labels,
    })

    if len(bl.buffer) >= bl.batchSize {
        go bl.flush()
    }
}

// flush åˆ·æ–°ç¼“å†²åŒº
func (bl *BatchLogger) flush() {
    bl.mu.Lock()
    if len(bl.buffer) == 0 {
        bl.mu.Unlock()
        return
    }

    logs := make([]LogEntry, len(bl.buffer))
    copy(logs, bl.buffer)
    bl.buffer = bl.buffer[:0]
    bl.mu.Unlock()

    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()

    if err := bl.client.BatchSendLogs(ctx, logs); err != nil {
        // é”™è¯¯å¤„ç† (é‡è¯•/è®°å½•åˆ°æœ¬åœ°ç­‰)
        fmt.Printf("Failed to flush logs: %v\n", err)
    }
}

// periodicFlush å®šæœŸåˆ·æ–°
func (bl *BatchLogger) periodicFlush() {
    ticker := time.NewTicker(bl.flushInterval)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            bl.flush()
        case <-bl.done:
            bl.flush()
            return
        }
    }
}

// Close å…³é—­è®°å½•å™¨
func (bl *BatchLogger) Close() {
    close(bl.done)
    bl.flush()
}
```

### 2. å‹ç¼©ä¼˜åŒ–

```go
package loki

import (
    "bytes"
    "compress/gzip"
    "context"
    "fmt"
    "io"
    "net/http"
)

// CompressedLokiClient å‹ç¼©çš„ Loki å®¢æˆ·ç«¯
type CompressedLokiClient struct {
    *LokiClient
}

// NewCompressedLokiClient åˆ›å»ºå‹ç¼©å®¢æˆ·ç«¯
func NewCompressedLokiClient(url string, labels model.LabelSet) *CompressedLokiClient {
    return &CompressedLokiClient{
        LokiClient: NewLokiClient(url, labels),
    }
}

// BatchSendLogsCompressed æ‰¹é‡å‘é€å‹ç¼©æ—¥å¿—
func (c *CompressedLokiClient) BatchSendLogsCompressed(ctx context.Context, logs []LogEntry) error {
    if len(logs) == 0 {
        return nil
    }

    // æ„å»ºè¯·æ±‚ä½“
    req := c.buildPushRequest(logs)
    body, err := json.Marshal(req)
    if err != nil {
        return fmt.Errorf("failed to marshal request: %w", err)
    }

    // å‹ç¼©
    var compressed bytes.Buffer
    gz := gzip.NewWriter(&compressed)
    if _, err := gz.Write(body); err != nil {
        return fmt.Errorf("failed to compress: %w", err)
    }
    if err := gz.Close(); err != nil {
        return fmt.Errorf("failed to close gzip writer: %w", err)
    }

    // å‘é€è¯·æ±‚
    pushURL := fmt.Sprintf("%s/loki/api/v1/push", c.url)
    httpReq, err := http.NewRequestWithContext(ctx, "POST", pushURL, &compressed)
    if err != nil {
        return fmt.Errorf("failed to create request: %w", err)
    }
    httpReq.Header.Set("Content-Type", "application/json")
    httpReq.Header.Set("Content-Encoding", "gzip")

    resp, err := c.client.Do(httpReq)
    if err != nil {
        return fmt.Errorf("failed to send request: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusNoContent && resp.StatusCode != http.StatusOK {
        respBody, _ := io.ReadAll(resp.Body)
        return fmt.Errorf("unexpected status code: %d, body: %s", resp.StatusCode, string(respBody))
    }

    return nil
}

func (c *CompressedLokiClient) buildPushRequest(logs []LogEntry) PushRequest {
    // å®ç°ç•¥...
    return PushRequest{}
}
```

### 3. æ ‡ç­¾ä¼˜åŒ–

```go
package loki

// LabelOptimizer æ ‡ç­¾ä¼˜åŒ–å™¨
type LabelOptimizer struct {
    maxLabels      int
    allowedLabels  map[string]struct{}
    labelCache     map[string]map[string]string
}

// NewLabelOptimizer åˆ›å»ºæ ‡ç­¾ä¼˜åŒ–å™¨
func NewLabelOptimizer(maxLabels int, allowedLabels []string) *LabelOptimizer {
    allowed := make(map[string]struct{})
    for _, label := range allowedLabels {
        allowed[label] = struct{}{}
    }

    return &LabelOptimizer{
        maxLabels:     maxLabels,
        allowedLabels: allowed,
        labelCache:    make(map[string]map[string]string),
    }
}

// OptimizeLabels ä¼˜åŒ–æ ‡ç­¾
func (lo *LabelOptimizer) OptimizeLabels(labels map[string]string) map[string]string {
    optimized := make(map[string]string)
    count := 0

    for k, v := range labels {
        // æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨ä¸­
        if _, allowed := lo.allowedLabels[k]; !allowed {
            continue
        }

        // æ£€æŸ¥æ•°é‡é™åˆ¶
        if count >= lo.maxLabels {
            break
        }

        optimized[k] = v
        count++
    }

    return optimized
}
```

---

## ç”Ÿäº§éƒ¨ç½²

### 1. Docker Compose éƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    command: -config.file=/etc/loki/loki-config.yaml
    volumes:
      - ./loki-config.yaml:/etc/loki/loki-config.yaml
      - loki-data:/loki
    ports:
      - "3100:3100"
    networks:
      - logging
    restart: unless-stopped

  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    command: -config.file=/etc/promtail/promtail-config.yaml
    volumes:
      - ./promtail-config.yaml:/etc/promtail/promtail-config.yaml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    networks:
      - logging
    depends_on:
      - loki
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
    ports:
      - "3000:3000"
    networks:
      - logging
    depends_on:
      - loki
    restart: unless-stopped

volumes:
  loki-data:
  grafana-data:

networks:
  logging:
    driver: bridge
```

#### Loki é…ç½®

```yaml
# loki-config.yaml
auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096
  log_level: info

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

storage_config:
  boltdb_shipper:
    active_index_directory: /loki/boltdb-shipper-active
    cache_location: /loki/boltdb-shipper-cache
    cache_ttl: 24h
    shared_store: filesystem
  filesystem:
    directory: /loki/chunks

compactor:
  working_directory: /loki/boltdb-shipper-compactor
  shared_store: filesystem

limits_config:
  reject_old_samples: true
  reject_old_samples_max_age: 168h
  ingestion_rate_mb: 10
  ingestion_burst_size_mb: 20
  max_query_series: 1000
  max_query_parallelism: 32

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: true
  retention_period: 720h  # 30 days

ruler:
  alertmanager_url: http://alertmanager:9093
```

#### Promtail é…ç½®

```yaml
# promtail-config.yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Docker å®¹å™¨æ—¥å¿—
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      - source_labels: ['__meta_docker_container_log_stream']
        target_label: 'stream'
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: 'project'
      - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
        target_label: 'service'

  # ç³»ç»Ÿæ—¥å¿—
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: varlogs
          __path__: /var/log/*log
```

### 2. Kubernetes éƒ¨ç½²

```yaml
# loki-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: logging
data:
  loki.yaml: |
    auth_enabled: false
    server:
      http_listen_port: 3100
    
    ingester:
      lifecycler:
        ring:
          kvstore:
            store: memberlist
          replication_factor: 1
      chunk_idle_period: 30m
      chunk_block_size: 262144
      chunk_retain_period: 1m
      max_transfer_retries: 0
    
    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: s3
          schema: v11
          index:
            prefix: index_
            period: 24h
    
    storage_config:
      boltdb_shipper:
        active_index_directory: /data/loki/boltdb-shipper-active
        cache_location: /data/loki/boltdb-shipper-cache
        shared_store: s3
      aws:
        s3: s3://us-east-1/my-loki-bucket
        s3forcepathstyle: true
    
    limits_config:
      ingestion_rate_mb: 10
      ingestion_burst_size_mb: 20

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: logging
spec:
  serviceName: loki
  replicas: 3
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.0
        args:
          - -config.file=/etc/loki/loki.yaml
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9096
          name: grpc
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: storage
          mountPath: /data
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
      volumes:
      - name: config
        configMap:
          name: loki-config
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi

---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: logging
spec:
  selector:
    app: loki
  ports:
  - name: http
    port: 3100
    targetPort: 3100
  - name: grpc
    port: 9096
    targetPort: 9096
  type: ClusterIP
```

---

## æœ€ä½³å®è·µ

### 1. æ ‡ç­¾è®¾è®¡

```text
âœ… å¥½çš„æ ‡ç­¾è®¾è®¡:
  - ä½åŸºæ•°æ ‡ç­¾: service, environment, level
  - é™æ€æ ‡ç­¾: ä¸é¢‘ç¹å˜åŒ–çš„å€¼
  - æœ‰æ„ä¹‰çš„æ ‡ç­¾: ä¾¿äºè¿‡æ»¤å’Œèšåˆ

âŒ é¿å…çš„æ ‡ç­¾:
  - é«˜åŸºæ•°æ ‡ç­¾: user_id, request_id, trace_id
  - åŠ¨æ€æ ‡ç­¾: é¢‘ç¹å˜åŒ–çš„å€¼
  - æ— æ„ä¹‰æ ‡ç­¾: random_value

æ¨èæ ‡ç­¾é›†:
  - job/service: æœåŠ¡åç§°
  - env: ç¯å¢ƒ (dev/staging/prod)
  - level: æ—¥å¿—çº§åˆ« (debug/info/warn/error)
  - region: åœ°ç†åŒºåŸŸ
  - namespace: K8s å‘½åç©ºé—´
```

### 2. æ—¥å¿—ç»“æ„åŒ–

```json
{
  "ts": "2025-01-15T10:30:45Z",
  "level": "error",
  "service": "api-server",
  "msg": "Database connection failed",
  "error": "connection timeout",
  "duration_ms": 5000,
  "trace_id": "abc123",
  "span_id": "def456"
}
```

### 3. ä¿ç•™ç­–ç•¥

```yaml
limits_config:
  # 7å¤©å†…çš„æ—¥å¿—
  reject_old_samples: true
  reject_old_samples_max_age: 168h

table_manager:
  # ä¿ç•™30å¤©
  retention_deletes_enabled: true
  retention_period: 720h
```

---

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

```text
é—®é¢˜ 1: æ—¥å¿—æœªæ˜¾ç¤º
æ’æŸ¥:
  1. æ£€æŸ¥ Loki æœåŠ¡çŠ¶æ€
  2. æ£€æŸ¥å®¢æˆ·ç«¯è¿æ¥
  3. éªŒè¯æ ‡ç­¾é…ç½®
  4. æŸ¥çœ‹ Loki æ—¥å¿—

é—®é¢˜ 2: æŸ¥è¯¢æ…¢
æ’æŸ¥:
  1. å‡å°æ—¶é—´èŒƒå›´
  2. æ·»åŠ æ ‡ç­¾è¿‡æ»¤
  3. ä½¿ç”¨ç´¢å¼•æ ‡ç­¾
  4. å¢åŠ æŸ¥è¯¢å¹¶å‘åº¦

é—®é¢˜ 3: ç£ç›˜ç©ºé—´ä¸è¶³
æ’æŸ¥:
  1. æ£€æŸ¥ä¿ç•™æœŸè®¾ç½®
  2. å¯ç”¨å‹ç¼©
  3. æ¸…ç†æ—§æ•°æ®
  4. å¢åŠ å­˜å‚¨ç©ºé—´
```

---

## æ€»ç»“

```text
âœ… Loki ä¼˜åŠ¿:
  - æˆæœ¬æä½ (ä»…ç´¢å¼•æ ‡ç­¾)
  - äº‘åŸç”Ÿè®¾è®¡
  - ä¸ Grafana æ·±åº¦é›†æˆ
  - LogQL å¼ºå¤§æŸ¥è¯¢è¯­è¨€

âœ… é›†æˆæ­¥éª¤:
  1. åˆ›å»º Loki å®¢æˆ·ç«¯
  2. é…ç½®æ—¥å¿—è®°å½•å™¨
  3. è®¾è®¡æ ‡ç­¾ç­–ç•¥
  4. éƒ¨ç½² Loki æœåŠ¡
  5. é…ç½® Grafana

âœ… æœ€ä½³å®è·µ:
  - ä½åŸºæ•°æ ‡ç­¾è®¾è®¡
  - ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
  - æ‰¹å¤„ç†ä¼˜åŒ–
  - åˆç†ä¿ç•™ç­–ç•¥
```

---

**æ›´æ–°æ—¶é—´**: 2025-10-12  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
**ç»´æŠ¤å›¢é˜Ÿ**: OTLP Go Integration Team

# 46. 性能调优案例分析

## 📚 目录

- [1. 案例一：API 延迟优化](#1-案例一api-延迟优化)
- [2. 案例二：内存使用优化](#2-案例二内存使用优化)
- [3. 案例三：数据库性能优化](#3-案例三数据库性能优化)
- [4. 案例四：并发性能优化](#4-案例四并发性能优化)
- [5. 案例五：GC 优化](#5-案例五gc-优化)
- [6. 优化工具链](#6-优化工具链)
- [7. 总结](#7-总结)

---

## 1. 案例一：API 延迟优化

### 1.1 问题描述

**场景**: 商品列表 API P95 延迟达到 800ms，影响用户体验

**初始性能**:
- P50: 200ms
- P95: 800ms
- P99: 1500ms
- QPS: 500

### 1.2 性能分析

使用 OTLP Trace 分析：

```bash
# Jaeger UI 中查看慢请求
Service: product-service
Operation: GET /api/products
Duration: > 500ms
```

Trace 分析发现：
- 数据库查询: 150ms
- Redis 缓存未命中: 60%
- 序列化: 50ms
- 数据转换: 100ms

### 1.3 优化方案

#### 优化1: 添加缓存预热

**优化前**:

```go
func (s *Service) List(ctx context.Context, req *ListRequest) ([]*Product, error) {
    // 每次都查数据库
    var products []*Product
    if err := s.db.WithContext(ctx).
        Where("category = ?", req.Category).
        Find(&products).Error; err != nil {
        return nil, err
    }
    return products, nil
}
```

**优化后**:

```go
func (s *Service) List(ctx context.Context, req *ListRequest) ([]*Product, error) {
    ctx, span := s.tracer.Start(ctx, "product.list")
    defer span.End()
    
    // 1. 尝试从缓存获取
    cacheKey := fmt.Sprintf("products:category:%s:page:%d", req.Category, req.Page)
    
    if cached, err := s.redis.Get(ctx, cacheKey).Result(); err == nil {
        var products []*Product
        if json.Unmarshal([]byte(cached), &products) == nil {
            span.SetAttributes(attribute.Bool("cache.hit", true))
            return products, nil
        }
    }
    
    // 2. 缓存未命中，查询数据库
    span.SetAttributes(attribute.Bool("cache.hit", false))
    
    var products []*Product
    if err := s.db.WithContext(ctx).
        Where("category = ? AND status = ?", req.Category, "active").
        Offset((req.Page-1)*req.PageSize).
        Limit(req.PageSize).
        Find(&products).Error; err != nil {
        return nil, err
    }
    
    // 3. 写入缓存（异步）
    go func() {
        data, _ := json.Marshal(products)
        s.redis.Set(context.Background(), cacheKey, data, 5*time.Minute)
    }()
    
    return products, nil
}

// 缓存预热
func (s *Service) WarmupCache(ctx context.Context) error {
    categories := []string{"electronics", "clothing", "food"}
    
    for _, category := range categories {
        for page := 1; page <= 5; page++ {
            products, err := s.List(ctx, &ListRequest{
                Category: category,
                Page:     page,
                PageSize: 20,
            })
            if err != nil {
                return err
            }
            
            cacheKey := fmt.Sprintf("products:category:%s:page:%d", category, page)
            data, _ := json.Marshal(products)
            s.redis.Set(ctx, cacheKey, data, 5*time.Minute)
        }
    }
    
    return nil
}
```

#### 优化2: 使用连接池

```go
// Redis 连接池配置
rdb := redis.NewClient(&redis.Options{
    Addr:         "localhost:6379",
    PoolSize:     50,  // 增加连接池大小
    MinIdleConns: 10,  // 保持最小空闲连接
    PoolTimeout:  4 * time.Second,
    MaxRetries:   3,
})
```

#### 优化3: 批量查询

**优化前**:

```go
// N+1 查询问题
for _, product := range products {
    var category Category
    s.db.Where("id = ?", product.CategoryID).First(&category)
    product.Category = category
}
```

**优化后**:

```go
// 使用 Preload 或 JOIN
var products []*Product
s.db.Preload("Category").Find(&products)

// 或使用 IN 查询
categoryIDs := extractCategoryIDs(products)
var categories []Category
s.db.Where("id IN ?", categoryIDs).Find(&categories)
categoryMap := buildCategoryMap(categories)

for _, product := range products {
    product.Category = categoryMap[product.CategoryID]
}
```

### 1.4 优化效果

**优化后性能**:
- P50: 50ms ⬇️ **75% 改善**
- P95: 150ms ⬇️ **81% 改善**
- P99: 300ms ⬇️ **80% 改善**
- QPS: 2000 ⬆️ **4x 提升**
- 缓存命中率: 85%

---

## 2. 案例二：内存使用优化

### 2.1 问题描述

**场景**: 订单服务内存占用持续增长，最终导致 OOM

**初始状态**:
- 启动内存: 100MB
- 运行 1 小时: 500MB
- 运行 6 小时: 2GB (OOM Kill)

### 2.2 内存分析

```bash
# 生成 heap profile
curl http://localhost:6060/debug/pprof/heap > heap.prof

# 分析内存分配
go tool pprof -alloc_space heap.prof
(pprof) top 20
```

**发现问题**:
1. 大量临时对象分配
2. 字符串拼接导致内存浪费
3. 未使用对象池

### 2.3 优化方案

#### 优化1: 对象池

**优化前**:

```go
func processOrders(orders []Order) {
    for _, order := range orders {
        buf := bytes.NewBuffer(nil) // 每次创建新 Buffer
        json.NewEncoder(buf).Encode(order)
        send(buf.Bytes())
    }
}
```

**优化后**:

```go
var bufferPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func processOrders(orders []Order) {
    for _, order := range orders {
        buf := bufferPool.Get().(*bytes.Buffer)
        buf.Reset() // 重置 Buffer
        
        json.NewEncoder(buf).Encode(order)
        send(buf.Bytes())
        
        bufferPool.Put(buf) // 归还到池
    }
}
```

#### 优化2: 预分配切片

**优化前**:

```go
func buildOrderItems(count int) []OrderItem {
    var items []OrderItem // 容量为 0，会多次扩容
    for i := 0; i < count; i++ {
        items = append(items, OrderItem{ID: i})
    }
    return items
}
```

**优化后**:

```go
func buildOrderItems(count int) []OrderItem {
    items := make([]OrderItem, 0, count) // 预分配容量
    for i := 0; i < count; i++ {
        items = append(items, OrderItem{ID: i})
    }
    return items
}
```

#### 优化3: 字符串优化

**优化前**:

```go
func buildQuery(ids []int) string {
    query := "SELECT * FROM orders WHERE id IN ("
    for i, id := range ids {
        if i > 0 {
            query += ", "
        }
        query += strconv.Itoa(id) // 每次创建新字符串
    }
    query += ")"
    return query
}
```

**优化后**:

```go
func buildQuery(ids []int) string {
    var builder strings.Builder
    builder.Grow(len(ids) * 10) // 预估大小
    
    builder.WriteString("SELECT * FROM orders WHERE id IN (")
    for i, id := range ids {
        if i > 0 {
            builder.WriteString(", ")
        }
        builder.WriteString(strconv.Itoa(id))
    }
    builder.WriteString(")")
    
    return builder.String()
}
```

### 2.4 优化效果

**优化后状态**:
- 启动内存: 100MB (不变)
- 运行 1 小时: 150MB ⬇️ **70% 改善**
- 运行 24 小时: 200MB ⬇️ **稳定**
- 内存分配速率: 5MB/s → 0.5MB/s ⬇️ **90% 减少**

---

## 3. 案例三：数据库性能优化

### 3.1 问题描述

**场景**: 订单统计查询耗时过长

**初始性能**:
- 查询时间: 3-5 秒
- 数据库 CPU: 80%
- 锁等待: 频繁

### 3.2 SQL 分析

```sql
-- 原始 SQL（未优化）
SELECT 
    DATE(created_at) as date,
    COUNT(*) as order_count,
    SUM(total_amount) as total_amount
FROM orders
WHERE created_at >= '2024-01-01'
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

**EXPLAIN 分析**:
```
Seq Scan on orders  (cost=0.00..10000.00 rows=50000 width=16)
  Filter: (created_at >= '2024-01-01'::date)
```

### 3.3 优化方案

#### 优化1: 添加索引

```sql
-- 创建复合索引
CREATE INDEX idx_orders_created_at ON orders(created_at) 
    WHERE created_at >= '2024-01-01';

-- 创建部分索引（只索引活跃数据）
CREATE INDEX idx_orders_active ON orders(created_at, status) 
    WHERE status IN ('pending', 'processing', 'completed');
```

#### 优化2: 查询优化

**优化后 SQL**:

```sql
-- 使用索引覆盖
CREATE INDEX idx_orders_stats ON orders(created_at, total_amount);

SELECT 
    DATE(created_at) as date,
    COUNT(*) as order_count,
    SUM(total_amount) as total_amount
FROM orders
WHERE created_at >= '2024-01-01'
    AND created_at < '2024-02-01'  -- 使用范围查询
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

#### 优化3: 应用层优化

```go
// 使用缓存和增量更新
type StatsCache struct {
    data  map[string]OrderStats
    mu    sync.RWMutex
    redis *redis.Client
}

func (c *StatsCache) GetStats(ctx context.Context, date time.Time) (*OrderStats, error) {
    dateStr := date.Format("2006-01-02")
    
    // 1. 尝试从内存缓存获取
    c.mu.RLock()
    if stats, ok := c.data[dateStr]; ok {
        c.mu.RUnlock()
        return &stats, nil
    }
    c.mu.RUnlock()
    
    // 2. 尝试从 Redis 获取
    key := fmt.Sprintf("stats:date:%s", dateStr)
    if data, err := c.redis.Get(ctx, key).Result(); err == nil {
        var stats OrderStats
        json.Unmarshal([]byte(data), &stats)
        
        // 更新内存缓存
        c.mu.Lock()
        c.data[dateStr] = stats
        c.mu.Unlock()
        
        return &stats, nil
    }
    
    // 3. 从数据库查询并缓存
    stats, err := c.queryFromDB(ctx, date)
    if err != nil {
        return nil, err
    }
    
    // 异步更新缓存
    go func() {
        data, _ := json.Marshal(stats)
        c.redis.Set(context.Background(), key, data, 24*time.Hour)
    }()
    
    return stats, nil
}
```

### 3.4 优化效果

**优化后性能**:
- 查询时间: 50-100ms ⬇️ **95% 改善**
- 数据库 CPU: 20% ⬇️ **75% 降低**
- 缓存命中率: 90%
- 锁等待: 基本消除

---

## 4. 案例四：并发性能优化

### 4.1 问题描述

**场景**: 批量处理订单时 CPU 利用率低，处理速度慢

**初始性能**:
- 处理 10000 订单: 100 秒
- CPU 利用率: 25% (单核)
- 吞吐量: 100 订单/秒

### 4.2 并发优化

#### 优化方案: Worker Pool

**优化前（串行处理）**:

```go
func ProcessOrders(orders []Order) error {
    for _, order := range orders {
        if err := processOrder(order); err != nil {
            return err
        }
    }
    return nil
}
```

**优化后（并行处理）**:

```go
func ProcessOrders(ctx context.Context, orders []Order) error {
    ctx, span := tracer.Start(ctx, "process_orders_parallel")
    defer span.End()
    
    // 创建 Worker Pool
    workerCount := runtime.NumCPU()
    pool, _ := NewWorkerPool[Order, error](ctx, workerCount, func(ctx context.Context, order Order) (error, error) {
        return processOrder(ctx, order), nil
    })
    
    // 提交任务
    futures := make([]*Future[error], 0, len(orders))
    for _, order := range orders {
        future := pool.Submit(ctx, order)
        futures = append(futures, future)
    }
    
    // 等待所有任务完成
    var errors []error
    for i, future := range futures {
        result, err := future.Get(ctx)
        if err != nil {
            errors = append(errors, fmt.Errorf("order %d failed: %w", i, err))
        }
    }
    
    pool.Shutdown(ctx)
    
    if len(errors) > 0 {
        return errors[0] // 或使用 errors.Join
    }
    
    return nil
}
```

#### 优化：限流控制

```go
type RateLimitedProcessor struct {
    limiter  *rate.Limiter
    pool     *WorkerPool
    tracer   trace.Tracer
}

func NewRateLimitedProcessor(qps int, workers int) *RateLimitedProcessor {
    return &RateLimitedProcessor{
        limiter: rate.NewLimiter(rate.Limit(qps), qps*2),
        pool:    NewWorkerPool(workers, processOrder),
        tracer:  otel.Tracer("rate-limited-processor"),
    }
}

func (p *RateLimitedProcessor) Process(ctx context.Context, order Order) error {
    // 等待令牌
    if err := p.limiter.Wait(ctx); err != nil {
        return err
    }
    
    return p.pool.Submit(ctx, order).Get(ctx)
}
```

### 4.3 优化效果

**优化后性能**:
- 处理 10000 订单: 12 秒 ⬇️ **88% 改善**
- CPU 利用率: 90% ⬆️ **3.6x 提升**
- 吞吐量: 833 订单/秒 ⬆️ **8.3x 提升**

---

## 5. 案例五：GC 优化

### 5.1 问题描述

**场景**: GC 暂停时间过长，影响服务可用性

**初始状态**:
- GC 暂停时间: 100-200ms
- GC 频率: 每 10 秒一次
- P99 延迟: 500ms

### 5.2 GC 分析

```bash
# 启用 GC trace
GODEBUG=gctrace=1 ./app

# 输出示例
gc 45 @10.123s 5%: 0.15+150+0.25 ms clock, 1.2+75/120/0+2.0 ms cpu
```

分析：
- STW 时间过长 (150ms)
- 堆内存过大
- 频繁分配小对象

### 5.3 优化方案

#### 优化1: 调整 GC 参数

```go
import "runtime/debug"

func init() {
    // 增加 GC 触发阈值（降低频率）
    debug.SetGCPercent(200) // 默认 100
    
    // 设置内存限制（Go 1.19+）
    debug.SetMemoryLimit(8 * 1024 * 1024 * 1024) // 8GB
}
```

#### 优化2: 减少堆分配

**使用栈分配**:

```go
// 优化前：返回指针（堆分配）
func createUser(id int) *User {
    return &User{ID: id}
}

// 优化后：返回值（栈分配）
func createUser(id int) User {
    return User{ID: id}
}
```

**重用对象**:

```go
var eventPool = sync.Pool{
    New: func() interface{} {
        return &Event{
            Attributes: make(map[string]string, 10),
        }
    },
}

func logEvent(name string, attrs map[string]string) {
    event := eventPool.Get().(*Event)
    defer eventPool.Put(event)
    
    event.Name = name
    for k, v := range attrs {
        event.Attributes[k] = v
    }
    
    processEvent(event)
    
    // 清理
    for k := range event.Attributes {
        delete(event.Attributes, k)
    }
}
```

### 5.4 优化效果

**优化后状态**:
- GC 暂停时间: 10-20ms ⬇️ **90% 改善**
- GC 频率: 每 30 秒一次 ⬇️ **67% 降低**
- P99 延迟: 150ms ⬇️ **70% 改善**
- 堆大小: 稳定在 2GB

---

## 6. 优化工具链

### 6.1 性能分析工具

```bash
# CPU Profiling
go test -cpuprofile=cpu.prof -bench=.
go tool pprof cpu.prof

# Memory Profiling
go test -memprofile=mem.prof -bench=.
go tool pprof mem.prof

# Trace 分析
go test -trace=trace.out -bench=.
go tool trace trace.out

# 生成火焰图
go tool pprof -http=:8080 cpu.prof
```

### 6.2 基准测试

```go
func BenchmarkProcessOrder(b *testing.B) {
    ctx := context.Background()
    order := Order{ID: 1, Amount: 100}
    
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        processOrder(ctx, order)
    }
}

// 运行基准测试
// go test -bench=. -benchmem -benchtime=10s
```

### 6.3 压力测试

```bash
# 使用 hey 进行压测
hey -z 60s -c 100 -q 10 http://localhost:8080/api/orders

# 使用 wrk
wrk -t12 -c400 -d30s http://localhost:8080/api/orders
```

---

## 7. 总结

### 优化成果汇总

| 案例 | 指标 | 优化前 | 优化后 | 改善 |
|------|------|--------|--------|------|
| API 延迟 | P95 延迟 | 800ms | 150ms | 81% ⬇️ |
| 内存使用 | 运行 24h | 2GB | 200MB | 90% ⬇️ |
| 数据库查询 | 查询时间 | 3-5s | 50-100ms | 95% ⬇️ |
| 并发处理 | 吞吐量 | 100/s | 833/s | 733% ⬆️ |
| GC 优化 | 暂停时间 | 100-200ms | 10-20ms | 90% ⬇️ |

### 优化方法论

1. **测量**: 使用 OTLP、pprof 等工具准确测量
2. **分析**: 找到真正的瓶颈，不要盲目优化
3. **优化**: 从影响最大的地方开始
4. **验证**: 确认优化效果，避免副作用
5. **监控**: 持续监控，防止性能退化

### 核心原则

✅ **过早优化是万恶之源** - 先保证正确性
✅ **数据驱动** - 基于监控数据做决策
✅ **循序渐进** - 一次优化一个点
✅ **权衡取舍** - 考虑可维护性和复杂度

### 相关文档

- [34_Go内存管理与性能调优实战](./34_Go内存管理与性能调优实战.md)
- [03_Go性能优化与最佳实践](./03_Go性能优化与最佳实践.md)
- [45_故障排查与调试指南](./45_故障排查与调试指南.md)


# 46. æ€§èƒ½è°ƒä¼˜æ¡ˆä¾‹åˆ†æ

## ğŸ“š ç›®å½•

- [1. æ¡ˆä¾‹ä¸€ï¼šAPI å»¶è¿Ÿä¼˜åŒ–](#1-æ¡ˆä¾‹ä¸€api-å»¶è¿Ÿä¼˜åŒ–)
- [2. æ¡ˆä¾‹äºŒï¼šå†…å­˜ä½¿ç”¨ä¼˜åŒ–](#2-æ¡ˆä¾‹äºŒå†…å­˜ä½¿ç”¨ä¼˜åŒ–)
- [3. æ¡ˆä¾‹ä¸‰ï¼šæ•°æ®åº“æ€§èƒ½ä¼˜åŒ–](#3-æ¡ˆä¾‹ä¸‰æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–)
- [4. æ¡ˆä¾‹å››ï¼šå¹¶å‘æ€§èƒ½ä¼˜åŒ–](#4-æ¡ˆä¾‹å››å¹¶å‘æ€§èƒ½ä¼˜åŒ–)
- [5. æ¡ˆä¾‹äº”ï¼šGC ä¼˜åŒ–](#5-æ¡ˆä¾‹äº”gc-ä¼˜åŒ–)
- [6. ä¼˜åŒ–å·¥å…·é“¾](#6-ä¼˜åŒ–å·¥å…·é“¾)
- [7. æ€»ç»“](#7-æ€»ç»“)

---

## 1. æ¡ˆä¾‹ä¸€ï¼šAPI å»¶è¿Ÿä¼˜åŒ–

### 1.1 é—®é¢˜æè¿°

**åœºæ™¯**: å•†å“åˆ—è¡¨ API P95 å»¶è¿Ÿè¾¾åˆ° 800msï¼Œå½±å“ç”¨æˆ·ä½“éªŒ

**åˆå§‹æ€§èƒ½**:
- P50: 200ms
- P95: 800ms
- P99: 1500ms
- QPS: 500

### 1.2 æ€§èƒ½åˆ†æ

ä½¿ç”¨ OTLP Trace åˆ†æï¼š

```bash
# Jaeger UI ä¸­æŸ¥çœ‹æ…¢è¯·æ±‚
Service: product-service
Operation: GET /api/products
Duration: > 500ms
```

Trace åˆ†æå‘ç°ï¼š
- æ•°æ®åº“æŸ¥è¯¢: 150ms
- Redis ç¼“å­˜æœªå‘½ä¸­: 60%
- åºåˆ—åŒ–: 50ms
- æ•°æ®è½¬æ¢: 100ms

### 1.3 ä¼˜åŒ–æ–¹æ¡ˆ

#### ä¼˜åŒ–1: æ·»åŠ ç¼“å­˜é¢„çƒ­

**ä¼˜åŒ–å‰**:

```go
func (s *Service) List(ctx context.Context, req *ListRequest) ([]*Product, error) {
    // æ¯æ¬¡éƒ½æŸ¥æ•°æ®åº“
    var products []*Product
    if err := s.db.WithContext(ctx).
        Where("category = ?", req.Category).
        Find(&products).Error; err != nil {
        return nil, err
    }
    return products, nil
}
```

**ä¼˜åŒ–å**:

```go
func (s *Service) List(ctx context.Context, req *ListRequest) ([]*Product, error) {
    ctx, span := s.tracer.Start(ctx, "product.list")
    defer span.End()
    
    // 1. å°è¯•ä»ç¼“å­˜è·å–
    cacheKey := fmt.Sprintf("products:category:%s:page:%d", req.Category, req.Page)
    
    if cached, err := s.redis.Get(ctx, cacheKey).Result(); err == nil {
        var products []*Product
        if json.Unmarshal([]byte(cached), &products) == nil {
            span.SetAttributes(attribute.Bool("cache.hit", true))
            return products, nil
        }
    }
    
    // 2. ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
    span.SetAttributes(attribute.Bool("cache.hit", false))
    
    var products []*Product
    if err := s.db.WithContext(ctx).
        Where("category = ? AND status = ?", req.Category, "active").
        Offset((req.Page-1)*req.PageSize).
        Limit(req.PageSize).
        Find(&products).Error; err != nil {
        return nil, err
    }
    
    // 3. å†™å…¥ç¼“å­˜ï¼ˆå¼‚æ­¥ï¼‰
    go func() {
        data, _ := json.Marshal(products)
        s.redis.Set(context.Background(), cacheKey, data, 5*time.Minute)
    }()
    
    return products, nil
}

// ç¼“å­˜é¢„çƒ­
func (s *Service) WarmupCache(ctx context.Context) error {
    categories := []string{"electronics", "clothing", "food"}
    
    for _, category := range categories {
        for page := 1; page <= 5; page++ {
            products, err := s.List(ctx, &ListRequest{
                Category: category,
                Page:     page,
                PageSize: 20,
            })
            if err != nil {
                return err
            }
            
            cacheKey := fmt.Sprintf("products:category:%s:page:%d", category, page)
            data, _ := json.Marshal(products)
            s.redis.Set(ctx, cacheKey, data, 5*time.Minute)
        }
    }
    
    return nil
}
```

#### ä¼˜åŒ–2: ä½¿ç”¨è¿æ¥æ± 

```go
// Redis è¿æ¥æ± é…ç½®
rdb := redis.NewClient(&redis.Options{
    Addr:         "localhost:6379",
    PoolSize:     50,  // å¢åŠ è¿æ¥æ± å¤§å°
    MinIdleConns: 10,  // ä¿æŒæœ€å°ç©ºé—²è¿æ¥
    PoolTimeout:  4 * time.Second,
    MaxRetries:   3,
})
```

#### ä¼˜åŒ–3: æ‰¹é‡æŸ¥è¯¢

**ä¼˜åŒ–å‰**:

```go
// N+1 æŸ¥è¯¢é—®é¢˜
for _, product := range products {
    var category Category
    s.db.Where("id = ?", product.CategoryID).First(&category)
    product.Category = category
}
```

**ä¼˜åŒ–å**:

```go
// ä½¿ç”¨ Preload æˆ– JOIN
var products []*Product
s.db.Preload("Category").Find(&products)

// æˆ–ä½¿ç”¨ IN æŸ¥è¯¢
categoryIDs := extractCategoryIDs(products)
var categories []Category
s.db.Where("id IN ?", categoryIDs).Find(&categories)
categoryMap := buildCategoryMap(categories)

for _, product := range products {
    product.Category = categoryMap[product.CategoryID]
}
```

### 1.4 ä¼˜åŒ–æ•ˆæœ

**ä¼˜åŒ–åæ€§èƒ½**:
- P50: 50ms â¬‡ï¸ **75% æ”¹å–„**
- P95: 150ms â¬‡ï¸ **81% æ”¹å–„**
- P99: 300ms â¬‡ï¸ **80% æ”¹å–„**
- QPS: 2000 â¬†ï¸ **4x æå‡**
- ç¼“å­˜å‘½ä¸­ç‡: 85%

---

## 2. æ¡ˆä¾‹äºŒï¼šå†…å­˜ä½¿ç”¨ä¼˜åŒ–

### 2.1 é—®é¢˜æè¿°

**åœºæ™¯**: è®¢å•æœåŠ¡å†…å­˜å ç”¨æŒç»­å¢é•¿ï¼Œæœ€ç»ˆå¯¼è‡´ OOM

**åˆå§‹çŠ¶æ€**:
- å¯åŠ¨å†…å­˜: 100MB
- è¿è¡Œ 1 å°æ—¶: 500MB
- è¿è¡Œ 6 å°æ—¶: 2GB (OOM Kill)

### 2.2 å†…å­˜åˆ†æ

```bash
# ç”Ÿæˆ heap profile
curl http://localhost:6060/debug/pprof/heap > heap.prof

# åˆ†æå†…å­˜åˆ†é…
go tool pprof -alloc_space heap.prof
(pprof) top 20
```

**å‘ç°é—®é¢˜**:
1. å¤§é‡ä¸´æ—¶å¯¹è±¡åˆ†é…
2. å­—ç¬¦ä¸²æ‹¼æ¥å¯¼è‡´å†…å­˜æµªè´¹
3. æœªä½¿ç”¨å¯¹è±¡æ± 

### 2.3 ä¼˜åŒ–æ–¹æ¡ˆ

#### ä¼˜åŒ–1: å¯¹è±¡æ± 

**ä¼˜åŒ–å‰**:

```go
func processOrders(orders []Order) {
    for _, order := range orders {
        buf := bytes.NewBuffer(nil) // æ¯æ¬¡åˆ›å»ºæ–° Buffer
        json.NewEncoder(buf).Encode(order)
        send(buf.Bytes())
    }
}
```

**ä¼˜åŒ–å**:

```go
var bufferPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func processOrders(orders []Order) {
    for _, order := range orders {
        buf := bufferPool.Get().(*bytes.Buffer)
        buf.Reset() // é‡ç½® Buffer
        
        json.NewEncoder(buf).Encode(order)
        send(buf.Bytes())
        
        bufferPool.Put(buf) // å½’è¿˜åˆ°æ± 
    }
}
```

#### ä¼˜åŒ–2: é¢„åˆ†é…åˆ‡ç‰‡

**ä¼˜åŒ–å‰**:

```go
func buildOrderItems(count int) []OrderItem {
    var items []OrderItem // å®¹é‡ä¸º 0ï¼Œä¼šå¤šæ¬¡æ‰©å®¹
    for i := 0; i < count; i++ {
        items = append(items, OrderItem{ID: i})
    }
    return items
}
```

**ä¼˜åŒ–å**:

```go
func buildOrderItems(count int) []OrderItem {
    items := make([]OrderItem, 0, count) // é¢„åˆ†é…å®¹é‡
    for i := 0; i < count; i++ {
        items = append(items, OrderItem{ID: i})
    }
    return items
}
```

#### ä¼˜åŒ–3: å­—ç¬¦ä¸²ä¼˜åŒ–

**ä¼˜åŒ–å‰**:

```go
func buildQuery(ids []int) string {
    query := "SELECT * FROM orders WHERE id IN ("
    for i, id := range ids {
        if i > 0 {
            query += ", "
        }
        query += strconv.Itoa(id) // æ¯æ¬¡åˆ›å»ºæ–°å­—ç¬¦ä¸²
    }
    query += ")"
    return query
}
```

**ä¼˜åŒ–å**:

```go
func buildQuery(ids []int) string {
    var builder strings.Builder
    builder.Grow(len(ids) * 10) // é¢„ä¼°å¤§å°
    
    builder.WriteString("SELECT * FROM orders WHERE id IN (")
    for i, id := range ids {
        if i > 0 {
            builder.WriteString(", ")
        }
        builder.WriteString(strconv.Itoa(id))
    }
    builder.WriteString(")")
    
    return builder.String()
}
```

### 2.4 ä¼˜åŒ–æ•ˆæœ

**ä¼˜åŒ–åçŠ¶æ€**:
- å¯åŠ¨å†…å­˜: 100MB (ä¸å˜)
- è¿è¡Œ 1 å°æ—¶: 150MB â¬‡ï¸ **70% æ”¹å–„**
- è¿è¡Œ 24 å°æ—¶: 200MB â¬‡ï¸ **ç¨³å®š**
- å†…å­˜åˆ†é…é€Ÿç‡: 5MB/s â†’ 0.5MB/s â¬‡ï¸ **90% å‡å°‘**

---

## 3. æ¡ˆä¾‹ä¸‰ï¼šæ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

### 3.1 é—®é¢˜æè¿°

**åœºæ™¯**: è®¢å•ç»Ÿè®¡æŸ¥è¯¢è€—æ—¶è¿‡é•¿

**åˆå§‹æ€§èƒ½**:
- æŸ¥è¯¢æ—¶é—´: 3-5 ç§’
- æ•°æ®åº“ CPU: 80%
- é”ç­‰å¾…: é¢‘ç¹

### 3.2 SQL åˆ†æ

```sql
-- åŸå§‹ SQLï¼ˆæœªä¼˜åŒ–ï¼‰
SELECT 
    DATE(created_at) as date,
    COUNT(*) as order_count,
    SUM(total_amount) as total_amount
FROM orders
WHERE created_at >= '2024-01-01'
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

**EXPLAIN åˆ†æ**:
```
Seq Scan on orders  (cost=0.00..10000.00 rows=50000 width=16)
  Filter: (created_at >= '2024-01-01'::date)
```

### 3.3 ä¼˜åŒ–æ–¹æ¡ˆ

#### ä¼˜åŒ–1: æ·»åŠ ç´¢å¼•

```sql
-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_orders_created_at ON orders(created_at) 
    WHERE created_at >= '2024-01-01';

-- åˆ›å»ºéƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æ´»è·ƒæ•°æ®ï¼‰
CREATE INDEX idx_orders_active ON orders(created_at, status) 
    WHERE status IN ('pending', 'processing', 'completed');
```

#### ä¼˜åŒ–2: æŸ¥è¯¢ä¼˜åŒ–

**ä¼˜åŒ–å SQL**:

```sql
-- ä½¿ç”¨ç´¢å¼•è¦†ç›–
CREATE INDEX idx_orders_stats ON orders(created_at, total_amount);

SELECT 
    DATE(created_at) as date,
    COUNT(*) as order_count,
    SUM(total_amount) as total_amount
FROM orders
WHERE created_at >= '2024-01-01'
    AND created_at < '2024-02-01'  -- ä½¿ç”¨èŒƒå›´æŸ¥è¯¢
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

#### ä¼˜åŒ–3: åº”ç”¨å±‚ä¼˜åŒ–

```go
// ä½¿ç”¨ç¼“å­˜å’Œå¢é‡æ›´æ–°
type StatsCache struct {
    data  map[string]OrderStats
    mu    sync.RWMutex
    redis *redis.Client
}

func (c *StatsCache) GetStats(ctx context.Context, date time.Time) (*OrderStats, error) {
    dateStr := date.Format("2006-01-02")
    
    // 1. å°è¯•ä»å†…å­˜ç¼“å­˜è·å–
    c.mu.RLock()
    if stats, ok := c.data[dateStr]; ok {
        c.mu.RUnlock()
        return &stats, nil
    }
    c.mu.RUnlock()
    
    // 2. å°è¯•ä» Redis è·å–
    key := fmt.Sprintf("stats:date:%s", dateStr)
    if data, err := c.redis.Get(ctx, key).Result(); err == nil {
        var stats OrderStats
        json.Unmarshal([]byte(data), &stats)
        
        // æ›´æ–°å†…å­˜ç¼“å­˜
        c.mu.Lock()
        c.data[dateStr] = stats
        c.mu.Unlock()
        
        return &stats, nil
    }
    
    // 3. ä»æ•°æ®åº“æŸ¥è¯¢å¹¶ç¼“å­˜
    stats, err := c.queryFromDB(ctx, date)
    if err != nil {
        return nil, err
    }
    
    // å¼‚æ­¥æ›´æ–°ç¼“å­˜
    go func() {
        data, _ := json.Marshal(stats)
        c.redis.Set(context.Background(), key, data, 24*time.Hour)
    }()
    
    return stats, nil
}
```

### 3.4 ä¼˜åŒ–æ•ˆæœ

**ä¼˜åŒ–åæ€§èƒ½**:
- æŸ¥è¯¢æ—¶é—´: 50-100ms â¬‡ï¸ **95% æ”¹å–„**
- æ•°æ®åº“ CPU: 20% â¬‡ï¸ **75% é™ä½**
- ç¼“å­˜å‘½ä¸­ç‡: 90%
- é”ç­‰å¾…: åŸºæœ¬æ¶ˆé™¤

---

## 4. æ¡ˆä¾‹å››ï¼šå¹¶å‘æ€§èƒ½ä¼˜åŒ–

### 4.1 é—®é¢˜æè¿°

**åœºæ™¯**: æ‰¹é‡å¤„ç†è®¢å•æ—¶ CPU åˆ©ç”¨ç‡ä½ï¼Œå¤„ç†é€Ÿåº¦æ…¢

**åˆå§‹æ€§èƒ½**:
- å¤„ç† 10000 è®¢å•: 100 ç§’
- CPU åˆ©ç”¨ç‡: 25% (å•æ ¸)
- ååé‡: 100 è®¢å•/ç§’

### 4.2 å¹¶å‘ä¼˜åŒ–

#### ä¼˜åŒ–æ–¹æ¡ˆ: Worker Pool

**ä¼˜åŒ–å‰ï¼ˆä¸²è¡Œå¤„ç†ï¼‰**:

```go
func ProcessOrders(orders []Order) error {
    for _, order := range orders {
        if err := processOrder(order); err != nil {
            return err
        }
    }
    return nil
}
```

**ä¼˜åŒ–åï¼ˆå¹¶è¡Œå¤„ç†ï¼‰**:

```go
func ProcessOrders(ctx context.Context, orders []Order) error {
    ctx, span := tracer.Start(ctx, "process_orders_parallel")
    defer span.End()
    
    // åˆ›å»º Worker Pool
    workerCount := runtime.NumCPU()
    pool, _ := NewWorkerPool[Order, error](ctx, workerCount, func(ctx context.Context, order Order) (error, error) {
        return processOrder(ctx, order), nil
    })
    
    // æäº¤ä»»åŠ¡
    futures := make([]*Future[error], 0, len(orders))
    for _, order := range orders {
        future := pool.Submit(ctx, order)
        futures = append(futures, future)
    }
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    var errors []error
    for i, future := range futures {
        result, err := future.Get(ctx)
        if err != nil {
            errors = append(errors, fmt.Errorf("order %d failed: %w", i, err))
        }
    }
    
    pool.Shutdown(ctx)
    
    if len(errors) > 0 {
        return errors[0] // æˆ–ä½¿ç”¨ errors.Join
    }
    
    return nil
}
```

#### ä¼˜åŒ–ï¼šé™æµæ§åˆ¶

```go
type RateLimitedProcessor struct {
    limiter  *rate.Limiter
    pool     *WorkerPool
    tracer   trace.Tracer
}

func NewRateLimitedProcessor(qps int, workers int) *RateLimitedProcessor {
    return &RateLimitedProcessor{
        limiter: rate.NewLimiter(rate.Limit(qps), qps*2),
        pool:    NewWorkerPool(workers, processOrder),
        tracer:  otel.Tracer("rate-limited-processor"),
    }
}

func (p *RateLimitedProcessor) Process(ctx context.Context, order Order) error {
    // ç­‰å¾…ä»¤ç‰Œ
    if err := p.limiter.Wait(ctx); err != nil {
        return err
    }
    
    return p.pool.Submit(ctx, order).Get(ctx)
}
```

### 4.3 ä¼˜åŒ–æ•ˆæœ

**ä¼˜åŒ–åæ€§èƒ½**:
- å¤„ç† 10000 è®¢å•: 12 ç§’ â¬‡ï¸ **88% æ”¹å–„**
- CPU åˆ©ç”¨ç‡: 90% â¬†ï¸ **3.6x æå‡**
- ååé‡: 833 è®¢å•/ç§’ â¬†ï¸ **8.3x æå‡**

---

## 5. æ¡ˆä¾‹äº”ï¼šGC ä¼˜åŒ–

### 5.1 é—®é¢˜æè¿°

**åœºæ™¯**: GC æš‚åœæ—¶é—´è¿‡é•¿ï¼Œå½±å“æœåŠ¡å¯ç”¨æ€§

**åˆå§‹çŠ¶æ€**:
- GC æš‚åœæ—¶é—´: 100-200ms
- GC é¢‘ç‡: æ¯ 10 ç§’ä¸€æ¬¡
- P99 å»¶è¿Ÿ: 500ms

### 5.2 GC åˆ†æ

```bash
# å¯ç”¨ GC trace
GODEBUG=gctrace=1 ./app

# è¾“å‡ºç¤ºä¾‹
gc 45 @10.123s 5%: 0.15+150+0.25 ms clock, 1.2+75/120/0+2.0 ms cpu
```

åˆ†æï¼š
- STW æ—¶é—´è¿‡é•¿ (150ms)
- å †å†…å­˜è¿‡å¤§
- é¢‘ç¹åˆ†é…å°å¯¹è±¡

### 5.3 ä¼˜åŒ–æ–¹æ¡ˆ

#### ä¼˜åŒ–1: è°ƒæ•´ GC å‚æ•°

```go
import "runtime/debug"

func init() {
    // å¢åŠ  GC è§¦å‘é˜ˆå€¼ï¼ˆé™ä½é¢‘ç‡ï¼‰
    debug.SetGCPercent(200) // é»˜è®¤ 100
    
    // è®¾ç½®å†…å­˜é™åˆ¶ï¼ˆGo 1.19+ï¼‰
    debug.SetMemoryLimit(8 * 1024 * 1024 * 1024) // 8GB
}
```

#### ä¼˜åŒ–2: å‡å°‘å †åˆ†é…

**ä½¿ç”¨æ ˆåˆ†é…**:

```go
// ä¼˜åŒ–å‰ï¼šè¿”å›æŒ‡é’ˆï¼ˆå †åˆ†é…ï¼‰
func createUser(id int) *User {
    return &User{ID: id}
}

// ä¼˜åŒ–åï¼šè¿”å›å€¼ï¼ˆæ ˆåˆ†é…ï¼‰
func createUser(id int) User {
    return User{ID: id}
}
```

**é‡ç”¨å¯¹è±¡**:

```go
var eventPool = sync.Pool{
    New: func() interface{} {
        return &Event{
            Attributes: make(map[string]string, 10),
        }
    },
}

func logEvent(name string, attrs map[string]string) {
    event := eventPool.Get().(*Event)
    defer eventPool.Put(event)
    
    event.Name = name
    for k, v := range attrs {
        event.Attributes[k] = v
    }
    
    processEvent(event)
    
    // æ¸…ç†
    for k := range event.Attributes {
        delete(event.Attributes, k)
    }
}
```

### 5.4 ä¼˜åŒ–æ•ˆæœ

**ä¼˜åŒ–åçŠ¶æ€**:
- GC æš‚åœæ—¶é—´: 10-20ms â¬‡ï¸ **90% æ”¹å–„**
- GC é¢‘ç‡: æ¯ 30 ç§’ä¸€æ¬¡ â¬‡ï¸ **67% é™ä½**
- P99 å»¶è¿Ÿ: 150ms â¬‡ï¸ **70% æ”¹å–„**
- å †å¤§å°: ç¨³å®šåœ¨ 2GB

---

## 6. ä¼˜åŒ–å·¥å…·é“¾

### 6.1 æ€§èƒ½åˆ†æå·¥å…·

```bash
# CPU Profiling
go test -cpuprofile=cpu.prof -bench=.
go tool pprof cpu.prof

# Memory Profiling
go test -memprofile=mem.prof -bench=.
go tool pprof mem.prof

# Trace åˆ†æ
go test -trace=trace.out -bench=.
go tool trace trace.out

# ç”Ÿæˆç«ç„°å›¾
go tool pprof -http=:8080 cpu.prof
```

### 6.2 åŸºå‡†æµ‹è¯•

```go
func BenchmarkProcessOrder(b *testing.B) {
    ctx := context.Background()
    order := Order{ID: 1, Amount: 100}
    
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        processOrder(ctx, order)
    }
}

// è¿è¡ŒåŸºå‡†æµ‹è¯•
// go test -bench=. -benchmem -benchtime=10s
```

### 6.3 å‹åŠ›æµ‹è¯•

```bash
# ä½¿ç”¨ hey è¿›è¡Œå‹æµ‹
hey -z 60s -c 100 -q 10 http://localhost:8080/api/orders

# ä½¿ç”¨ wrk
wrk -t12 -c400 -d30s http://localhost:8080/api/orders
```

---

## 7. æ€»ç»“

### ä¼˜åŒ–æˆæœæ±‡æ€»

| æ¡ˆä¾‹ | æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹å–„ |
|------|------|--------|--------|------|
| API å»¶è¿Ÿ | P95 å»¶è¿Ÿ | 800ms | 150ms | 81% â¬‡ï¸ |
| å†…å­˜ä½¿ç”¨ | è¿è¡Œ 24h | 2GB | 200MB | 90% â¬‡ï¸ |
| æ•°æ®åº“æŸ¥è¯¢ | æŸ¥è¯¢æ—¶é—´ | 3-5s | 50-100ms | 95% â¬‡ï¸ |
| å¹¶å‘å¤„ç† | ååé‡ | 100/s | 833/s | 733% â¬†ï¸ |
| GC ä¼˜åŒ– | æš‚åœæ—¶é—´ | 100-200ms | 10-20ms | 90% â¬‡ï¸ |

### ä¼˜åŒ–æ–¹æ³•è®º

1. **æµ‹é‡**: ä½¿ç”¨ OTLPã€pprof ç­‰å·¥å…·å‡†ç¡®æµ‹é‡
2. **åˆ†æ**: æ‰¾åˆ°çœŸæ­£çš„ç“¶é¢ˆï¼Œä¸è¦ç›²ç›®ä¼˜åŒ–
3. **ä¼˜åŒ–**: ä»å½±å“æœ€å¤§çš„åœ°æ–¹å¼€å§‹
4. **éªŒè¯**: ç¡®è®¤ä¼˜åŒ–æ•ˆæœï¼Œé¿å…å‰¯ä½œç”¨
5. **ç›‘æ§**: æŒç»­ç›‘æ§ï¼Œé˜²æ­¢æ€§èƒ½é€€åŒ–

### æ ¸å¿ƒåŸåˆ™

âœ… **è¿‡æ—©ä¼˜åŒ–æ˜¯ä¸‡æ¶ä¹‹æº** - å…ˆä¿è¯æ­£ç¡®æ€§
âœ… **æ•°æ®é©±åŠ¨** - åŸºäºç›‘æ§æ•°æ®åšå†³ç­–
âœ… **å¾ªåºæ¸è¿›** - ä¸€æ¬¡ä¼˜åŒ–ä¸€ä¸ªç‚¹
âœ… **æƒè¡¡å–èˆ** - è€ƒè™‘å¯ç»´æŠ¤æ€§å’Œå¤æ‚åº¦

### ç›¸å…³æ–‡æ¡£

- [34_Goå†…å­˜ç®¡ç†ä¸æ€§èƒ½è°ƒä¼˜å®æˆ˜](./34_Goå†…å­˜ç®¡ç†ä¸æ€§èƒ½è°ƒä¼˜å®æˆ˜.md)
- [03_Goæ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ](./03_Goæ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ.md)
- [45_æ•…éšœæ’æŸ¥ä¸è°ƒè¯•æŒ‡å—](./45_æ•…éšœæ’æŸ¥ä¸è°ƒè¯•æŒ‡å—.md)


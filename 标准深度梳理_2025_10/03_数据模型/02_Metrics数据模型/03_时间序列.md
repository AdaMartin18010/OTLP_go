# æ—¶é—´åºåˆ—å®Œæ•´æŒ‡å—

## ğŸ“‹ ç›®å½•

- [æ—¶é—´åºåˆ—å®Œæ•´æŒ‡å—](#æ—¶é—´åºåˆ—å®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
    - [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
    - [æ—¶é—´åºåˆ—æ¨¡å‹](#æ—¶é—´åºåˆ—æ¨¡å‹)
  - [Temporality (æ—¶é—´æ€§)](#temporality-æ—¶é—´æ€§)
    - [å®šä¹‰](#å®šä¹‰)
    - [Cumulative (ç´¯ç§¯)](#cumulative-ç´¯ç§¯)
    - [Delta (å¢é‡)](#delta-å¢é‡)
    - [å¯¹æ¯”åˆ†æ](#å¯¹æ¯”åˆ†æ)
    - [Go å®ç°](#go-å®ç°)
  - [Aggregation (èšåˆ)](#aggregation-èšåˆ)
    - [èšåˆç±»å‹](#èšåˆç±»å‹)
    - [Sum (æ±‚å’Œ)](#sum-æ±‚å’Œ)
    - [LastValue (æœ€æ–°å€¼)](#lastvalue-æœ€æ–°å€¼)
    - [Histogram (ç›´æ–¹å›¾)](#histogram-ç›´æ–¹å›¾)
    - [ExponentialHistogram (æŒ‡æ•°ç›´æ–¹å›¾)](#exponentialhistogram-æŒ‡æ•°ç›´æ–¹å›¾)
  - [Aggregation Temporality](#aggregation-temporality)
    - [Counter èšåˆ](#counter-èšåˆ)
    - [UpDownCounter èšåˆ](#updowncounter-èšåˆ)
    - [Gauge èšåˆ](#gauge-èšåˆ)
    - [Histogram èšåˆ](#histogram-èšåˆ)
  - [æ—¶é—´çª—å£ç®¡ç†](#æ—¶é—´çª—å£ç®¡ç†)
    - [çª—å£ç±»å‹](#çª—å£ç±»å‹)
    - [æ»šåŠ¨çª—å£](#æ»šåŠ¨çª—å£)
    - [æ»‘åŠ¨çª—å£](#æ»‘åŠ¨çª—å£)
    - [Go å®ç°2](#go-å®ç°2)
  - [æ—¶é—´å¯¹é½](#æ—¶é—´å¯¹é½)
    - [å¯¹é½ç­–ç•¥](#å¯¹é½ç­–ç•¥)
    - [æ—¶é’Ÿåç§»å¤„ç†](#æ—¶é’Ÿåç§»å¤„ç†)
    - [Go å®ç°3](#go-å®ç°3)
  - [é™é‡‡æ ·ä¸ä¸Šé‡‡æ ·](#é™é‡‡æ ·ä¸ä¸Šé‡‡æ ·)
    - [é™é‡‡æ ·](#é™é‡‡æ ·)
    - [ä¸Šé‡‡æ ·](#ä¸Šé‡‡æ ·)
    - [Go å®ç°4](#go-å®ç°4)
  - [æ—¶é—´åºåˆ—å­˜å‚¨](#æ—¶é—´åºåˆ—å­˜å‚¨)
    - [å­˜å‚¨æ¨¡å‹](#å­˜å‚¨æ¨¡å‹)
    - [å‹ç¼©ç­–ç•¥](#å‹ç¼©ç­–ç•¥)
    - [ç´¢å¼•ä¼˜åŒ–](#ç´¢å¼•ä¼˜åŒ–)
  - [æ—¶é—´åºåˆ—æŸ¥è¯¢](#æ—¶é—´åºåˆ—æŸ¥è¯¢)
    - [æŸ¥è¯¢è¯­è¨€](#æŸ¥è¯¢è¯­è¨€)
    - [PromQL ç¤ºä¾‹](#promql-ç¤ºä¾‹)
    - [Go å®¢æˆ·ç«¯æŸ¥è¯¢](#go-å®¢æˆ·ç«¯æŸ¥è¯¢)
  - [å®Œæ•´å®ç°](#å®Œæ•´å®ç°)
    - [æ—¶é—´åºåˆ—ç®¡ç†ç³»ç»Ÿ](#æ—¶é—´åºåˆ—ç®¡ç†ç³»ç»Ÿ)
  - [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
    - [1. é€‰æ‹©åˆé€‚çš„ Temporality](#1-é€‰æ‹©åˆé€‚çš„-temporality)
    - [2. åˆç†çš„èšåˆç²’åº¦](#2-åˆç†çš„èšåˆç²’åº¦)
    - [3. æ—¶é—´çª—å£é…ç½®](#3-æ—¶é—´çª—å£é…ç½®)
    - [4. é«˜åŸºæ•°å¤„ç†](#4-é«˜åŸºæ•°å¤„ç†)
  - [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
    - [1. æ‰¹é‡èšåˆ](#1-æ‰¹é‡èšåˆ)
    - [2. é¢„èšåˆ](#2-é¢„èšåˆ)
    - [3. åˆ†ç‰‡ç­–ç•¥](#3-åˆ†ç‰‡ç­–ç•¥)
  - [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
    - [Q1: Cumulative å’Œ Delta å¦‚ä½•é€‰æ‹©ï¼Ÿ](#q1-cumulative-å’Œ-delta-å¦‚ä½•é€‰æ‹©)
    - [Q2: å¦‚ä½•å¤„ç†æ—¶é—´çª—å£é‡å ï¼Ÿ](#q2-å¦‚ä½•å¤„ç†æ—¶é—´çª—å£é‡å )
    - [Q3: å¦‚ä½•å¤„ç†æ—¶é’Ÿåç§»ï¼Ÿ](#q3-å¦‚ä½•å¤„ç†æ—¶é’Ÿåç§»)
    - [Q4: é™é‡‡æ ·ä¼šä¸¢å¤±æ•°æ®å—ï¼Ÿ](#q4-é™é‡‡æ ·ä¼šä¸¢å¤±æ•°æ®å—)
    - [Q5: å¦‚ä½•ä¼˜åŒ–æ—¶é—´åºåˆ—å­˜å‚¨ï¼Ÿ](#q5-å¦‚ä½•ä¼˜åŒ–æ—¶é—´åºåˆ—å­˜å‚¨)
  - [å‚è€ƒèµ„æº](#å‚è€ƒèµ„æº)
    - [å®˜æ–¹æ–‡æ¡£](#å®˜æ–¹æ–‡æ¡£)
    - [Go å®ç°5](#go-å®ç°5)
    - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)

---

## æ¦‚è¿°

**æ—¶é—´åºåˆ— (Time Series)** æ˜¯æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ•°æ®ç‚¹é›†åˆï¼Œç”¨äºè¡¨ç¤ºæŸä¸ªæŒ‡æ ‡éšæ—¶é—´å˜åŒ–çš„è¶‹åŠ¿ã€‚

### æ ¸å¿ƒæ¦‚å¿µ

- âœ… **Temporality**: æ—¶é—´æ€§ï¼Œå®šä¹‰æ•°æ®ç‚¹çš„æ—¶é—´è¯­ä¹‰
- âœ… **Aggregation**: èšåˆï¼Œå®šä¹‰å¦‚ä½•ç»„åˆå¤šä¸ªè§‚æµ‹å€¼
- âœ… **Time Window**: æ—¶é—´çª—å£ï¼Œæ•°æ®é‡‡é›†çš„æ—¶é—´èŒƒå›´
- âœ… **Resolution**: åˆ†è¾¨ç‡ï¼Œæ•°æ®ç‚¹çš„æ—¶é—´é—´éš”

### æ—¶é—´åºåˆ—æ¨¡å‹

```text
Time Series = {(tâ‚, vâ‚), (tâ‚‚, vâ‚‚), ..., (tâ‚™, vâ‚™)}

å…¶ä¸­:
- táµ¢: æ—¶é—´æˆ³
- váµ¢: è§‚æµ‹å€¼
- táµ¢ < táµ¢â‚Šâ‚ (å•è°ƒé€’å¢)
```

---

## Temporality (æ—¶é—´æ€§)

### å®šä¹‰

**Temporality** å®šä¹‰äº†æ•°æ®ç‚¹çš„æ—¶é—´è¯­ä¹‰ï¼Œå†³å®šäº†å¦‚ä½•è§£é‡Šæ•°æ®ç‚¹çš„å€¼ã€‚

### Cumulative (ç´¯ç§¯)

**å€¼æ˜¯ä»èµ·å§‹æ—¶é—´ç´¯ç§¯åˆ°å½“å‰çš„æ€»é‡**ã€‚

```text
ç‰¹ç‚¹:
- èµ·å§‹æ—¶é—´: è¿›ç¨‹å¯åŠ¨æˆ–é¦–æ¬¡è®°å½•
- å€¼æ˜¯ç´¯ç§¯çš„æ€»é‡
- é€‚åˆé•¿æœŸè¶‹åŠ¿åˆ†æ

ç¤ºä¾‹:
T0: value = 10  (ç´¯ç§¯: 0 â†’ 10)
T1: value = 25  (ç´¯ç§¯: 0 â†’ 25)
T2: value = 42  (ç´¯ç§¯: 0 â†’ 42)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cumulative Counter                  â”‚
â”‚                                     â”‚
â”‚ 50â”‚                          â—42   â”‚
â”‚   â”‚                    â—25         â”‚
â”‚ 30â”‚                               â”‚
â”‚   â”‚              â—10              â”‚
â”‚ 10â”‚                               â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚       T0   T1   T2               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Delta (å¢é‡)

**å€¼æ˜¯ä¸¤æ¬¡å¯¼å‡ºä¹‹é—´çš„å˜åŒ–é‡**ã€‚

```text
ç‰¹ç‚¹:
- èµ·å§‹æ—¶é—´: ä¸Šæ¬¡å¯¼å‡ºæ—¶é—´
- å€¼æ˜¯æ—¶é—´æ®µå†…çš„å¢é‡
- é€‚åˆçŸ­æœŸå˜åŒ–ç›‘æ§

ç¤ºä¾‹:
T0â†’T1: value = 10  (å¢é‡: +10)
T1â†’T2: value = 15  (å¢é‡: +15)
T2â†’T3: value = 17  (å¢é‡: +17)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Delta Counter                       â”‚
â”‚                                     â”‚
â”‚ 20â”‚        â—17                      â”‚
â”‚   â”‚    â—15                          â”‚
â”‚ 10â”‚â—10                              â”‚
â”‚   â”‚                                 â”‚
â”‚  0â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚      T0â†’T1 T1â†’T2 T2â†’T3           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¯¹æ¯”åˆ†æ

| ç‰¹æ€§ | Cumulative | Delta |
|------|------------|-------|
| **èµ·å§‹æ—¶é—´** | è¿›ç¨‹å¯åŠ¨ | ä¸Šæ¬¡å¯¼å‡º |
| **å€¼çš„å«ä¹‰** | ç´¯ç§¯æ€»é‡ | æ—¶é—´æ®µå¢é‡ |
| **Reset å¤„ç†** | éœ€è¦æ£€æµ‹é‡å¯ | è‡ªåŠ¨å¤„ç† |
| **å­˜å‚¨ç©ºé—´** | è¾ƒå¤§ | è¾ƒå° |
| **èšåˆå¤æ‚åº¦** | ç®€å• (å–æœ€æ–°å€¼) | å¤æ‚ (éœ€ç´¯åŠ ) |
| **é€‚ç”¨åœºæ™¯** | Prometheus | StatsD, DataDog |

### Go å®ç°

```go
package timeseries

import (
    "go.opentelemetry.io/otel/sdk/metric"
    "go.opentelemetry.io/otel/sdk/metric/metricdata"
)

// é…ç½® Temporality
func setupTemporality(exporter metric.Exporter) *metric.PeriodicReader {
    // 1. å…¨éƒ¨ä½¿ç”¨ Cumulative
    return metric.NewPeriodicReader(
        exporter,
        metric.WithTemporalitySelector(
            func(ik metric.InstrumentKind) metricdata.Temporality {
                return metricdata.CumulativeTemporality
            },
        ),
    )
}

// 2. æ ¹æ® Instrument ç±»å‹é€‰æ‹©
func setupMixedTemporality(exporter metric.Exporter) *metric.PeriodicReader {
    return metric.NewPeriodicReader(
        exporter,
        metric.WithTemporalitySelector(
            func(ik metric.InstrumentKind) metricdata.Temporality {
                switch ik {
                case metric.InstrumentKindCounter:
                    return metricdata.DeltaTemporality
                case metric.InstrumentKindUpDownCounter:
                    return metricdata.CumulativeTemporality
                case metric.InstrumentKindHistogram:
                    return metricdata.DeltaTemporality
                default:
                    return metricdata.CumulativeTemporality
                }
            },
        ),
    )
}

// 3. Prometheus é£æ ¼ (å…¨éƒ¨ Cumulative)
func setupPrometheusTemporality(exporter metric.Exporter) *metric.PeriodicReader {
    return metric.NewPeriodicReader(
        exporter,
        metric.WithTemporalitySelector(
            func(ik metric.InstrumentKind) metricdata.Temporality {
                return metricdata.CumulativeTemporality
            },
        ),
    )
}

// 4. StatsD é£æ ¼ (å…¨éƒ¨ Delta)
func setupStatsDTemporality(exporter metric.Exporter) *metric.PeriodicReader {
    return metric.NewPeriodicReader(
        exporter,
        metric.WithTemporalitySelector(
            func(ik metric.InstrumentKind) metricdata.Temporality {
                return metricdata.DeltaTemporality
            },
        ),
    )
}
```

---

## Aggregation (èšåˆ)

### èšåˆç±»å‹

OpenTelemetry å®šä¹‰äº†å¤šç§èšåˆæ–¹å¼ï¼š

| èšåˆç±»å‹ | é€‚ç”¨ Metric | è¯´æ˜ |
|---------|-------------|------|
| **Sum** | Counter, UpDownCounter | æ±‚å’Œ |
| **LastValue** | Gauge | æœ€æ–°å€¼ |
| **Histogram** | Histogram | åˆ†å¸ƒç»Ÿè®¡ |
| **ExponentialHistogram** | Histogram | æŒ‡æ•°åˆ†å¸ƒ |

### Sum (æ±‚å’Œ)

```go
// Sum èšåˆ
type SumAggregation struct {
    Value        float64
    StartTime    time.Time
    EndTime      time.Time
    Temporality  metricdata.Temporality
}

// ç´¯åŠ è§‚æµ‹å€¼
func (s *SumAggregation) Aggregate(value float64) {
    s.Value += value
    s.EndTime = time.Now()
}

// å¯¼å‡ºæ•°æ®ç‚¹
func (s *SumAggregation) Export() metricdata.DataPoint {
    return metricdata.DataPoint{
        StartTime: s.StartTime,
        Time:      s.EndTime,
        Value:     s.Value,
    }
}

// Reset (Delta æ¨¡å¼)
func (s *SumAggregation) Reset() {
    s.StartTime = s.EndTime
    s.Value = 0
}
```

### LastValue (æœ€æ–°å€¼)

```go
// LastValue èšåˆ
type LastValueAggregation struct {
    Value     float64
    Timestamp time.Time
}

// æ›´æ–°ä¸ºæœ€æ–°å€¼
func (lv *LastValueAggregation) Update(value float64, timestamp time.Time) {
    if timestamp.After(lv.Timestamp) {
        lv.Value = value
        lv.Timestamp = timestamp
    }
}

// å¯¼å‡ºæ•°æ®ç‚¹
func (lv *LastValueAggregation) Export() metricdata.DataPoint {
    return metricdata.DataPoint{
        Time:  lv.Timestamp,
        Value: lv.Value,
    }
}
```

### Histogram (ç›´æ–¹å›¾)

```go
// Histogram èšåˆ
type HistogramAggregation struct {
    Bounds       []float64
    Counts       []uint64
    Sum          float64
    Count        uint64
    Min          float64
    Max          float64
    StartTime    time.Time
    EndTime      time.Time
}

func NewHistogramAggregation(bounds []float64) *HistogramAggregation {
    return &HistogramAggregation{
        Bounds:    bounds,
        Counts:    make([]uint64, len(bounds)+1),
        StartTime: time.Now(),
        Min:       math.Inf(1),
        Max:       math.Inf(-1),
    }
}

// è®°å½•è§‚æµ‹å€¼
func (h *HistogramAggregation) Record(value float64) {
    h.Count++
    h.Sum += value
    h.EndTime = time.Now()
    
    if value < h.Min {
        h.Min = value
    }
    if value > h.Max {
        h.Max = value
    }
    
    // æ‰¾åˆ°å¯¹åº”çš„æ¡¶
    bucketIdx := len(h.Bounds)
    for i, bound := range h.Bounds {
        if value <= bound {
            bucketIdx = i
            break
        }
    }
    h.Counts[bucketIdx]++
}

// å¯¼å‡ºæ•°æ®ç‚¹
func (h *HistogramAggregation) Export() metricdata.HistogramDataPoint {
    return metricdata.HistogramDataPoint{
        StartTime:      h.StartTime,
        Time:           h.EndTime,
        Count:          h.Count,
        Sum:            &h.Sum,
        BucketCounts:   h.Counts,
        ExplicitBounds: h.Bounds,
        Min:            &h.Min,
        Max:            &h.Max,
    }
}

// Reset (Delta æ¨¡å¼)
func (h *HistogramAggregation) Reset() {
    h.StartTime = h.EndTime
    h.Count = 0
    h.Sum = 0
    h.Min = math.Inf(1)
    h.Max = math.Inf(-1)
    for i := range h.Counts {
        h.Counts[i] = 0
    }
}
```

### ExponentialHistogram (æŒ‡æ•°ç›´æ–¹å›¾)

```go
// ExponentialHistogram èšåˆ
type ExponentialHistogramAggregation struct {
    Scale        int32
    ZeroCount    uint64
    PositiveBuckets map[int32]uint64
    NegativeBuckets map[int32]uint64
    Sum          float64
    Count        uint64
    StartTime    time.Time
    EndTime      time.Time
}

func NewExponentialHistogramAggregation(scale int32) *ExponentialHistogramAggregation {
    return &ExponentialHistogramAggregation{
        Scale:           scale,
        PositiveBuckets: make(map[int32]uint64),
        NegativeBuckets: make(map[int32]uint64),
        StartTime:       time.Now(),
    }
}

// è®¡ç®—æ¡¶ç´¢å¼•
func (eh *ExponentialHistogramAggregation) bucketIndex(value float64) int32 {
    if value == 0 {
        return 0
    }
    
    import "math"
    base := math.Pow(2, math.Pow(2, float64(-eh.Scale)))
    return int32(math.Floor(math.Log(math.Abs(value)) / math.Log(base)))
}

// è®°å½•è§‚æµ‹å€¼
func (eh *ExponentialHistogramAggregation) Record(value float64) {
    eh.Count++
    eh.Sum += value
    eh.EndTime = time.Now()
    
    if value == 0 {
        eh.ZeroCount++
        return
    }
    
    idx := eh.bucketIndex(value)
    if value > 0 {
        eh.PositiveBuckets[idx]++
    } else {
        eh.NegativeBuckets[idx]++
    }
}
```

---

## Aggregation Temporality

### Counter èšåˆ

```go
// Counter: Sum + Cumulative/Delta
type CounterAggregation struct {
    value       int64
    startTime   time.Time
    temporality metricdata.Temporality
}

func (c *CounterAggregation) Add(delta int64) {
    atomic.AddInt64(&c.value, delta)
}

func (c *CounterAggregation) Export() (int64, bool) {
    value := atomic.LoadInt64(&c.value)
    
    if c.temporality == metricdata.DeltaTemporality {
        // Delta: å¯¼å‡ºåé‡ç½®
        atomic.StoreInt64(&c.value, 0)
        c.startTime = time.Now()
        return value, true
    }
    
    // Cumulative: ä¿æŒç´¯ç§¯å€¼
    return value, false
}
```

### UpDownCounter èšåˆ

```go
// UpDownCounter: Sum + Cumulative/Delta
type UpDownCounterAggregation struct {
    value       int64
    startTime   time.Time
    temporality metricdata.Temporality
}

func (udc *UpDownCounterAggregation) Add(delta int64) {
    atomic.AddInt64(&udc.value, delta)
}

func (udc *UpDownCounterAggregation) Export() (int64, bool) {
    value := atomic.LoadInt64(&udc.value)
    
    if udc.temporality == metricdata.DeltaTemporality {
        atomic.StoreInt64(&udc.value, 0)
        udc.startTime = time.Now()
        return value, true
    }
    
    return value, false
}
```

### Gauge èšåˆ

```go
// Gauge: LastValue (æ—  Temporality)
type GaugeAggregation struct {
    value     float64
    timestamp time.Time
    mu        sync.RWMutex
}

func (g *GaugeAggregation) Set(value float64) {
    g.mu.Lock()
    g.value = value
    g.timestamp = time.Now()
    g.mu.Unlock()
}

func (g *GaugeAggregation) Export() (float64, time.Time) {
    g.mu.RLock()
    defer g.mu.RUnlock()
    return g.value, g.timestamp
}
```

### Histogram èšåˆ

```go
// Histogram: Histogram + Cumulative/Delta
type HistogramAggregationWithTemporality struct {
    *HistogramAggregation
    temporality metricdata.Temporality
}

func (h *HistogramAggregationWithTemporality) Export() metricdata.HistogramDataPoint {
    dp := h.HistogramAggregation.Export()
    
    if h.temporality == metricdata.DeltaTemporality {
        h.HistogramAggregation.Reset()
    }
    
    return dp
}
```

---

## æ—¶é—´çª—å£ç®¡ç†

### çª—å£ç±»å‹

```text
1. å›ºå®šçª—å£ (Fixed Window):
   [0, 60s] [60s, 120s] [120s, 180s] ...

2. æ»šåŠ¨çª—å£ (Tumbling Window):
   æ¯60sä¸€ä¸ªçª—å£ï¼Œæ— é‡å 

3. æ»‘åŠ¨çª—å£ (Sliding Window):
   æ¯10sæ»‘åŠ¨ä¸€æ¬¡ï¼Œçª—å£60s
   [0, 60s] [10s, 70s] [20s, 80s] ...

4. ä¼šè¯çª—å£ (Session Window):
   åŸºäºæ´»åŠ¨é—´éš”
```

### æ»šåŠ¨çª—å£

```go
// æ»šåŠ¨çª—å£
type TumblingWindow struct {
    interval time.Duration
    data     []float64
    startTime time.Time
    mu       sync.Mutex
}

func NewTumblingWindow(interval time.Duration) *TumblingWindow {
    return &TumblingWindow{
        interval:  interval,
        data:      make([]float64, 0, 1000),
        startTime: time.Now(),
    }
}

func (tw *TumblingWindow) Add(value float64) {
    tw.mu.Lock()
    defer tw.mu.Unlock()
    
    now := time.Now()
    if now.Sub(tw.startTime) >= tw.interval {
        // çª—å£ç»“æŸï¼Œå¯¼å‡ºæ•°æ®
        tw.export()
        tw.data = tw.data[:0]
        tw.startTime = now
    }
    
    tw.data = append(tw.data, value)
}

func (tw *TumblingWindow) export() {
    // è®¡ç®—èšåˆå€¼
    var sum float64
    for _, v := range tw.data {
        sum += v
    }
    avg := sum / float64(len(tw.data))
    
    fmt.Printf("Window [%v, %v): count=%d, sum=%.2f, avg=%.2f\n",
        tw.startTime, time.Now(), len(tw.data), sum, avg)
}
```

### æ»‘åŠ¨çª—å£

```go
// æ»‘åŠ¨çª—å£
type SlidingWindow struct {
    windowSize time.Duration
    slideInterval time.Duration
    data       []TimestampedValue
    mu         sync.RWMutex
}

type TimestampedValue struct {
    Value     float64
    Timestamp time.Time
}

func NewSlidingWindow(windowSize, slideInterval time.Duration) *SlidingWindow {
    sw := &SlidingWindow{
        windowSize:    windowSize,
        slideInterval: slideInterval,
        data:          make([]TimestampedValue, 0, 10000),
    }
    
    // å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
    go sw.cleanup()
    
    return sw
}

func (sw *SlidingWindow) Add(value float64) {
    sw.mu.Lock()
    defer sw.mu.Unlock()
    
    sw.data = append(sw.data, TimestampedValue{
        Value:     value,
        Timestamp: time.Now(),
    })
}

func (sw *SlidingWindow) GetWindowData() []float64 {
    sw.mu.RLock()
    defer sw.mu.RUnlock()
    
    cutoff := time.Now().Add(-sw.windowSize)
    result := make([]float64, 0, len(sw.data))
    
    for _, tv := range sw.data {
        if tv.Timestamp.After(cutoff) {
            result = append(result, tv.Value)
        }
    }
    
    return result
}

func (sw *SlidingWindow) cleanup() {
    ticker := time.NewTicker(sw.slideInterval)
    defer ticker.Stop()
    
    for range ticker.C {
        sw.mu.Lock()
        cutoff := time.Now().Add(-sw.windowSize)
        
        // ç§»é™¤è¿‡æœŸæ•°æ®
        validIdx := 0
        for i, tv := range sw.data {
            if tv.Timestamp.After(cutoff) {
                validIdx = i
                break
            }
        }
        sw.data = sw.data[validIdx:]
        sw.mu.Unlock()
    }
}
```

### Go å®ç°2

```go
// å®Œæ•´çš„çª—å£ç®¡ç†å™¨
type WindowManager struct {
    windows map[string]*TumblingWindow
    mu      sync.RWMutex
}

func NewWindowManager() *WindowManager {
    return &WindowManager{
        windows: make(map[string]*TumblingWindow),
    }
}

func (wm *WindowManager) GetOrCreateWindow(
    name string,
    interval time.Duration,
) *TumblingWindow {
    wm.mu.Lock()
    defer wm.mu.Unlock()
    
    if window, exists := wm.windows[name]; exists {
        return window
    }
    
    window := NewTumblingWindow(interval)
    wm.windows[name] = window
    return window
}
```

---

## æ—¶é—´å¯¹é½

### å¯¹é½ç­–ç•¥

```go
// æ—¶é—´å¯¹é½å™¨
type TimeAligner struct {
    interval time.Duration
}

func NewTimeAligner(interval time.Duration) *TimeAligner {
    return &TimeAligner{interval: interval}
}

// å¯¹é½åˆ°æœ€è¿‘çš„æ—¶é—´ç‚¹
func (ta *TimeAligner) AlignFloor(t time.Time) time.Time {
    unix := t.Unix()
    intervalSec := int64(ta.interval.Seconds())
    aligned := (unix / intervalSec) * intervalSec
    return time.Unix(aligned, 0)
}

// å¯¹é½åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹
func (ta *TimeAligner) AlignCeil(t time.Time) time.Time {
    unix := t.Unix()
    intervalSec := int64(ta.interval.Seconds())
    aligned := ((unix + intervalSec - 1) / intervalSec) * intervalSec
    return time.Unix(aligned, 0)
}

// ç¤ºä¾‹
func exampleTimeAlignment() {
    aligner := NewTimeAligner(60 * time.Second)
    
    now := time.Now()
    // 2025-10-09 14:32:45
    
    floor := aligner.AlignFloor(now)
    // 2025-10-09 14:32:00
    
    ceil := aligner.AlignCeil(now)
    // 2025-10-09 14:33:00
}
```

### æ—¶é’Ÿåç§»å¤„ç†

```go
// æ—¶é’Ÿåç§»æ£€æµ‹
type ClockSkewDetector struct {
    lastTimestamp time.Time
    maxSkew       time.Duration
    mu            sync.Mutex
}

func NewClockSkewDetector(maxSkew time.Duration) *ClockSkewDetector {
    return &ClockSkewDetector{
        maxSkew: maxSkew,
    }
}

func (csd *ClockSkewDetector) CheckAndUpdate(t time.Time) error {
    csd.mu.Lock()
    defer csd.mu.Unlock()
    
    if !csd.lastTimestamp.IsZero() {
        if t.Before(csd.lastTimestamp) {
            skew := csd.lastTimestamp.Sub(t)
            if skew > csd.maxSkew {
                return fmt.Errorf("clock skew detected: %v", skew)
            }
        }
    }
    
    csd.lastTimestamp = t
    return nil
}
```

### Go å®ç°3

```go
// NTP æ—¶é—´åŒæ­¥
func syncTimeWithNTP(server string) (time.Time, error) {
    import "github.com/beevik/ntp"
    
    response, err := ntp.Query(server)
    if err != nil {
        return time.Time{}, err
    }
    
    return time.Now().Add(response.ClockOffset), nil
}

// ä½¿ç”¨ NTP æ—¶é—´
func useNTPTime() {
    ntpTime, err := syncTimeWithNTP("pool.ntp.org")
    if err != nil {
        log.Printf("NTP sync failed: %v", err)
        return
    }
    
    offset := ntpTime.Sub(time.Now())
    log.Printf("Clock offset: %v", offset)
}
```

---

## é™é‡‡æ ·ä¸ä¸Šé‡‡æ ·

### é™é‡‡æ ·

**é™é‡‡æ · (Downsampling)**: é™ä½æ—¶é—´åºåˆ—çš„åˆ†è¾¨ç‡ã€‚

```go
// é™é‡‡æ ·å™¨
type Downsampler struct {
    interval time.Duration
}

func NewDownsampler(interval time.Duration) *Downsampler {
    return &Downsampler{interval: interval}
}

// å¹³å‡å€¼é™é‡‡æ ·
func (ds *Downsampler) DownsampleAverage(
    data []TimestampedValue,
) []TimestampedValue {
    if len(data) == 0 {
        return nil
    }
    
    result := make([]TimestampedValue, 0)
    aligner := NewTimeAligner(ds.interval)
    
    var bucket []float64
    var bucketTime time.Time
    
    for _, tv := range data {
        aligned := aligner.AlignFloor(tv.Timestamp)
        
        if bucketTime.IsZero() || aligned == bucketTime {
            bucket = append(bucket, tv.Value)
            bucketTime = aligned
        } else {
            // è®¡ç®—å¹³å‡å€¼
            if len(bucket) > 0 {
                var sum float64
                for _, v := range bucket {
                    sum += v
                }
                result = append(result, TimestampedValue{
                    Value:     sum / float64(len(bucket)),
                    Timestamp: bucketTime,
                })
            }
            
            bucket = []float64{tv.Value}
            bucketTime = aligned
        }
    }
    
    // æœ€åä¸€ä¸ªæ¡¶
    if len(bucket) > 0 {
        var sum float64
        for _, v := range bucket {
            sum += v
        }
        result = append(result, TimestampedValue{
            Value:     sum / float64(len(bucket)),
            Timestamp: bucketTime,
        })
    }
    
    return result
}

// æœ€å¤§å€¼é™é‡‡æ ·
func (ds *Downsampler) DownsampleMax(
    data []TimestampedValue,
) []TimestampedValue {
    // ç±»ä¼¼å®ç°ï¼Œä½¿ç”¨ max è€Œä¸æ˜¯ average
    return nil
}

// æœ€å°å€¼é™é‡‡æ ·
func (ds *Downsampler) DownsampleMin(
    data []TimestampedValue,
) []TimestampedValue {
    // ç±»ä¼¼å®ç°ï¼Œä½¿ç”¨ min è€Œä¸æ˜¯ average
    return nil
}
```

### ä¸Šé‡‡æ ·

**ä¸Šé‡‡æ · (Upsampling)**: å¢åŠ æ—¶é—´åºåˆ—çš„åˆ†è¾¨ç‡ã€‚

```go
// ä¸Šé‡‡æ ·å™¨
type Upsampler struct {
    interval time.Duration
}

func NewUpsampler(interval time.Duration) *Upsampler {
    return &Upsampler{interval: interval}
}

// çº¿æ€§æ’å€¼ä¸Šé‡‡æ ·
func (us *Upsampler) UpsampleLinear(
    data []TimestampedValue,
) []TimestampedValue {
    if len(data) < 2 {
        return data
    }
    
    result := make([]TimestampedValue, 0)
    
    for i := 0; i < len(data)-1; i++ {
        current := data[i]
        next := data[i+1]
        
        result = append(result, current)
        
        // è®¡ç®—æ’å€¼ç‚¹
        duration := next.Timestamp.Sub(current.Timestamp)
        numPoints := int(duration / us.interval)
        
        for j := 1; j < numPoints; j++ {
            t := current.Timestamp.Add(time.Duration(j) * us.interval)
            // çº¿æ€§æ’å€¼
            ratio := float64(j) / float64(numPoints)
            value := current.Value + (next.Value-current.Value)*ratio
            
            result = append(result, TimestampedValue{
                Value:     value,
                Timestamp: t,
            })
        }
    }
    
    result = append(result, data[len(data)-1])
    return result
}
```

### Go å®ç°4

```go
// è‡ªé€‚åº”é‡‡æ ·
type AdaptiveSampler struct {
    minInterval time.Duration
    maxInterval time.Duration
    threshold   float64
}

func (as *AdaptiveSampler) Sample(
    data []TimestampedValue,
) []TimestampedValue {
    result := make([]TimestampedValue, 0)
    
    for i := 0; i < len(data); i++ {
        if i == 0 || i == len(data)-1 {
            result = append(result, data[i])
            continue
        }
        
        // è®¡ç®—å˜åŒ–ç‡
        prev := data[i-1].Value
        curr := data[i].Value
        change := math.Abs(curr - prev)
        
        // å˜åŒ–å¤§æ—¶ä¿ç•™
        if change > as.threshold {
            result = append(result, data[i])
        }
    }
    
    return result
}
```

---

## æ—¶é—´åºåˆ—å­˜å‚¨

### å­˜å‚¨æ¨¡å‹

```go
// æ—¶é—´åºåˆ—å­˜å‚¨
type TimeSeriesStore struct {
    data   map[string][]TimestampedValue
    mu     sync.RWMutex
    maxSize int
}

func NewTimeSeriesStore(maxSize int) *TimeSeriesStore {
    return &TimeSeriesStore{
        data:    make(map[string][]TimestampedValue),
        maxSize: maxSize,
    }
}

func (tss *TimeSeriesStore) Append(
    seriesName string,
    value float64,
    timestamp time.Time,
) {
    tss.mu.Lock()
    defer tss.mu.Unlock()
    
    series := tss.data[seriesName]
    series = append(series, TimestampedValue{
        Value:     value,
        Timestamp: timestamp,
    })
    
    // é™åˆ¶å¤§å°
    if len(series) > tss.maxSize {
        series = series[len(series)-tss.maxSize:]
    }
    
    tss.data[seriesName] = series
}

func (tss *TimeSeriesStore) Query(
    seriesName string,
    start, end time.Time,
) []TimestampedValue {
    tss.mu.RLock()
    defer tss.mu.RUnlock()
    
    series := tss.data[seriesName]
    result := make([]TimestampedValue, 0)
    
    for _, tv := range series {
        if tv.Timestamp.After(start) && tv.Timestamp.Before(end) {
            result = append(result, tv)
        }
    }
    
    return result
}
```

### å‹ç¼©ç­–ç•¥

```go
// Delta-of-Delta å‹ç¼©
type DeltaOfDeltaCompressor struct {
    lastValue     int64
    lastDelta     int64
    lastTimestamp int64
}

func (doc *DeltaOfDeltaCompressor) Compress(
    value int64,
    timestamp int64,
) (valueDelta, timeDelta int64) {
    if doc.lastTimestamp == 0 {
        doc.lastValue = value
        doc.lastTimestamp = timestamp
        return value, timestamp
    }
    
    // è®¡ç®— delta
    valueDelta = value - doc.lastValue
    timeDelta = timestamp - doc.lastTimestamp
    
    // è®¡ç®— delta-of-delta
    valueDeltaOfDelta := valueDelta - doc.lastDelta
    
    doc.lastValue = value
    doc.lastDelta = valueDelta
    doc.lastTimestamp = timestamp
    
    return valueDeltaOfDelta, timeDelta
}
```

### ç´¢å¼•ä¼˜åŒ–

```go
// æ—¶é—´åºåˆ—ç´¢å¼•
type TimeSeriesIndex struct {
    labelIndex map[string][]string // label -> series names
    mu         sync.RWMutex
}

func NewTimeSeriesIndex() *TimeSeriesIndex {
    return &TimeSeriesIndex{
        labelIndex: make(map[string][]string),
    }
}

func (tsi *TimeSeriesIndex) Index(
    seriesName string,
    labels map[string]string,
) {
    tsi.mu.Lock()
    defer tsi.mu.Unlock()
    
    for key, value := range labels {
        labelKey := key + "=" + value
        tsi.labelIndex[labelKey] = append(
            tsi.labelIndex[labelKey],
            seriesName,
        )
    }
}

func (tsi *TimeSeriesIndex) Query(
    labelKey, labelValue string,
) []string {
    tsi.mu.RLock()
    defer tsi.mu.RUnlock()
    
    labelKey = labelKey + "=" + labelValue
    return tsi.labelIndex[labelKey]
}
```

---

## æ—¶é—´åºåˆ—æŸ¥è¯¢

### æŸ¥è¯¢è¯­è¨€

```text
å¸¸è§æŸ¥è¯¢è¯­è¨€:
1. PromQL (Prometheus Query Language)
2. InfluxQL (InfluxDB Query Language)
3. Flux (InfluxDB 2.0+)
4. M3QL (M3DB Query Language)
```

### PromQL ç¤ºä¾‹

```promql
# å³æ—¶æŸ¥è¯¢
http_requests_total

# èŒƒå›´æŸ¥è¯¢
http_requests_total[5m]

# èšåˆ
sum(rate(http_requests_total[5m])) by (status)

# ç®—æœ¯è¿ç®—
http_requests_total / http_requests_duration_seconds_sum

# é¢„æµ‹
predict_linear(http_requests_total[1h], 3600)
```

### Go å®¢æˆ·ç«¯æŸ¥è¯¢

```go
import (
    "github.com/prometheus/client_golang/api"
    v1 "github.com/prometheus/client_golang/api/prometheus/v1"
)

// Prometheus æŸ¥è¯¢
func queryPrometheus(query string) error {
    client, err := api.NewClient(api.Config{
        Address: "http://localhost:9090",
    })
    if err != nil {
        return err
    }
    
    v1api := v1.NewAPI(client)
    ctx := context.Background()
    
    // å³æ—¶æŸ¥è¯¢
    result, warnings, err := v1api.Query(ctx, query, time.Now())
    if err != nil {
        return err
    }
    
    for _, w := range warnings {
        log.Printf("Warning: %s", w)
    }
    
    fmt.Printf("Result: %v\n", result)
    return nil
}

// èŒƒå›´æŸ¥è¯¢
func queryPrometheusRange(query string, start, end time.Time, step time.Duration) error {
    client, err := api.NewClient(api.Config{
        Address: "http://localhost:9090",
    })
    if err != nil {
        return err
    }
    
    v1api := v1.NewAPI(client)
    ctx := context.Background()
    
    r := v1.Range{
        Start: start,
        End:   end,
        Step:  step,
    }
    
    result, warnings, err := v1api.QueryRange(ctx, query, r)
    if err != nil {
        return err
    }
    
    for _, w := range warnings {
        log.Printf("Warning: %s", w)
    }
    
    fmt.Printf("Result: %v\n", result)
    return nil
}
```

---

## å®Œæ•´å®ç°

### æ—¶é—´åºåˆ—ç®¡ç†ç³»ç»Ÿ

```go
package timeseries

import (
    "context"
    "sync"
    "time"
)

// TimeSeriesManager æ—¶é—´åºåˆ—ç®¡ç†å™¨
type TimeSeriesManager struct {
    store       *TimeSeriesStore
    index       *TimeSeriesIndex
    downsampler *Downsampler
    aligner     *TimeAligner
    mu          sync.RWMutex
}

func NewTimeSeriesManager(
    maxSize int,
    downsampleInterval time.Duration,
    alignInterval time.Duration,
) *TimeSeriesManager {
    return &TimeSeriesManager{
        store:       NewTimeSeriesStore(maxSize),
        index:       NewTimeSeriesIndex(),
        downsampler: NewDownsampler(downsampleInterval),
        aligner:     NewTimeAligner(alignInterval),
    }
}

// Record è®°å½•æ•°æ®ç‚¹
func (tsm *TimeSeriesManager) Record(
    ctx context.Context,
    seriesName string,
    value float64,
    labels map[string]string,
) {
    timestamp := time.Now()
    alignedTime := tsm.aligner.AlignFloor(timestamp)
    
    // å­˜å‚¨æ•°æ®
    tsm.store.Append(seriesName, value, alignedTime)
    
    // ç´¢å¼•æ ‡ç­¾
    tsm.index.Index(seriesName, labels)
}

// Query æŸ¥è¯¢æ•°æ®
func (tsm *TimeSeriesManager) Query(
    seriesName string,
    start, end time.Time,
    downsample bool,
) []TimestampedValue {
    data := tsm.store.Query(seriesName, start, end)
    
    if downsample {
        data = tsm.downsampler.DownsampleAverage(data)
    }
    
    return data
}

// QueryByLabel æŒ‰æ ‡ç­¾æŸ¥è¯¢
func (tsm *TimeSeriesManager) QueryByLabel(
    labelKey, labelValue string,
    start, end time.Time,
) map[string][]TimestampedValue {
    seriesNames := tsm.index.Query(labelKey, labelValue)
    
    result := make(map[string][]TimestampedValue)
    for _, name := range seriesNames {
        result[name] = tsm.store.Query(name, start, end)
    }
    
    return result
}

// Aggregate èšåˆå¤šä¸ªåºåˆ—
func (tsm *TimeSeriesManager) Aggregate(
    seriesNames []string,
    start, end time.Time,
    aggFunc func([]float64) float64,
) []TimestampedValue {
    // è·å–æ‰€æœ‰åºåˆ—æ•°æ®
    allData := make([][]TimestampedValue, len(seriesNames))
    for i, name := range seriesNames {
        allData[i] = tsm.store.Query(name, start, end)
    }
    
    // æ—¶é—´å¯¹é½å’Œèšåˆ
    result := make([]TimestampedValue, 0)
    // ... å®ç°èšåˆé€»è¾‘
    
    return result
}
```

---

## æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„ Temporality

```go
// âœ… æ¨èï¼šæ ¹æ®åç«¯é€‰æ‹©
// Prometheus: Cumulative
// StatsD/DataDog: Delta

func setupForPrometheus() {
    // ä½¿ç”¨ Cumulative
}

func setupForStatsD() {
    // ä½¿ç”¨ Delta
}
```

### 2. åˆç†çš„èšåˆç²’åº¦

```go
// âœ… æ¨èï¼šå¤šçº§èšåˆ
// åŸå§‹æ•°æ®: 1s
// 1åˆ†é’Ÿèšåˆ: é™é‡‡æ ·åˆ° 10s
// 1å°æ—¶èšåˆ: é™é‡‡æ ·åˆ° 1min
// 1å¤©èšåˆ: é™é‡‡æ ·åˆ° 5min

type MultiLevelAggregation struct {
    raw       *TimeSeriesStore  // 1s
    minute    *TimeSeriesStore  // 10s
    hour      *TimeSeriesStore  // 1min
    day       *TimeSeriesStore  // 5min
}
```

### 3. æ—¶é—´çª—å£é…ç½®

```go
// âœ… æ¨èï¼šæ ¹æ®åœºæ™¯é€‰æ‹©çª—å£å¤§å°
const (
    RealtimeWindow  = 5 * time.Minute   // å®æ—¶ç›‘æ§
    ShortTermWindow = 1 * time.Hour     // çŸ­æœŸåˆ†æ
    LongTermWindow  = 24 * time.Hour    // é•¿æœŸè¶‹åŠ¿
)
```

### 4. é«˜åŸºæ•°å¤„ç†

```go
// âœ… æ¨èï¼šé™åˆ¶æ ‡ç­¾åŸºæ•°
const MaxCardinality = 10000

func checkCardinality(labels map[string]string) error {
    // æ£€æŸ¥æ ‡ç­¾ç»„åˆæ•°é‡
    if cardinality > MaxCardinality {
        return fmt.Errorf("cardinality too high: %d", cardinality)
    }
    return nil
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡èšåˆ

```go
// âœ… æ‰¹é‡å¤„ç†
func batchAggregate(data []TimestampedValue, batchSize int) {
    for i := 0; i < len(data); i += batchSize {
        end := i + batchSize
        if end > len(data) {
            end = len(data)
        }
        batch := data[i:end]
        processBatch(batch)
    }
}
```

### 2. é¢„èšåˆ

```go
// âœ… é¢„èšåˆçƒ­æ•°æ®
type PreAggregator struct {
    cache map[string]float64
    mu    sync.RWMutex
}

func (pa *PreAggregator) Update(key string, value float64) {
    pa.mu.Lock()
    pa.cache[key] += value
    pa.mu.Unlock()
}
```

### 3. åˆ†ç‰‡ç­–ç•¥

```go
// âœ… æŒ‰æ—¶é—´åˆ†ç‰‡
type ShardedStore struct {
    shards    []*TimeSeriesStore
    shardSize time.Duration
}

func (ss *ShardedStore) getShard(t time.Time) *TimeSeriesStore {
    idx := int(t.Unix() / int64(ss.shardSize.Seconds()))
    return ss.shards[idx%len(ss.shards)]
}
```

---

## å¸¸è§é—®é¢˜

### Q1: Cumulative å’Œ Delta å¦‚ä½•é€‰æ‹©ï¼Ÿ

**A**: æ ¹æ®ç›‘æ§åç«¯

- **Prometheus**: Cumulative
- **StatsD/DataDog**: Delta
- **æ··åˆç¯å¢ƒ**: æ ¹æ® Instrument ç±»å‹åˆ†åˆ«é…ç½®

---

### Q2: å¦‚ä½•å¤„ç†æ—¶é—´çª—å£é‡å ï¼Ÿ

**A**: ä½¿ç”¨æ»šåŠ¨çª—å£é¿å…é‡å ï¼Œæˆ–ä½¿ç”¨æ»‘åŠ¨çª—å£å¹¶å»é‡

---

### Q3: å¦‚ä½•å¤„ç†æ—¶é’Ÿåç§»ï¼Ÿ

**A**:

1. ä½¿ç”¨ NTP åŒæ­¥
2. æ£€æµ‹å¹¶è®°å½•åç§»
3. å®¹å¿å°èŒƒå›´åç§» (< 5s)

---

### Q4: é™é‡‡æ ·ä¼šä¸¢å¤±æ•°æ®å—ï¼Ÿ

**A**:

- å¹³å‡å€¼é™é‡‡æ ·: ä¿ç•™è¶‹åŠ¿
- æœ€å¤§/æœ€å°å€¼é™é‡‡æ ·: ä¿ç•™æå€¼
- ä½¿ç”¨å¤šç§èšåˆæ–¹å¼ä¿ç•™æ›´å¤šä¿¡æ¯

---

### Q5: å¦‚ä½•ä¼˜åŒ–æ—¶é—´åºåˆ—å­˜å‚¨ï¼Ÿ

**A**:

1. ä½¿ç”¨å‹ç¼© (Delta-of-Delta)
2. åˆ†çº§å­˜å‚¨ (çƒ­/å†·æ•°æ®)
3. å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
4. ä½¿ç”¨ä¸“ç”¨æ—¶åºæ•°æ®åº“

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [OpenTelemetry Metrics Data Model](https://opentelemetry.io/docs/specs/otel/metrics/data-model/)
- [Temporality](https://opentelemetry.io/docs/specs/otel/metrics/data-model/#temporality)

### Go å®ç°5

- [go.opentelemetry.io/otel/sdk/metric](https://pkg.go.dev/go.opentelemetry.io/otel/sdk/metric)

### ç›¸å…³æ–‡æ¡£

- [01_Metricç±»å‹.md](./01_Metricç±»å‹.md)
- [02_æ•°æ®ç‚¹.md](./02_æ•°æ®ç‚¹.md)
- [04_æ ‡ç­¾.md](./04_æ ‡ç­¾.md)

---

**ğŸ‰ æ­å–œï¼ä½ å·²ç»æŒæ¡äº†æ—¶é—´åºåˆ—çš„å®Œæ•´çŸ¥è¯†ï¼**

ä¸‹ä¸€æ­¥ï¼šå­¦ä¹  [æ ‡ç­¾](./04_æ ‡ç­¾.md) äº†è§£ Attributes å’Œ Exemplarsã€‚

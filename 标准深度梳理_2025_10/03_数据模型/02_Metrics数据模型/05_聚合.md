# 聚合完整指南

## 📋 目录

- [聚合完整指南](#聚合完整指南)
  - [📋 目录](#-目录)
  - [概述](#概述)
    - [核心概念](#核心概念)
    - [聚合流程](#聚合流程)
  - [Sum (求和聚合)](#sum-求和聚合)
    - [定义](#定义)
    - [适用场景](#适用场景)
    - [Temporality 支持](#temporality-支持)
    - [Go 实现](#go-实现)
  - [LastValue (最新值聚合)](#lastvalue-最新值聚合)
    - [定义2](#定义2)
    - [适用场景2](#适用场景2)
    - [时间戳处理](#时间戳处理)
    - [Go 实现2](#go-实现2)
  - [Histogram (直方图聚合)](#histogram-直方图聚合)
    - [定义3](#定义3)
    - [桶边界配置](#桶边界配置)
    - [统计计算](#统计计算)
    - [Go 实现3](#go-实现3)
  - [ExponentialHistogram (指数直方图聚合)](#exponentialhistogram-指数直方图聚合)
    - [定义4](#定义4)
    - [Scale 参数](#scale-参数)
    - [桶索引计算](#桶索引计算)
    - [Go 实现4](#go-实现4)
  - [聚合配置](#聚合配置)
    - [View 机制](#view-机制)
    - [聚合选择器](#聚合选择器)
    - [自定义聚合](#自定义聚合)
    - [Go 实现5](#go-实现5)
  - [多维聚合](#多维聚合)
    - [按属性聚合](#按属性聚合)
    - [聚合树](#聚合树)
    - [动态聚合](#动态聚合)
    - [Go 实现6](#go-实现6)
  - [预聚合](#预聚合)
    - [什么是预聚合](#什么是预聚合)
    - [预聚合策略](#预聚合策略)
    - [Go 实现7](#go-实现7)
  - [聚合合并](#聚合合并)
    - [Sum 合并](#sum-合并)
    - [Histogram 合并](#histogram-合并)
    - [ExponentialHistogram 合并](#exponentialhistogram-合并)
    - [Go 实现8](#go-实现8)
  - [性能优化](#性能优化)
    - [1. 并发聚合](#1-并发聚合)
    - [2. 增量聚合](#2-增量聚合)
    - [3. 内存优化](#3-内存优化)
  - [完整实现](#完整实现)
    - [聚合管理系统](#聚合管理系统)
  - [最佳实践](#最佳实践)
    - [1. 选择合适的聚合类型](#1-选择合适的聚合类型)
    - [2. 合理配置 Histogram 桶](#2-合理配置-histogram-桶)
    - [3. 控制聚合粒度](#3-控制聚合粒度)
    - [4. 预聚合热数据](#4-预聚合热数据)
  - [常见问题](#常见问题)
    - [Q1: Sum 和 LastValue 如何选择？](#q1-sum-和-lastvalue-如何选择)
    - [Q2: Histogram 和 ExponentialHistogram 如何选择？](#q2-histogram-和-exponentialhistogram-如何选择)
    - [Q3: 如何优化 Histogram 性能？](#q3-如何优化-histogram-性能)
    - [Q4: 聚合数据如何持久化？](#q4-聚合数据如何持久化)
    - [Q5: 如何处理聚合数据的过期？](#q5-如何处理聚合数据的过期)
  - [参考资源](#参考资源)
    - [官方文档](#官方文档)
    - [Go 实现9](#go-实现9)
    - [相关文档](#相关文档)

---

## 概述

**聚合 (Aggregation)** 是将多个观测值组合成单个数据点的过程，是 Metrics 系统的核心功能。

### 核心概念

- ✅ **Sum**: 累加所有观测值
- ✅ **LastValue**: 保留最新的观测值
- ✅ **Histogram**: 统计值的分布
- ✅ **ExponentialHistogram**: 自适应的分布统计

### 聚合流程

```text
┌──────────────┐
│ 观测值记录    │
│ counter.Add() │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 聚合处理     │
│ Sum/Histogram │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 生成数据点   │
│ DataPoint     │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 导出         │
│ Exporter     │
└──────────────┘
```

---

## Sum (求和聚合)

### 定义

**Sum** 聚合将所有观测值累加，用于 Counter 和 UpDownCounter。

### 适用场景

```text
✅ Counter:
- HTTP 请求总数
- 错误总数
- 处理的字节数

✅ UpDownCounter:
- 活动连接数
- 队列长度
- 缓存条目数
```

### Temporality 支持

```text
Cumulative (累积):
T0: sum = 10  (从启动累积)
T1: sum = 25  (从启动累积)
T2: sum = 42  (从启动累积)

Delta (增量):
T0→T1: sum = 10  (时间段增量)
T1→T2: sum = 15  (时间段增量)
T2→T3: sum = 17  (时间段增量)
```

### Go 实现

```go
package aggregation

import (
    "sync/atomic"
    "time"
    
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/sdk/metric/metricdata"
)

// Sum 聚合器
type SumAggregation struct {
    value       int64
    startTime   time.Time
    endTime     time.Time
    temporality metricdata.Temporality
    mu          sync.RWMutex
}

func NewSumAggregation(temporality metricdata.Temporality) *SumAggregation {
    return &SumAggregation{
        value:       0,
        startTime:   time.Now(),
        temporality: temporality,
    }
}

// 记录观测值
func (sa *SumAggregation) Record(value int64) {
    atomic.AddInt64(&sa.value, value)
    sa.mu.Lock()
    sa.endTime = time.Now()
    sa.mu.Unlock()
}

// 导出数据点
func (sa *SumAggregation) Export() metricdata.DataPoint[int64] {
    sa.mu.RLock()
    value := atomic.LoadInt64(&sa.value)
    startTime := sa.startTime
    endTime := sa.endTime
    sa.mu.RUnlock()
    
    dp := metricdata.DataPoint[int64]{
        Attributes: attribute.EmptySet(),
        StartTime:  startTime,
        Time:       endTime,
        Value:      value,
    }
    
    // Delta 模式：导出后重置
    if sa.temporality == metricdata.DeltaTemporality {
        sa.Reset()
    }
    
    return dp
}

// 重置 (Delta 模式)
func (sa *SumAggregation) Reset() {
    sa.mu.Lock()
    defer sa.mu.Unlock()
    
    atomic.StoreInt64(&sa.value, 0)
    sa.startTime = sa.endTime
}

// Float64 版本
type Float64SumAggregation struct {
    value       uint64  // 存储 float64 的位模式
    startTime   time.Time
    endTime     time.Time
    temporality metricdata.Temporality
    mu          sync.RWMutex
}

func NewFloat64SumAggregation(temporality metricdata.Temporality) *Float64SumAggregation {
    return &Float64SumAggregation{
        startTime:   time.Now(),
        temporality: temporality,
    }
}

func (fsa *Float64SumAggregation) Record(value float64) {
    import "math"
    
    for {
        old := atomic.LoadUint64(&fsa.value)
        oldFloat := math.Float64frombits(old)
        newFloat := oldFloat + value
        new := math.Float64bits(newFloat)
        
        if atomic.CompareAndSwapUint64(&fsa.value, old, new) {
            break
        }
    }
    
    fsa.mu.Lock()
    fsa.endTime = time.Now()
    fsa.mu.Unlock()
}

func (fsa *Float64SumAggregation) Export() metricdata.DataPoint[float64] {
    import "math"
    
    fsa.mu.RLock()
    valueBits := atomic.LoadUint64(&fsa.value)
    value := math.Float64frombits(valueBits)
    startTime := fsa.startTime
    endTime := fsa.endTime
    fsa.mu.RUnlock()
    
    dp := metricdata.DataPoint[float64]{
        Attributes: attribute.EmptySet(),
        StartTime:  startTime,
        Time:       endTime,
        Value:      value,
    }
    
    if fsa.temporality == metricdata.DeltaTemporality {
        fsa.Reset()
    }
    
    return dp
}

func (fsa *Float64SumAggregation) Reset() {
    fsa.mu.Lock()
    defer fsa.mu.Unlock()
    
    atomic.StoreUint64(&fsa.value, 0)
    fsa.startTime = fsa.endTime
}
```

---

## LastValue (最新值聚合)

### 定义2

**LastValue** 聚合保留最新的观测值，用于 Gauge。

### 适用场景2

```text
✅ 适用场景:
- 内存使用量
- CPU 使用率
- 温度
- 当前队列长度
- Goroutine 数量
```

### 时间戳处理

```text
采用最新值的时间戳:

T0: value = 100, timestamp = T0
T1: value = 150, timestamp = T1  ← 保留
T2: value = 120, timestamp = T2  ← 保留 (最新)

导出: value = 120, timestamp = T2
```

### Go 实现2

```go
// LastValue 聚合器
type LastValueAggregation struct {
    value     float64
    timestamp time.Time
    mu        sync.RWMutex
}

func NewLastValueAggregation() *LastValueAggregation {
    return &LastValueAggregation{
        timestamp: time.Now(),
    }
}

// 记录观测值
func (lva *LastValueAggregation) Record(value float64) {
    lva.RecordWithTimestamp(value, time.Now())
}

// 记录观测值（带时间戳）
func (lva *LastValueAggregation) RecordWithTimestamp(
    value float64,
    timestamp time.Time,
) {
    lva.mu.Lock()
    defer lva.mu.Unlock()
    
    // 仅保留更新的值
    if timestamp.After(lva.timestamp) {
        lva.value = value
        lva.timestamp = timestamp
    }
}

// 导出数据点
func (lva *LastValueAggregation) Export() metricdata.DataPoint[float64] {
    lva.mu.RLock()
    defer lva.mu.RUnlock()
    
    return metricdata.DataPoint[float64]{
        Attributes: attribute.EmptySet(),
        Time:       lva.timestamp,
        Value:      lva.value,
    }
}

// 异步 Gauge 实现
type AsynchronousGauge struct {
    callback func() float64
    lastValue *LastValueAggregation
}

func NewAsynchronousGauge(callback func() float64) *AsynchronousGauge {
    return &AsynchronousGauge{
        callback:  callback,
        lastValue: NewLastValueAggregation(),
    }
}

// 采集
func (ag *AsynchronousGauge) Collect() {
    value := ag.callback()
    ag.lastValue.Record(value)
}

// 导出
func (ag *AsynchronousGauge) Export() metricdata.DataPoint[float64] {
    return ag.lastValue.Export()
}

// 示例：监控内存使用
func monitorMemoryUsage() *AsynchronousGauge {
    return NewAsynchronousGauge(func() float64 {
        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        return float64(m.Alloc)
    })
}
```

---

## Histogram (直方图聚合)

### 定义3

**Histogram** 聚合统计值的分布，将观测值分配到预定义的桶中。

### 桶边界配置

```go
// 常用桶边界配置
var (
    // HTTP 延迟 (秒)
    HTTPLatencyBounds = []float64{
        0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10,
    }
    
    // 响应大小 (字节)
    ResponseSizeBounds = []float64{
        100, 1000, 10000, 100000, 1000000, 10000000,
    }
    
    // 数据库查询延迟 (秒)
    DBQueryBounds = []float64{
        0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5,
    }
    
    // 默认桶 (指数增长)
    DefaultBounds = []float64{
        0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75,
        1, 2.5, 5, 7.5, 10,
    }
)

// 生成指数桶
func generateExponentialBounds(start, factor float64, count int) []float64 {
    bounds := make([]float64, count)
    current := start
    for i := 0; i < count; i++ {
        bounds[i] = current
        current *= factor
    }
    return bounds
}

// 示例：生成 10 个桶，从 0.01 开始，每次翻倍
// bounds := generateExponentialBounds(0.01, 2.0, 10)
// [0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1.28, 2.56, 5.12]
```

### 统计计算

```text
统计指标:
- Count: 观测值总数
- Sum: 观测值总和
- Min: 最小值
- Max: 最大值
- Bucket Counts: 各桶计数
- Percentiles: 百分位数 (P50, P95, P99)

计算百分位数:
P50 (中位数): 50% 的值 ≤ P50
P95: 95% 的值 ≤ P95
P99: 99% 的值 ≤ P99
```

### Go 实现3

```go
// Histogram 聚合器
type HistogramAggregation struct {
    bounds       []float64
    counts       []uint64
    sum          float64
    count        uint64
    min          float64
    max          float64
    startTime    time.Time
    endTime      time.Time
    temporality  metricdata.Temporality
    mu           sync.RWMutex
}

func NewHistogramAggregation(
    bounds []float64,
    temporality metricdata.Temporality,
) *HistogramAggregation {
    return &HistogramAggregation{
        bounds:      bounds,
        counts:      make([]uint64, len(bounds)+1),
        min:         math.Inf(1),
        max:         math.Inf(-1),
        startTime:   time.Now(),
        temporality: temporality,
    }
}

// 记录观测值
func (ha *HistogramAggregation) Record(value float64) {
    ha.mu.Lock()
    defer ha.mu.Unlock()
    
    ha.count++
    ha.sum += value
    ha.endTime = time.Now()
    
    if value < ha.min {
        ha.min = value
    }
    if value > ha.max {
        ha.max = value
    }
    
    // 找到对应的桶
    bucketIdx := ha.findBucket(value)
    ha.counts[bucketIdx]++
}

// 查找桶索引
func (ha *HistogramAggregation) findBucket(value float64) int {
    // 二分查找
    left, right := 0, len(ha.bounds)
    for left < right {
        mid := (left + right) / 2
        if value <= ha.bounds[mid] {
            right = mid
        } else {
            left = mid + 1
        }
    }
    return left
}

// 导出数据点
func (ha *HistogramAggregation) Export() metricdata.HistogramDataPoint[float64] {
    ha.mu.RLock()
    defer ha.mu.RUnlock()
    
    // 复制数据
    counts := make([]uint64, len(ha.counts))
    copy(counts, ha.counts)
    
    dp := metricdata.HistogramDataPoint[float64]{
        Attributes:     attribute.EmptySet(),
        StartTime:      ha.startTime,
        Time:           ha.endTime,
        Count:          ha.count,
        Sum:            ha.sum,
        Min:            metricdata.NewExtrema(ha.min),
        Max:            metricdata.NewExtrema(ha.max),
        BucketCounts:   counts,
        Bounds:         ha.bounds,
    }
    
    return dp
}

// 重置 (Delta 模式)
func (ha *HistogramAggregation) Reset() {
    ha.mu.Lock()
    defer ha.mu.Unlock()
    
    ha.count = 0
    ha.sum = 0
    ha.min = math.Inf(1)
    ha.max = math.Inf(-1)
    ha.startTime = ha.endTime
    
    for i := range ha.counts {
        ha.counts[i] = 0
    }
}

// 计算百分位数
func (ha *HistogramAggregation) Percentile(p float64) float64 {
    ha.mu.RLock()
    defer ha.mu.RUnlock()
    
    if ha.count == 0 {
        return 0
    }
    
    targetCount := uint64(float64(ha.count) * p)
    var cumCount uint64
    
    for i, count := range ha.counts {
        cumCount += count
        if cumCount >= targetCount {
            if i == 0 {
                return ha.min
            }
            if i >= len(ha.bounds) {
                return ha.max
            }
            return ha.bounds[i]
        }
    }
    
    return ha.max
}

// 使用示例
func exampleHistogramUsage() {
    histogram := NewHistogramAggregation(
        HTTPLatencyBounds,
        metricdata.CumulativeTemporality,
    )
    
    // 记录观测值
    histogram.Record(0.012)  // 12ms
    histogram.Record(0.125)  // 125ms
    histogram.Record(1.5)    // 1.5s
    
    // 导出
    dp := histogram.Export()
    fmt.Printf("Count: %d, Sum: %.3f, Min: %.3f, Max: %.3f\n",
        dp.Count, dp.Sum, dp.Min.Value(), dp.Max.Value())
    
    // 计算百分位数
    p50 := histogram.Percentile(0.50)
    p95 := histogram.Percentile(0.95)
    p99 := histogram.Percentile(0.99)
    
    fmt.Printf("P50: %.3f, P95: %.3f, P99: %.3f\n", p50, p95, p99)
}
```

---

## ExponentialHistogram (指数直方图聚合)

### 定义4

**ExponentialHistogram** 使用指数增长的桶边界，自动适应值的范围。

### Scale 参数

```text
Scale 控制桶的精度:

Scale = 0:  base = 2^(2^0) = 2
  Buckets: (1,2], (2,4], (4,8], (8,16], ...

Scale = 1:  base = 2^(2^-1) = √2 ≈ 1.414
  更细的粒度

Scale = -1: base = 2^(2^1) = 4
  更粗的粒度

Scale 越大，精度越高，但桶数量越多
```

### 桶索引计算

```go
// 计算桶索引
func calculateBucketIndex(value float64, scale int32) int32 {
    if value == 0 {
        return 0
    }
    
    import "math"
    
    // base = 2^(2^-scale)
    // index = floor(log(value) / log(base))
    
    logBase := math.Pow(2, float64(-scale))
    return int32(math.Floor(math.Log(math.Abs(value)) * logBase))
}

// 示例
func exampleBucketIndex() {
    // Scale = 0
    fmt.Println(calculateBucketIndex(1.5, 0))   // 0: (1, 2]
    fmt.Println(calculateBucketIndex(3.0, 0))   // 1: (2, 4]
    fmt.Println(calculateBucketIndex(6.0, 0))   // 2: (4, 8]
    
    // Scale = 1
    fmt.Println(calculateBucketIndex(1.3, 1))   // 0: (1, √2]
    fmt.Println(calculateBucketIndex(1.5, 1))   // 1: (√2, 2]
}
```

### Go 实现4

```go
// ExponentialHistogram 聚合器
type ExponentialHistogramAggregation struct {
    scale         int32
    zeroCount     uint64
    positiveBuckets map[int32]uint64
    negativeBuckets map[int32]uint64
    sum           float64
    count         uint64
    min           float64
    max           float64
    startTime     time.Time
    endTime       time.Time
    temporality   metricdata.Temporality
    mu            sync.RWMutex
}

func NewExponentialHistogramAggregation(
    scale int32,
    temporality metricdata.Temporality,
) *ExponentialHistogramAggregation {
    return &ExponentialHistogramAggregation{
        scale:           scale,
        positiveBuckets: make(map[int32]uint64),
        negativeBuckets: make(map[int32]uint64),
        min:             math.Inf(1),
        max:             math.Inf(-1),
        startTime:       time.Now(),
        temporality:     temporality,
    }
}

// 记录观测值
func (eha *ExponentialHistogramAggregation) Record(value float64) {
    eha.mu.Lock()
    defer eha.mu.Unlock()
    
    eha.count++
    eha.sum += value
    eha.endTime = time.Now()
    
    if value < eha.min {
        eha.min = value
    }
    if value > eha.max {
        eha.max = value
    }
    
    // 处理零值
    if value == 0 {
        eha.zeroCount++
        return
    }
    
    // 计算桶索引
    idx := eha.bucketIndex(value)
    
    // 分正负值
    if value > 0 {
        eha.positiveBuckets[idx]++
    } else {
        eha.negativeBuckets[idx]++
    }
}

// 计算桶索引
func (eha *ExponentialHistogramAggregation) bucketIndex(value float64) int32 {
    import "math"
    
    if value == 0 {
        return 0
    }
    
    logBase := math.Pow(2, float64(-eha.scale))
    return int32(math.Floor(math.Log(math.Abs(value)) * logBase))
}

// 导出数据点
func (eha *ExponentialHistogramAggregation) Export() metricdata.ExponentialHistogramDataPoint[float64] {
    eha.mu.RLock()
    defer eha.mu.RUnlock()
    
    // 转换为有序桶
    positive := eha.convertToOrderedBuckets(eha.positiveBuckets)
    negative := eha.convertToOrderedBuckets(eha.negativeBuckets)
    
    dp := metricdata.ExponentialHistogramDataPoint[float64]{
        Attributes: attribute.EmptySet(),
        StartTime:  eha.startTime,
        Time:       eha.endTime,
        Count:      eha.count,
        Sum:        eha.sum,
        Min:        metricdata.NewExtrema(eha.min),
        Max:        metricdata.NewExtrema(eha.max),
        Scale:      eha.scale,
        ZeroCount:  eha.zeroCount,
        PositiveBucket: positive,
        NegativeBucket: negative,
    }
    
    return dp
}

// 转换为有序桶
func (eha *ExponentialHistogramAggregation) convertToOrderedBuckets(
    buckets map[int32]uint64,
) metricdata.ExponentialBucket {
    if len(buckets) == 0 {
        return metricdata.ExponentialBucket{}
    }
    
    // 找到最小和最大索引
    var minIdx, maxIdx int32
    first := true
    for idx := range buckets {
        if first {
            minIdx, maxIdx = idx, idx
            first = false
        } else {
            if idx < minIdx {
                minIdx = idx
            }
            if idx > maxIdx {
                maxIdx = idx
            }
        }
    }
    
    // 创建连续数组
    size := int(maxIdx - minIdx + 1)
    counts := make([]uint64, size)
    
    for idx, count := range buckets {
        counts[idx-minIdx] = count
    }
    
    return metricdata.ExponentialBucket{
        Offset:       minIdx,
        Counts:       counts,
    }
}

// 重置
func (eha *ExponentialHistogramAggregation) Reset() {
    eha.mu.Lock()
    defer eha.mu.Unlock()
    
    eha.count = 0
    eha.sum = 0
    eha.zeroCount = 0
    eha.min = math.Inf(1)
    eha.max = math.Inf(-1)
    eha.startTime = eha.endTime
    eha.positiveBuckets = make(map[int32]uint64)
    eha.negativeBuckets = make(map[int32]uint64)
}
```

---

## 聚合配置

### View 机制

```go
import (
    "go.opentelemetry.io/otel/sdk/metric"
)

// View 允许自定义聚合行为
func setupViews() []metric.View {
    return []metric.View{
        // 1. 修改 Histogram 桶
        metric.NewView(
            metric.Instrument{
                Name: "http.server.request.duration",
            },
            metric.Stream{
                Aggregation: metric.AggregationExplicitBucketHistogram{
                    Boundaries: []float64{0.01, 0.1, 0.5, 1, 5},
                },
            },
        ),
        
        // 2. 将 Histogram 改为 ExponentialHistogram
        metric.NewView(
            metric.Instrument{
                Name: "http.client.request.duration",
            },
            metric.Stream{
                Aggregation: metric.AggregationBase2ExponentialHistogram{
                    MaxSize:  160,
                    MaxScale: 20,
                },
            },
        ),
        
        // 3. 过滤属性
        metric.NewView(
            metric.Instrument{
                Name: "http.server.request.count",
            },
            metric.Stream{
                AttributeFilter: attribute.NewSet(
                    attribute.String("http.method", ""),
                    attribute.String("http.route", ""),
                ),
            },
        ),
    }
}
```

### 聚合选择器

```go
// 自定义聚合选择器
type CustomAggregationSelector struct{}

func (cas *CustomAggregationSelector) AggregationFor(
    kind metric.InstrumentKind,
) metric.Aggregation {
    switch kind {
    case metric.InstrumentKindCounter:
        return metric.AggregationSum{}
        
    case metric.InstrumentKindUpDownCounter:
        return metric.AggregationSum{}
        
    case metric.InstrumentKindHistogram:
        // 使用 ExponentialHistogram
        return metric.AggregationBase2ExponentialHistogram{
            MaxSize:  160,
            MaxScale: 20,
        }
        
    case metric.InstrumentKindObservableGauge:
        return metric.AggregationLastValue{}
        
    default:
        return metric.AggregationDefault{}
    }
}
```

### 自定义聚合

```go
// 实现自定义聚合
type MinMaxAggregation struct {
    min float64
    max float64
    mu  sync.RWMutex
}

func NewMinMaxAggregation() *MinMaxAggregation {
    return &MinMaxAggregation{
        min: math.Inf(1),
        max: math.Inf(-1),
    }
}

func (mma *MinMaxAggregation) Record(value float64) {
    mma.mu.Lock()
    defer mma.mu.Unlock()
    
    if value < mma.min {
        mma.min = value
    }
    if value > mma.max {
        mma.max = value
    }
}

func (mma *MinMaxAggregation) Export() (min, max float64) {
    mma.mu.RLock()
    defer mma.mu.RUnlock()
    return mma.min, mma.max
}
```

### Go 实现5

```go
// 聚合工厂
type AggregationFactory struct {
    temporality metricdata.Temporality
}

func NewAggregationFactory(
    temporality metricdata.Temporality,
) *AggregationFactory {
    return &AggregationFactory{
        temporality: temporality,
    }
}

// 创建聚合器
func (af *AggregationFactory) Create(
    kind metric.InstrumentKind,
    config interface{},
) interface{} {
    switch kind {
    case metric.InstrumentKindCounter:
        return NewSumAggregation(af.temporality)
        
    case metric.InstrumentKindUpDownCounter:
        return NewSumAggregation(af.temporality)
        
    case metric.InstrumentKindHistogram:
        if cfg, ok := config.(HistogramConfig); ok {
            return NewHistogramAggregation(cfg.Bounds, af.temporality)
        }
        return NewHistogramAggregation(DefaultBounds, af.temporality)
        
    case metric.InstrumentKindObservableGauge:
        return NewLastValueAggregation()
        
    default:
        return nil
    }
}

type HistogramConfig struct {
    Bounds []float64
}
```

---

## 多维聚合

### 按属性聚合

```go
// 多维聚合器
type MultiDimensionalAggregator struct {
    aggregations map[string]*HistogramAggregation
    bounds       []float64
    temporality  metricdata.Temporality
    mu           sync.RWMutex
}

func NewMultiDimensionalAggregator(
    bounds []float64,
    temporality metricdata.Temporality,
) *MultiDimensionalAggregator {
    return &MultiDimensionalAggregator{
        aggregations: make(map[string]*HistogramAggregation),
        bounds:       bounds,
        temporality:  temporality,
    }
}

// 记录观测值（带属性）
func (mda *MultiDimensionalAggregator) Record(
    value float64,
    attrs []attribute.KeyValue,
) {
    key := mda.makeKey(attrs)
    
    mda.mu.RLock()
    agg, exists := mda.aggregations[key]
    mda.mu.RUnlock()
    
    if !exists {
        mda.mu.Lock()
        // Double-check
        agg, exists = mda.aggregations[key]
        if !exists {
            agg = NewHistogramAggregation(mda.bounds, mda.temporality)
            mda.aggregations[key] = agg
        }
        mda.mu.Unlock()
    }
    
    agg.Record(value)
}

// 生成聚合键
func (mda *MultiDimensionalAggregator) makeKey(
    attrs []attribute.KeyValue,
) string {
    import "sort"
    import "strings"
    
    pairs := make([]string, len(attrs))
    for i, attr := range attrs {
        pairs[i] = fmt.Sprintf("%s=%v", attr.Key, attr.Value)
    }
    sort.Strings(pairs)
    return strings.Join(pairs, "|")
}

// 导出所有聚合
func (mda *MultiDimensionalAggregator) ExportAll() map[string]metricdata.HistogramDataPoint[float64] {
    mda.mu.RLock()
    defer mda.mu.RUnlock()
    
    result := make(map[string]metricdata.HistogramDataPoint[float64])
    for key, agg := range mda.aggregations {
        result[key] = agg.Export()
    }
    
    return result
}
```

### 聚合树

```go
// 聚合树节点
type AggregationTreeNode struct {
    dimension string
    children  map[string]*AggregationTreeNode
    aggregation *HistogramAggregation
    mu        sync.RWMutex
}

func NewAggregationTreeNode(dimension string) *AggregationTreeNode {
    return &AggregationTreeNode{
        dimension: dimension,
        children:  make(map[string]*AggregationTreeNode),
    }
}

// 记录观测值
func (atn *AggregationTreeNode) Record(
    value float64,
    dims map[string]string,
    remainingDims []string,
) {
    if len(remainingDims) == 0 {
        if atn.aggregation == nil {
            atn.aggregation = NewHistogramAggregation(
                DefaultBounds,
                metricdata.CumulativeTemporality,
            )
        }
        atn.aggregation.Record(value)
        return
    }
    
    nextDim := remainingDims[0]
    value := dims[nextDim]
    
    atn.mu.RLock()
    child, exists := atn.children[dimValue]
    atn.mu.RUnlock()
    
    if !exists {
        atn.mu.Lock()
        child, exists = atn.children[dimValue]
        if !exists {
            child = NewAggregationTreeNode(nextDim)
            atn.children[dimValue] = child
        }
        atn.mu.Unlock()
    }
    
    child.Record(value, dims, remainingDims[1:])
}
```

### 动态聚合

```go
// 动态聚合管理器
type DynamicAggregationManager struct {
    factory      *AggregationFactory
    aggregations sync.Map  // map[string]interface{}
}

func NewDynamicAggregationManager(
    factory *AggregationFactory,
) *DynamicAggregationManager {
    return &DynamicAggregationManager{
        factory: factory,
    }
}

// 获取或创建聚合器
func (dam *DynamicAggregationManager) GetOrCreate(
    name string,
    kind metric.InstrumentKind,
    attrs []attribute.KeyValue,
) interface{} {
    key := makeAggregationKey(name, attrs)
    
    if agg, ok := dam.aggregations.Load(key); ok {
        return agg
    }
    
    agg := dam.factory.Create(kind, nil)
    dam.aggregations.Store(key, agg)
    return agg
}

func makeAggregationKey(name string, attrs []attribute.KeyValue) string {
    import "sort"
    
    pairs := make([]string, len(attrs))
    for i, attr := range attrs {
        pairs[i] = fmt.Sprintf("%s=%v", attr.Key, attr.Value)
    }
    sort.Strings(pairs)
    
    return name + "|" + strings.Join(pairs, "|")
}
```

### Go 实现6

```go
// 完整的多维聚合系统
type MultiDimensionalSystem struct {
    manager *DynamicAggregationManager
    limiter *CardinalityLimiter
}

type CardinalityLimiter struct {
    maxCardinality int
    currentCount   int
    mu             sync.Mutex
}

func NewCardinalityLimiter(maxCardinality int) *CardinalityLimiter {
    return &CardinalityLimiter{
        maxCardinality: maxCardinality,
    }
}

func (cl *CardinalityLimiter) CheckAndIncrement() error {
    cl.mu.Lock()
    defer cl.mu.Unlock()
    
    if cl.currentCount >= cl.maxCardinality {
        return fmt.Errorf("cardinality limit exceeded: %d", cl.maxCardinality)
    }
    
    cl.currentCount++
    return nil
}
```

---

## 预聚合

### 什么是预聚合

**预聚合** 是在数据写入前进行聚合，减少存储和查询开销。

```text
无预聚合:
原始数据 → 存储 → 查询时聚合

有预聚合:
原始数据 → 预聚合 → 存储 → 查询（已聚合）
```

### 预聚合策略

```go
// 预聚合器
type PreAggregator struct {
    interval    time.Duration
    aggregations map[string]*HistogramAggregation
    mu          sync.RWMutex
    ticker      *time.Ticker
    done        chan struct{}
}

func NewPreAggregator(interval time.Duration) *PreAggregator {
    pa := &PreAggregator{
        interval:     interval,
        aggregations: make(map[string]*HistogramAggregation),
        ticker:       time.NewTicker(interval),
        done:         make(chan struct{}),
    }
    
    go pa.run()
    return pa
}

// 记录观测值
func (pa *PreAggregator) Record(
    key string,
    value float64,
) {
    pa.mu.RLock()
    agg, exists := pa.aggregations[key]
    pa.mu.RUnlock()
    
    if !exists {
        pa.mu.Lock()
        agg, exists = pa.aggregations[key]
        if !exists {
            agg = NewHistogramAggregation(
                DefaultBounds,
                metricdata.DeltaTemporality,
            )
            pa.aggregations[key] = agg
        }
        pa.mu.Unlock()
    }
    
    agg.Record(value)
}

// 定期导出
func (pa *PreAggregator) run() {
    for {
        select {
        case <-pa.ticker.C:
            pa.flush()
        case <-pa.done:
            return
        }
    }
}

// 刷新数据
func (pa *PreAggregator) flush() {
    pa.mu.Lock()
    defer pa.mu.Unlock()
    
    for key, agg := range pa.aggregations {
        dp := agg.Export()
        // 发送到存储
        sendToStorage(key, dp)
    }
}

func (pa *PreAggregator) Stop() {
    close(pa.done)
    pa.ticker.Stop()
}
```

### Go 实现7

```go
// 分层预聚合
type TieredPreAggregator struct {
    realtime *PreAggregator  // 实时 (1s)
    minute   *PreAggregator  // 分钟 (60s)
    hour     *PreAggregator  // 小时 (3600s)
}

func NewTieredPreAggregator() *TieredPreAggregator {
    return &TieredPreAggregator{
        realtime: NewPreAggregator(1 * time.Second),
        minute:   NewPreAggregator(60 * time.Second),
        hour:     NewPreAggregator(3600 * time.Second),
    }
}

func (tpa *TieredPreAggregator) Record(key string, value float64) {
    tpa.realtime.Record(key, value)
    tpa.minute.Record(key, value)
    tpa.hour.Record(key, value)
}

func (tpa *TieredPreAggregator) Stop() {
    tpa.realtime.Stop()
    tpa.minute.Stop()
    tpa.hour.Stop()
}
```

---

## 聚合合并

### Sum 合并

```go
// Sum 聚合合并
func mergeSumAggregations(aggs []*SumAggregation) *SumAggregation {
    if len(aggs) == 0 {
        return NewSumAggregation(metricdata.CumulativeTemporality)
    }
    
    result := NewSumAggregation(aggs[0].temporality)
    
    for _, agg := range aggs {
        dp := agg.Export()
        result.value += dp.Value
    }
    
    return result
}
```

### Histogram 合并

```go
// Histogram 聚合合并
func mergeHistogramAggregations(
    aggs []*HistogramAggregation,
) *HistogramAggregation {
    if len(aggs) == 0 {
        return nil
    }
    
    // 确保所有 Histogram 使用相同的桶
    bounds := aggs[0].bounds
    result := NewHistogramAggregation(bounds, aggs[0].temporality)
    
    for _, agg := range aggs {
        dp := agg.Export()
        
        result.count += dp.Count
        result.sum += dp.Sum
        
        if dp.Min.Value() < result.min {
            result.min = dp.Min.Value()
        }
        if dp.Max.Value() > result.max {
            result.max = dp.Max.Value()
        }
        
        for i, count := range dp.BucketCounts {
            result.counts[i] += count
        }
    }
    
    return result
}
```

### ExponentialHistogram 合并

```go
// ExponentialHistogram 聚合合并（复杂）
func mergeExponentialHistogramAggregations(
    aggs []*ExponentialHistogramAggregation,
) *ExponentialHistogramAggregation {
    if len(aggs) == 0 {
        return nil
    }
    
    // 选择最小的 scale
    minScale := aggs[0].scale
    for _, agg := range aggs[1:] {
        if agg.scale < minScale {
            minScale = agg.scale
        }
    }
    
    result := NewExponentialHistogramAggregation(
        minScale,
        aggs[0].temporality,
    )
    
    for _, agg := range aggs {
        dp := agg.Export()
        
        result.count += dp.Count
        result.sum += dp.Sum
        result.zeroCount += dp.ZeroCount
        
        // 合并正值桶
        for idx, count := range dp.PositiveBucket.Counts {
            adjustedIdx := adjustIndex(
                idx, dp.PositiveBucket.Offset,
                agg.scale, minScale,
            )
            result.positiveBuckets[adjustedIdx] += count
        }
        
        // 合并负值桶
        for idx, count := range dp.NegativeBucket.Counts {
            adjustedIdx := adjustIndex(
                idx, dp.NegativeBucket.Offset,
                agg.scale, minScale,
            )
            result.negativeBuckets[adjustedIdx] += count
        }
    }
    
    return result
}

func adjustIndex(
    idx int, offset int32,
    fromScale, toScale int32,
) int32 {
    actualIdx := int32(idx) + offset
    scaleDiff := fromScale - toScale
    return actualIdx >> scaleDiff
}
```

### Go 实现8

```go
// 聚合合并器
type AggregationMerger struct{}

func (am *AggregationMerger) Merge(
    kind metric.InstrumentKind,
    aggs []interface{},
) interface{} {
    switch kind {
    case metric.InstrumentKindCounter,
         metric.InstrumentKindUpDownCounter:
        sumAggs := make([]*SumAggregation, len(aggs))
        for i, agg := range aggs {
            sumAggs[i] = agg.(*SumAggregation)
        }
        return mergeSumAggregations(sumAggs)
        
    case metric.InstrumentKindHistogram:
        histoAggs := make([]*HistogramAggregation, len(aggs))
        for i, agg := range aggs {
            histoAggs[i] = agg.(*HistogramAggregation)
        }
        return mergeHistogramAggregations(histoAggs)
        
    default:
        return nil
    }
}
```

---

## 性能优化

### 1. 并发聚合

```go
// 并发安全的聚合器
type ConcurrentHistogramAggregation struct {
    shards []*HistogramAggregation
    numShards int
}

func NewConcurrentHistogramAggregation(
    bounds []float64,
    temporality metricdata.Temporality,
    numShards int,
) *ConcurrentHistogramAggregation {
    shards := make([]*HistogramAggregation, numShards)
    for i := 0; i < numShards; i++ {
        shards[i] = NewHistogramAggregation(bounds, temporality)
    }
    
    return &ConcurrentHistogramAggregation{
        shards:    shards,
        numShards: numShards,
    }
}

// 记录观测值
func (cha *ConcurrentHistogramAggregation) Record(value float64) {
    import "hash/maphash"
    
    // 根据 goroutine ID 分片
    shardIdx := int(maphash.Bytes(maphash.MakeSeed(), 
        []byte(fmt.Sprint(getGoroutineID())))) % cha.numShards
    
    cha.shards[shardIdx].Record(value)
}

// 导出（合并所有分片）
func (cha *ConcurrentHistogramAggregation) Export() metricdata.HistogramDataPoint[float64] {
    return mergeHistogramAggregations(cha.shards).Export()
}
```

### 2. 增量聚合

```go
// 增量聚合
type IncrementalAggregation struct {
    current  *HistogramAggregation
    previous *HistogramAggregation
}

func (ia *IncrementalAggregation) Record(value float64) {
    ia.current.Record(value)
}

func (ia *IncrementalAggregation) ExportDelta() metricdata.HistogramDataPoint[float64] {
    current := ia.current.Export()
    
    if ia.previous == nil {
        ia.previous = ia.current
        ia.current = NewHistogramAggregation(
            ia.current.bounds,
            ia.current.temporality,
        )
        return current
    }
    
    previous := ia.previous.Export()
    
    // 计算增量
    delta := metricdata.HistogramDataPoint[float64]{
        Count: current.Count - previous.Count,
        Sum:   current.Sum - previous.Sum,
        // ... 其他字段
    }
    
    ia.previous = ia.current
    ia.current = NewHistogramAggregation(
        ia.current.bounds,
        ia.current.temporality,
    )
    
    return delta
}
```

### 3. 内存优化

```go
// 使用对象池
var histogramAggregationPool = sync.Pool{
    New: func() interface{} {
        return &HistogramAggregation{
            counts: make([]uint64, 20),
        }
    },
}

func acquireHistogramAggregation() *HistogramAggregation {
    return histogramAggregationPool.Get().(*HistogramAggregation)
}

func releaseHistogramAggregation(ha *HistogramAggregation) {
    ha.Reset()
    histogramAggregationPool.Put(ha)
}
```

---

## 完整实现

### 聚合管理系统

```go
package aggregation

import (
    "context"
    "sync"
    "time"
)

// AggregationManager 聚合管理器
type AggregationManager struct {
    factory     *AggregationFactory
    aggregations sync.Map
    merger      *AggregationMerger
    preAggregator *PreAggregator
    mu          sync.RWMutex
}

func NewAggregationManager(
    temporality metricdata.Temporality,
    preAggInterval time.Duration,
) *AggregationManager {
    return &AggregationManager{
        factory:       NewAggregationFactory(temporality),
        merger:        &AggregationMerger{},
        preAggregator: NewPreAggregator(preAggInterval),
    }
}

// 记录观测值
func (am *AggregationManager) Record(
    ctx context.Context,
    name string,
    kind metric.InstrumentKind,
    value float64,
    attrs []attribute.KeyValue,
) error {
    key := makeAggregationKey(name, attrs)
    
    // 获取或创建聚合器
    agg := am.getOrCreateAggregation(key, kind)
    
    // 记录值
    switch a := agg.(type) {
    case *SumAggregation:
        a.Record(int64(value))
    case *Float64SumAggregation:
        a.Record(value)
    case *LastValueAggregation:
        a.Record(value)
    case *HistogramAggregation:
        a.Record(value)
    case *ExponentialHistogramAggregation:
        a.Record(value)
    default:
        return fmt.Errorf("unknown aggregation type")
    }
    
    // 预聚合
    am.preAggregator.Record(key, value)
    
    return nil
}

// 获取或创建聚合器
func (am *AggregationManager) getOrCreateAggregation(
    key string,
    kind metric.InstrumentKind,
) interface{} {
    if agg, ok := am.aggregations.Load(key); ok {
        return agg
    }
    
    agg := am.factory.Create(kind, HistogramConfig{
        Bounds: DefaultBounds,
    })
    am.aggregations.Store(key, agg)
    return agg
}

// 导出所有聚合
func (am *AggregationManager) ExportAll() map[string]interface{} {
    result := make(map[string]interface{})
    
    am.aggregations.Range(func(key, value interface{}) bool {
        result[key.(string)] = value
        return true
    })
    
    return result
}

// 停止
func (am *AggregationManager) Stop() {
    am.preAggregator.Stop()
}
```

---

## 最佳实践

### 1. 选择合适的聚合类型

```go
// ✅ 推荐
// Counter → Sum
// Gauge → LastValue
// 延迟/大小 → Histogram

// ❌ 避免
// 不要对 Counter 使用 Histogram
// 不要对 Gauge 使用 Sum
```

### 2. 合理配置 Histogram 桶

```go
// ✅ 推荐：根据实际分布配置
// HTTP 延迟: 集中在毫秒级
bounds := []float64{0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1}

// ❌ 避免：桶过多或分布不均
bounds := []float64{0.001, 0.002, 0.003, ...} // 太多
```

### 3. 控制聚合粒度

```go
// ✅ 推荐：限制时间序列数量
maxCardinality := 10000

// ✅ 推荐：使用低基数标签
attrs := []attribute.KeyValue{
    attribute.String("http.method", "GET"),  // 低基数
    attribute.Int("http.status_code", 200),  // 低基数
}

// ❌ 避免：高基数标签
attrs := []attribute.KeyValue{
    attribute.String("user.id", userID),  // 高基数！
}
```

### 4. 预聚合热数据

```go
// ✅ 推荐：预聚合高频数据
preAggregator := NewPreAggregator(1 * time.Second)

// 热路径直接记录
preAggregator.Record("hot_metric", value)
```

---

## 常见问题

### Q1: Sum 和 LastValue 如何选择？

**A**:

- **Sum**: 累积值（Counter, UpDownCounter）
- **LastValue**: 瞬时值（Gauge）

---

### Q2: Histogram 和 ExponentialHistogram 如何选择？

**A**:

- **Histogram**: 值范围已知，需要精确控制桶
- **ExponentialHistogram**: 值范围未知，自动适应

---

### Q3: 如何优化 Histogram 性能？

**A**:

1. 减少桶数量
2. 使用并发分片
3. 预聚合
4. 对象池

---

### Q4: 聚合数据如何持久化？

**A**:

1. 定期导出到时序数据库
2. 使用预聚合减少存储
3. 分级存储（热/冷数据）

---

### Q5: 如何处理聚合数据的过期？

**A**:

1. 设置 TTL
2. 定期清理
3. LRU 淘汰策略

---

## 参考资源

### 官方文档

- [OpenTelemetry Metrics Aggregation](https://opentelemetry.io/docs/specs/otel/metrics/sdk/#aggregation)
- [Views](https://opentelemetry.io/docs/specs/otel/metrics/sdk/#view)

### Go 实现9

- [go.opentelemetry.io/otel/sdk/metric](https://pkg.go.dev/go.opentelemetry.io/otel/sdk/metric)

### 相关文档

- [01_Metric类型.md](./01_Metric类型.md)
- [02_数据点.md](./02_数据点.md)
- [03_时间序列.md](./03_时间序列.md)

---

**🎉 恭喜！你已经掌握了聚合的完整知识！**

下一步：学习 [Exemplars](./06_Exemplars.md) 了解采样数据点。

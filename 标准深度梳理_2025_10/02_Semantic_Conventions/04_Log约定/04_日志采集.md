# OTLP 日志采集与 Go 实现完整指南

## 目录

- [OTLP 日志采集与 Go 实现完整指南](#otlp-日志采集与-go-实现完整指南)
  - [目录](#目录)
  - [1. 日志采集概述](#1-日志采集概述)
    - [1.1 采集架构](#11-采集架构)
    - [1.2 采集方式](#12-采集方式)
  - [2. 文件采集](#2-文件采集)
    - [2.1 Go 文件日志写入](#21-go-文件日志写入)
    - [2.2 日志轮转配置](#22-日志轮转配置)
  - [3. OTLP 导出器](#3-otlp-导出器)
    - [3.1 gRPC 导出器](#31-grpc-导出器)
    - [3.2 HTTP 导出器](#32-http-导出器)
    - [3.3 批量处理配置](#33-批量处理配置)
  - [4. 日志解析器](#4-日志解析器)
    - [4.1 JSON 日志解析](#41-json-日志解析)
    - [4.2 结构化日志提取](#42-结构化日志提取)
  - [5. OpenTelemetry Collector](#5-opentelemetry-collector)
    - [5.1 Collector 配置](#51-collector-配置)
    - [5.2 Go Collector SDK](#52-go-collector-sdk)
  - [6. 采集最佳实践](#6-采集最佳实践)
    - [6.1 采集策略](#61-采集策略)
    - [6.2 错误处理](#62-错误处理)
  - [7. 完整示例](#7-完整示例)
    - [7.1 企业级日志采集](#71-企业级日志采集)
  - [8. 参考资料](#8-参考资料)

---

## 1. 日志采集概述

### 1.1 采集架构

```text
应用日志 → 采集器 → 处理器 → 存储/分析
   ↓
文件/标准输出 → Collector → Loki/ES → Grafana
   ↓
OTLP 直接导出 → Collector → Backend
```

### 1.2 采集方式

1. **直接导出**：应用直接通过 OTLP 发送日志
2. **文件采集**：Collector 读取日志文件
3. **代理采集**：Sidecar 模式采集容器日志
4. **标准输出采集**：Kubernetes 自动采集 stdout/stderr

---

## 2. 文件采集

### 2.1 Go 文件日志写入

```go
import (
    "log/slog"
    "os"
    "gopkg.in/natefinch/lumberjack.v2"
)

// 轮转日志文件
func NewFileLogger(filename string) *slog.Logger {
    writer := &lumberjack.Logger{
        Filename:   filename,
        MaxSize:    100, // MB
        MaxBackups: 3,
        MaxAge:     28, // days
        Compress:   true,
    }
    
    handler := slog.NewJSONHandler(writer, &slog.HandlerOptions{
        Level: slog.LevelInfo,
    })
    
    return slog.New(handler)
}

// 使用示例
func main() {
    logger := NewFileLogger("/var/log/myapp/app.log")
    
    logger.Info("Application started",
        "version", "1.0.0",
        "pid", os.Getpid(),
    )
}
```

### 2.2 日志轮转配置

```go
type LogRotationConfig struct {
    Filename   string
    MaxSize    int  // MB
    MaxBackups int
    MaxAge     int  // days
    Compress   bool
    LocalTime  bool
}

func NewRotatingLogger(config LogRotationConfig) *slog.Logger {
    writer := &lumberjack.Logger{
        Filename:   config.Filename,
        MaxSize:    config.MaxSize,
        MaxBackups: config.MaxBackups,
        MaxAge:     config.MaxAge,
        Compress:   config.Compress,
        LocalTime:  config.LocalTime,
    }
    
    handler := slog.NewJSONHandler(writer, nil)
    return slog.New(handler)
}
```

---

## 3. OTLP 导出器

### 3.1 gRPC 导出器

```go
import (
    "context"
    "go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc"
    sdklog "go.opentelemetry.io/otel/sdk/log"
)

func NewOTLPGRPCExporter(ctx context.Context, endpoint string) (*otlploggrpc.Exporter, error) {
    exporter, err := otlploggrpc.New(ctx,
        otlploggrpc.WithEndpoint(endpoint),
        otlploggrpc.WithInsecure(),
        otlploggrpc.WithCompressor("gzip"),
        otlploggrpc.WithHeaders(map[string]string{
            "x-api-key": "your-api-key",
        }),
    )
    return exporter, err
}

// 使用
func main() {
    ctx := context.Background()
    
    exporter, err := NewOTLPGRPCExporter(ctx, "localhost:4317")
    if err != nil {
        panic(err)
    }
    defer exporter.Shutdown(ctx)
    
    provider := sdklog.NewLoggerProvider(
        sdklog.WithProcessor(sdklog.NewBatchProcessor(exporter)),
    )
    defer provider.Shutdown(ctx)
}
```

### 3.2 HTTP 导出器

```go
import (
    "go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploghttp"
)

func NewOTLPHTTPExporter(ctx context.Context, endpoint string) (*otlploghttp.Exporter, error) {
    exporter, err := otlploghttp.New(ctx,
        otlploghttp.WithEndpoint(endpoint),
        otlploghttp.WithInsecure(),
        otlploghttp.WithCompression(otlploghttp.GzipCompression),
        otlploghttp.WithHeaders(map[string]string{
            "Authorization": "Bearer token",
        }),
    )
    return exporter, err
}
```

### 3.3 批量处理配置

```go
import (
    "time"
    sdklog "go.opentelemetry.io/otel/sdk/log"
)

func NewBatchProcessor(exporter sdklog.Exporter) sdklog.Processor {
    return sdklog.NewBatchProcessor(
        exporter,
        // 最大导出批次大小
        sdklog.WithExportMaxBatchSize(512),
        
        // 最大队列大小
        sdklog.WithMaxQueueSize(2048),
        
        // 导出间隔
        sdklog.WithExportInterval(5 * time.Second),
        
        // 导出超时
        sdklog.WithExportTimeout(30 * time.Second),
    )
}
```

---

## 4. 日志解析器

### 4.1 JSON 日志解析

```go
import (
    "encoding/json"
    "bufio"
    "os"
)

type LogEntry struct {
    Timestamp  string                 `json:"timestamp"`
    Level      string                 `json:"level"`
    Message    string                 `json:"message"`
    TraceID    string                 `json:"trace_id,omitempty"`
    SpanID     string                 `json:"span_id,omitempty"`
    Attributes map[string]interface{} `json:"attributes"`
}

func ParseJSONLog(filename string) ([]*LogEntry, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()
    
    var entries []*LogEntry
    scanner := bufio.NewScanner(file)
    
    for scanner.Scan() {
        var entry LogEntry
        if err := json.Unmarshal(scanner.Bytes(), &entry); err != nil {
            continue // 跳过无效行
        }
        entries = append(entries, &entry)
    }
    
    return entries, scanner.Err()
}
```

### 4.2 结构化日志提取

```go
import (
    "regexp"
    "strings"
)

// 解析各种格式的日志
type LogParser interface {
    Parse(line string) (*LogEntry, error)
}

// JSON 解析器
type JSONParser struct{}

func (p *JSONParser) Parse(line string) (*LogEntry, error) {
    var entry LogEntry
    err := json.Unmarshal([]byte(line), &entry)
    return &entry, err
}

// Logfmt 解析器
type LogfmtParser struct{}

func (p *LogfmtParser) Parse(line string) (*LogEntry, error) {
    entry := &LogEntry{
        Attributes: make(map[string]interface{}),
    }
    
    // 解析 key=value 格式
    pairs := strings.Split(line, " ")
    for _, pair := range pairs {
        parts := strings.SplitN(pair, "=", 2)
        if len(parts) == 2 {
            key := parts[0]
            value := strings.Trim(parts[1], `"`)
            
            switch key {
            case "timestamp", "time":
                entry.Timestamp = value
            case "level", "severity":
                entry.Level = value
            case "message", "msg":
                entry.Message = value
            case "trace_id":
                entry.TraceID = value
            case "span_id":
                entry.SpanID = value
            default:
                entry.Attributes[key] = value
            }
        }
    }
    
    return entry, nil
}

// 正则表达式解析器
type RegexParser struct {
    pattern *regexp.Regexp
}

func NewRegexParser(pattern string) (*RegexParser, error) {
    re, err := regexp.Compile(pattern)
    if err != nil {
        return nil, err
    }
    return &RegexParser{pattern: re}, nil
}

func (p *RegexParser) Parse(line string) (*LogEntry, error) {
    matches := p.pattern.FindStringSubmatch(line)
    if matches == nil {
        return nil, fmt.Errorf("no match")
    }
    
    // 提取命名捕获组
    entry := &LogEntry{
        Attributes: make(map[string]interface{}),
    }
    
    for i, name := range p.pattern.SubexpNames() {
        if i == 0 || name == "" {
            continue
        }
        
        switch name {
        case "timestamp":
            entry.Timestamp = matches[i]
        case "level":
            entry.Level = matches[i]
        case "message":
            entry.Message = matches[i]
        default:
            entry.Attributes[name] = matches[i]
        }
    }
    
    return entry, nil
}
```

---

## 5. OpenTelemetry Collector

### 5.1 Collector 配置

```yaml
# collector-config.yaml
receivers:
  # 文件日志接收器
  filelog:
    include:
      - /var/log/myapp/*.log
    operators:
      - type: json_parser
        timestamp:
          parse_from: attributes.timestamp
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      - type: trace_parser
        trace_id:
          parse_from: attributes.trace_id
        span_id:
          parse_from: attributes.span_id
      - type: severity_parser
        parse_from: attributes.level
        mapping:
          debug: debug
          info: info
          warn: warn
          error: error
          fatal: fatal
  
  # OTLP 接收器
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  # 批处理
  batch:
    timeout: 10s
    send_batch_size: 1024
  
  # 资源属性
  resource:
    attributes:
      - key: service.name
        value: myapp
        action: upsert
      - key: deployment.environment
        value: production
        action: insert
  
  # 属性处理
  attributes:
    actions:
      - key: sensitive_data
        action: delete

exporters:
  # 导出到 Loki
  loki:
    endpoint: http://loki:3100/loki/api/v1/push
    labels:
      resource:
        service.name: "service_name"
        deployment.environment: "env"
  
  # 导出到 Elasticsearch
  elasticsearch:
    endpoints:
      - http://elasticsearch:9200
    index: logs-%{+yyyy.MM.dd}
  
  # 日志输出（调试用）
  logging:
    loglevel: debug

service:
  pipelines:
    logs:
      receivers: [filelog, otlp]
      processors: [resource, attributes, batch]
      exporters: [loki, elasticsearch, logging]
```

### 5.2 Go Collector SDK

```go
import (
    "go.opentelemetry.io/collector/component"
    "go.opentelemetry.io/collector/consumer"
    "go.opentelemetry.io/collector/pdata/plog"
)

// 自定义 Collector 处理器
type CustomProcessor struct {
    next consumer.Logs
}

func (p *CustomProcessor) ConsumeLogs(ctx context.Context, ld plog.Logs) error {
    // 处理日志
    resourceLogs := ld.ResourceLogs()
    for i := 0; i < resourceLogs.Len(); i++ {
        resourceLog := resourceLogs.At(i)
        scopeLogs := resourceLog.ScopeLogs()
        
        for j := 0; j < scopeLogs.Len(); j++ {
            scopeLog := scopeLogs.At(j)
            logRecords := scopeLog.LogRecords()
            
            for k := 0; k < logRecords.Len(); k++ {
                logRecord := logRecords.At(k)
                
                // 添加自定义属性
                logRecord.Attributes().PutStr("processed_by", "custom_processor")
                
                // 过滤敏感信息
                if attr, ok := logRecord.Attributes().Get("password"); ok {
                    attr.SetStr("***REDACTED***")
                }
            }
        }
    }
    
    // 传递给下一个处理器
    return p.next.ConsumeLogs(ctx, ld)
}
```

---

## 6. 采集最佳实践

### 6.1 采集策略

```go
// 多目标采集配置
type CollectionConfig struct {
    // 直接 OTLP 导出
    OTLPEnabled   bool
    OTLPEndpoint  string
    
    // 文件日志
    FileEnabled   bool
    FilePath      string
    
    // 标准输出（开发环境）
    StdoutEnabled bool
}

func ConfigureLogging(config CollectionConfig) (*slog.Logger, error) {
    var writers []io.Writer
    
    // 标准输出
    if config.StdoutEnabled {
        writers = append(writers, os.Stdout)
    }
    
    // 文件
    if config.FileEnabled {
        fileWriter := &lumberjack.Logger{
            Filename:   config.FilePath,
            MaxSize:    100,
            MaxBackups: 3,
            Compress:   true,
        }
        writers = append(writers, fileWriter)
    }
    
    // OTLP（需要特殊处理）
    var handler slog.Handler
    if config.OTLPEnabled {
        otlpHandler := NewOTLPHandler(config.OTLPEndpoint)
        
        if len(writers) > 0 {
            // 多输出
            multiWriter := io.MultiWriter(writers...)
            fileHandler := slog.NewJSONHandler(multiWriter, nil)
            handler = NewMultiHandler(otlpHandler, fileHandler)
        } else {
            handler = otlpHandler
        }
    } else if len(writers) > 0 {
        multiWriter := io.MultiWriter(writers...)
        handler = slog.NewJSONHandler(multiWriter, nil)
    }
    
    return slog.New(handler), nil
}
```

### 6.2 错误处理

```go
// 可靠的日志导出器
type ReliableExporter struct {
    primary   sdklog.Exporter
    fallback  sdklog.Exporter
    failCount atomic.Int32
    threshold int32
}

func (e *ReliableExporter) Export(ctx context.Context, logs []sdklog.Record) error {
    // 尝试主导出器
    err := e.primary.Export(ctx, logs)
    if err == nil {
        e.failCount.Store(0)
        return nil
    }
    
    // 增加失败计数
    count := e.failCount.Add(1)
    
    // 超过阈值，使用备用导出器
    if count >= e.threshold {
        if e.fallback != nil {
            return e.fallback.Export(ctx, logs)
        }
    }
    
    return err
}
```

---

## 7. 完整示例

### 7.1 企业级日志采集

```go
package main

import (
    "context"
    "log/slog"
    "os"
    
    "go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc"
    sdklog "go.opentelemetry.io/otel/sdk/log"
    "gopkg.in/natefinch/lumberjack.v2"
)

func main() {
    ctx := context.Background()
    
    // 1. OTLP 导出器
    otlpExporter, err := otlploggrpc.New(ctx,
        otlploggrpc.WithEndpoint("localhost:4317"),
        otlploggrpc.WithInsecure(),
    )
    if err != nil {
        panic(err)
    }
    
    // 2. 文件日志
    fileWriter := &lumberjack.Logger{
        Filename:   "/var/log/myapp/app.log",
        MaxSize:    100,
        MaxBackups: 3,
        MaxAge:     28,
        Compress:   true,
    }
    
    // 3. 创建多输出处理器
    otlpHandler := NewOTLPHandler(otlpExporter)
    fileHandler := slog.NewJSONHandler(fileWriter, nil)
    stdoutHandler := slog.NewJSONHandler(os.Stdout, nil)
    
    multiHandler := NewMultiHandler(otlpHandler, fileHandler, stdoutHandler)
    logger := slog.New(multiHandler)
    slog.SetDefault(logger)
    
    // 4. 使用日志
    logger.Info("Application started",
        "version", "1.0.0",
        "pid", os.Getpid(),
    )
    
    // 5. 优雅关闭
    defer func() {
        provider := sdklog.NewLoggerProvider(
            sdklog.WithProcessor(sdklog.NewBatchProcessor(otlpExporter)),
        )
        provider.Shutdown(ctx)
    }()
}

// MultiHandler 多输出处理器
type MultiHandler struct {
    handlers []slog.Handler
}

func NewMultiHandler(handlers ...slog.Handler) *MultiHandler {
    return &MultiHandler{handlers: handlers}
}

func (h *MultiHandler) Enabled(ctx context.Context, level slog.Level) bool {
    for _, handler := range h.handlers {
        if handler.Enabled(ctx, level) {
            return true
        }
    }
    return false
}

func (h *MultiHandler) Handle(ctx context.Context, record slog.Record) error {
    var errs []error
    for _, handler := range h.handlers {
        if err := handler.Handle(ctx, record); err != nil {
            errs = append(errs, err)
        }
    }
    if len(errs) > 0 {
        return fmt.Errorf("multiple errors: %v", errs)
    }
    return nil
}

func (h *MultiHandler) WithAttrs(attrs []slog.Attr) slog.Handler {
    newHandlers := make([]slog.Handler, len(h.handlers))
    for i, handler := range h.handlers {
        newHandlers[i] = handler.WithAttrs(attrs)
    }
    return &MultiHandler{handlers: newHandlers}
}

func (h *MultiHandler) WithGroup(name string) slog.Handler {
    newHandlers := make([]slog.Handler, len(h.handlers))
    for i, handler := range h.handlers {
        newHandlers[i] = handler.WithGroup(name)
    }
    return &MultiHandler{handlers: newHandlers}
}
```

---

## 8. 参考资料

1. **OpenTelemetry Collector**  
   <https://opentelemetry.io/docs/collector/>

2. **Filelog Receiver**  
   <https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/filelogreceiver>

3. **Lumberjack**  
   <https://github.com/natefinch/lumberjack>

---

**文档版本**: v1.0.0  
**最后更新**: 2025-10-09  
**Go 版本**: 1.25.1  
**OpenTelemetry**: v1.32.0

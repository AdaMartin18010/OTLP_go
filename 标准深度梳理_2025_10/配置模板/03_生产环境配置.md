# OpenTelemetry ç”Ÿäº§ç¯å¢ƒé…ç½®æ¨¡æ¿

> **ç›®æ ‡**: ç”Ÿäº§çº§é«˜å¯ç”¨ã€é«˜æ€§èƒ½ã€ä½æˆæœ¬é…ç½®  
> **ç‰¹ç‚¹**: 1-10%é‡‡æ ·ã€æ‰¹å¤„ç†ä¼˜åŒ–ã€é«˜å¯ç”¨éƒ¨ç½²ã€æˆæœ¬æ§åˆ¶  
> **é€‚ç”¨åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡éƒ¨ç½²ã€æˆæœ¬æ•æ„Ÿåœºæ™¯  
> **éš¾åº¦**: â­â­â­â­ (éœ€è¦è°ƒä¼˜)

---

## å¿«é€Ÿéƒ¨ç½²

```bash
# Kubernetes éƒ¨ç½²
kubectl apply -f k8s-prod/

# éªŒè¯
kubectl get pods -n observability
kubectl logs -f deployment/otel-collector -n observability
```

---

## ç”Ÿäº§çº§ Go åº”ç”¨é…ç½®

```go:pkg/telemetry/production.go
package telemetry

import (
    "context"
    "time"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.26.0"
)

func InitProduction(ctx context.Context, serviceName string) (*sdktrace.TracerProvider, error) {
    res, err := resource.New(ctx,
        resource.WithAttributes(
            semconv.ServiceNameKey.String(serviceName),
            semconv.DeploymentEnvironmentKey.String("production"),
        ),
    )
    if err != nil {
        return nil, err
    }

    exporter, err := otlptracegrpc.New(ctx,
        otlptracegrpc.WithEndpoint("otel-collector.observability.svc.cluster.local:4317"),
        otlptracegrpc.WithInsecure(),
        otlptracegrpc.WithTimeout(5*time.Second),
    )
    if err != nil {
        return nil, err
    }

    tp := sdktrace.NewTracerProvider(
        sdktrace.WithResource(res),
        // ç”Ÿäº§ç¯å¢ƒï¼šé‡‡æ ·ä¼˜åŒ–
        sdktrace.WithSampler(sdktrace.ParentBased(
            sdktrace.TraceIDRatioBased(0.05), // 5% é‡‡æ ·
        )),
        // æ‰¹å¤„ç†ä¼˜åŒ–
        sdktrace.WithBatcher(exporter,
            sdktrace.WithBatchTimeout(10*time.Second),
            sdktrace.WithMaxExportBatchSize(512),
            sdktrace.WithMaxQueueSize(2048),
        ),
    )

    otel.SetTracerProvider(tp)
    return tp, nil
}
```

---

## Kubernetes éƒ¨ç½²

### DaemonSet é…ç½®

```yaml:k8s-prod/otel-collector-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-collector
  namespace: observability
spec:
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      serviceAccountName: otel-collector
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:0.96.0
        ports:
        - containerPort: 4317
        resources:
          requests:
            memory: "1Gi"
            cpu: "1000m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        env:
        - name: K8S_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        volumeMounts:
        - name: config
          mountPath: /etc/otel
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
```

### Collector é…ç½®

```yaml:k8s-prod/otel-collector-config.yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_recv_msg_size_mib: 32

processors:
  batch:
    timeout: 10s
    send_batch_size: 512
    send_batch_max_size: 1024

  k8sattributes:
    auth_type: "serviceAccount"
    passthrough: false
    extract:
      metadata:
        - k8s.namespace.name
        - k8s.pod.name
        - k8s.node.name

  # Tail Samplingï¼ˆä¿ç•™é”™è¯¯å’Œæ…¢è¯·æ±‚ï¼‰
  tail_sampling:
    decision_wait: 10s
    num_traces: 100
    policies:
      - name: errors
        type: status_code
        status_code:
          status_codes: [ERROR]
      - name: slow
        type: latency
        latency:
          threshold_ms: 1000
      - name: random
        type: probabilistic
        probabilistic:
          sampling_percentage: 1  # 1% éšæœºé‡‡æ ·

  # å†…å­˜é™åˆ¶
  memory_limiter:
    check_interval: 1s
    limit_mib: 1536  # 1.5GB
    spike_limit_mib: 512

exporters:
  otlp/jaeger:
    endpoint: jaeger-collector:4317
    tls:
      insecure: true

  prometheusremotewrite:
    endpoint: http://prometheus:9090/api/v1/write

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, k8sattributes, tail_sampling, batch]
      exporters: [otlp/jaeger]
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, k8sattributes, batch]
      exporters: [prometheusremotewrite]
```

---

## ç›‘æ§å‘Šè­¦

### Prometheus å‘Šè­¦è§„åˆ™

```yaml:alerts.yaml
groups:
  - name: otel_collector
    rules:
      - alert: OTELCollectorDown
        expr: up{job="otel-collector"} == 0
        for: 5m
        annotations:
          summary: "OTLP Collector is down"

      - alert: HighDropRate
        expr: rate(otelcol_processor_dropped_spans[5m]) > 100
        for: 5m
        annotations:
          summary: "High span drop rate"

      - alert: HighMemoryUsage
        expr: container_memory_usage_bytes{pod=~"otel-collector.*"} > 1.8e9
        for: 5m
        annotations:
          summary: "OTLP Collector memory usage > 1.8GB"
```

---

## æˆæœ¬ä¼˜åŒ–

### é‡‡æ ·ç­–ç•¥

- **Head Sampling**: 5% é‡‡æ ·ç‡
- **Tail Sampling**: ä¿ç•™100%é”™è¯¯ + 100%æ…¢è¯·æ±‚ + 1%éšæœº

### æ•°æ®å½’æ¡£

```yaml
exporters:
  s3:
    region: us-east-1
    s3_bucket: traces-archive
    compression: gzip
service:
  pipelines:
    traces:
      exporters: [otlp/jaeger, s3]  # åŒæ—¶å½’æ¡£åˆ° S3
```

### ä¼°ç®—æˆæœ¬

```text
å‡è®¾:
- 100ä¸‡ RPM (requests per minute)
- 5% é‡‡æ ·ç‡ = 50,000 traces/min
- å¹³å‡ Span å¤§å° = 2KB
- æ•°æ®é‡ = 50,000 * 2KB = 100MB/min = 144GB/day

æˆæœ¬:
- Jaeger å­˜å‚¨ (7å¤©): 144GB * 7 = 1TB @ $0.023/GB = $23/day
- S3 å½’æ¡£ (90å¤©): 144GB * 90 = 12.96TB @ $0.004/GB = $52/month
- ç½‘ç»œä¼ è¾“: ~$10/month

æ€»è®¡: ~$60-70/month
```

---

## æ€§èƒ½è°ƒä¼˜

### 1. è¿æ¥æ± 

```go
exporter, err := otlptracegrpc.New(ctx,
    otlptracegrpc.WithDialOption(
        grpc.WithDefaultCallOptions(
            grpc.MaxCallRecvMsgSize(16*1024*1024), // 16MB
        ),
    ),
)
```

### 2. æ‰¹å¤„ç†

```yaml
processors:
  batch:
    timeout: 10s
    send_batch_size: 512        # æ‰¹æ¬¡å¤§å°
    send_batch_max_size: 1024   # æœ€å¤§æ‰¹æ¬¡
```

### 3. å¹¶å‘

```yaml
exporters:
  otlp:
    endpoint: jaeger:4317
    sending_queue:
      enabled: true
      num_consumers: 10  # 10ä¸ªå¹¶å‘å¯¼å‡º
      queue_size: 5000
```

---

## æ•…éšœæ¢å¤

### é‡è¯•ç­–ç•¥

```yaml
exporters:
  otlp:
    endpoint: jaeger:4317
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
```

### é™çº§ç­–ç•¥

```go
// å¦‚æœ Collector ä¸å¯ç”¨ï¼Œé™çº§ä¸ºæœ¬åœ°æ—¥å¿—
exporter, err := otlptracegrpc.New(ctx)
if err != nil {
    log.Warn("OTLP exporter unavailable, fallback to logging")
    exporter = loggingExporter()
}
```

---

## ğŸ¯ ç”Ÿäº§æ£€æŸ¥æ¸…å•

- [ ] é‡‡æ ·ç‡è®¾ç½®ï¼ˆ1-10%ï¼‰
- [ ] æ‰¹å¤„ç†é…ç½®ï¼ˆ10s, 512 spansï¼‰
- [ ] å†…å­˜é™åˆ¶ï¼ˆ< 2GBï¼‰
- [ ] èµ„æºé™åˆ¶ï¼ˆCPU/Memory requests & limitsï¼‰
- [ ] ç›‘æ§å‘Šè­¦ï¼ˆPrometheus alertsï¼‰
- [ ] æˆæœ¬ç›‘æ§ï¼ˆæ•°æ®é‡è¿½è¸ªï¼‰
- [ ] ç¾å¤‡æ–¹æ¡ˆï¼ˆå¤š Collector å®ä¾‹ï¼‰
- [ ] æ—¥å¿—çº§åˆ«ï¼ˆwarn æˆ– errorï¼‰

---

**ğŸŠ ç”Ÿäº§ç¯å¢ƒé…ç½®å®Œæˆï¼**

- ğŸ“š [ä¸­é—´ä»¶é›†æˆ](./04_ä¸­é—´ä»¶é›†æˆ_Gin.md)
- ğŸ“š [å®æˆ˜æ¡ˆä¾‹](../å®æˆ˜æ¡ˆä¾‹/)
